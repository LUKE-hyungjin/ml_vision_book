[{"id":0,"href":"/ko/docs/architecture/cnn/alexnet/","title":"AlexNet","section":"CNN","content":"AlexNet# 개요# 논문: ImageNet Classification with Deep Convolutional Neural Networks (2012) 저자: Alex Krizhevsky, Ilya Sutskever, Geoffrey Hinton 핵심 기여: 딥러닝 시대의 시작을 알린 모델. ImageNet 2012에서 압도적 성능으로 우승 왜 중요한가?# AlexNet은 ImageNet에서 top-5 error를 **26% → 16%**로 크게 낮추며 딥러닝의 가능성을 증명했습니다. 이후 모든 컴퓨터 비전 연구가 CNN 기반으로 전환되는 계기가 되었습니다.\n구조# 전체 아키텍처# Input (224×224×3) ↓ Conv1: 96 filters, 11×11, stride 4 → ReLU → LRN → MaxPool ↓ Conv2: 256 filters, 5×5 → ReLU → LRN → MaxPool ↓ Conv3: 384 filters, 3×3 → ReLU ↓ Conv4: 384 filters, 3×3 → ReLU ↓ Conv5: 256 filters, 3×3 → ReLU → MaxPool ↓ FC6: 4096 → ReLU → Dropout ↓ FC7: 4096 → ReLU → Dropout ↓ FC8: 1000 (softmax)주요 특징# 요소 설명 ReLU Sigmoid 대신 사용하여 학습 속도 6배 향상 GPU 학습 2개의 GTX 580 GPU로 병렬 학습 Dropout FC 레이어에 0.5 비율로 적용하여 과적합 방지 LRN Local Response Normalization (현재는 사용 안 함) Data Augmentation 랜덤 크롭, 수평 뒤집기, 색상 변환 핵심 기술 상세# 1. ReLU (Rectified Linear Unit)# $$f(x) = \\max(0, x)$$\n장점:\nSigmoid/tanh보다 계산이 단순 Gradient vanishing 문제 완화 학습 속도 대폭 향상 2. Dropout# 학습 시 뉴런을 랜덤하게 비활성화하여 과적합 방지:\n$$\\hat{y} = \\frac{1}{1-p} \\cdot y \\cdot \\text{mask}$$\n3. Data Augmentation# 원본 256×256 이미지에서:\n224×224 랜덤 크롭 수평 뒤집기 PCA 기반 색상 변환 파라미터 수# 레이어 파라미터 Conv 레이어 ~2.3M FC 레이어 ~58.6M 총합 ~60M 대부분의 파라미터가 FC 레이어에 집중되어 있습니다.\n구현 예시# import torch.nn as nn class AlexNet(nn.Module): def __init__(self, num_classes=1000): super().__init__() self.features = nn.Sequential( nn.Conv2d(3, 96, kernel_size=11, stride=4, padding=2), nn.ReLU(inplace=True), nn.MaxPool2d(kernel_size=3, stride=2), nn.Conv2d(96, 256, kernel_size=5, padding=2), nn.ReLU(inplace=True), nn.MaxPool2d(kernel_size=3, stride=2), nn.Conv2d(256, 384, kernel_size=3, padding=1), nn.ReLU(inplace=True), nn.Conv2d(384, 384, kernel_size=3, padding=1), nn.ReLU(inplace=True), nn.Conv2d(384, 256, kernel_size=3, padding=1), nn.ReLU(inplace=True), nn.MaxPool2d(kernel_size=3, stride=2), ) self.classifier = nn.Sequential( nn.Dropout(0.5), nn.Linear(256 * 6 * 6, 4096), nn.ReLU(inplace=True), nn.Dropout(0.5), nn.Linear(4096, 4096), nn.ReLU(inplace=True), nn.Linear(4096, num_classes), ) def forward(self, x): x = self.features(x) x = x.view(x.size(0), 256 * 6 * 6) x = self.classifier(x) return x 한계점# 큰 필터 크기 (11×11, 5×5) → 비효율적 LRN은 효과 미미 → 이후 사용 안 함 FC 레이어에 파라미터 집중 → 메모리 비효율 이러한 한계는 VGG와 ResNet에서 개선되었습니다.\n관련 콘텐츠# CNN 기초 - CNN의 기본 구조 VGG - 더 깊은 네트워크 ResNet - Skip Connection Classification - 이미지 분류 태스크 "},{"id":1,"href":"/ko/docs/architecture/classical/","title":"Classical CV","section":"아키텍처","content":"Classical Computer Vision# 딥러닝 이전의 전통적인 컴퓨터 비전 기법들입니다.\n특징# 수작업으로 설계된 특징 추출기 (Hand-crafted features) 수학적으로 해석 가능한 알고리즘 적은 데이터로도 동작 계산 비용이 상대적으로 낮음 주요 기법# SIFT \u0026amp; HOG - 대표적인 특징 추출 기법 "},{"id":2,"href":"/ko/docs/architecture/classical/sift-hog/","title":"SIFT \u0026 HOG","section":"Classical CV","content":"SIFT \u0026amp; HOG# 개요# 딥러닝 이전 시대의 대표적인 특징 추출 기법입니다.\n기법 연도 핵심 아이디어 SIFT 2004 스케일 불변 키포인트 검출 HOG 2005 그래디언트 방향 히스토그램 SIFT (Scale-Invariant Feature Transform)# 핵심 아이디어# 이미지의 크기나 회전에 관계없이 동일한 특징점을 찾아내는 알고리즘입니다.\n동작 과정# Scale-space 생성: Gaussian blur를 다양한 스케일로 적용 DoG (Difference of Gaussian): 인접한 스케일 간 차이 계산 키포인트 검출: DoG에서 극값(extrema) 찾기 방향 할당: 키포인트 주변의 그래디언트 방향 계산 디스크립터 생성: 128차원 벡터로 특징 표현 수식# Gaussian blur: $$L(x, y, \\sigma) = G(x, y, \\sigma) * I(x, y)$$\nDifference of Gaussian: $$D(x, y, \\sigma) = L(x, y, k\\sigma) - L(x, y, \\sigma)$$\n특징# 장점: 스케일, 회전, 조명 변화에 강건 단점: 계산 비용이 높음, 실시간 처리 어려움 HOG (Histogram of Oriented Gradients)# 핵심 아이디어# 이미지를 셀 단위로 나누고, 각 셀에서 그래디언트 방향의 히스토그램을 계산합니다.\n동작 과정# 그래디언트 계산: 각 픽셀에서 x, y 방향 그래디언트 계산 셀 분할: 이미지를 8x8 픽셀 셀로 분할 히스토그램 생성: 각 셀에서 9개 방향(0°~180°)의 히스토그램 계산 블록 정규화: 2x2 셀을 하나의 블록으로 묶어 정규화 특징 벡터 생성: 모든 블록의 히스토그램을 연결 수식# 그래디언트 크기와 방향: $$G = \\sqrt{G_x^2 + G_y^2}$$ $$\\theta = \\arctan\\left(\\frac{G_y}{G_x}\\right)$$\n특징# 장점: 조명 변화에 강건, 계산이 상대적으로 빠름 단점: 스케일 변화에 민감 주요 용도: 보행자 검출 (Dalal \u0026amp; Triggs, 2005) 구현 예시# import cv2 # SIFT sift = cv2.SIFT_create() keypoints, descriptors = sift.detectAndCompute(image, None) # HOG hog = cv2.HOGDescriptor() hog.setSVMDetector(cv2.HOGDescriptor_getDefaultPeopleDetector()) boxes, weights = hog.detectMultiScale(image) 딥러닝과의 비교# 측면 SIFT/HOG CNN 특징 설계 수작업 학습 기반 데이터 요구량 적음 많음 성능 제한적 우수 해석 가능성 높음 낮음 일반화 제한적 우수 현재는 대부분의 태스크에서 딥러닝이 SIFT/HOG를 대체했지만, 특징 매칭이나 엣지 케이스에서는 여전히 사용됩니다.\n관련 콘텐츠# 선형대수 - 그래디언트 계산의 기초 CNN 기초 - SIFT/HOG를 대체한 딥러닝 기법 "},{"id":3,"href":"/ko/docs/timeline/","title":"타임라인","section":"Docs","content":"타임라인으로 배우는 Vision# 연대순으로 Computer Vision의 발전 과정을 따라가며 학습합니다.\n~2012: Classical Computer Vision# 선형대수 기하학 SIFT \u0026amp; HOG 2012-2015: CNN 시대의 시작# Convolution Backpropagation AlexNet VGG ResNet Classification 2015-2017: Detection \u0026amp; Segmentation# IoU \u0026amp; NMS YOLO Faster R-CNN U-Net Detection Segmentation 2017-2019: Attention의 등장# Attention Transformer 2020-2021: Vision Transformer \u0026amp; CLIP# ViT CLIP Contrastive Learning Self-supervised Learning 2021-2022: Diffusion 시대# Diffusion Process Stable Diffusion Generation 2023: Controllable Generation \u0026amp; SAM# ControlNet SAM 2023-2024: VLM \u0026amp; DiT# VLM DiT Vision-Language 2024-현재: 3D \u0026amp; Video Generation# NeRF 3D Gaussian Splatting 3D Vision "},{"id":4,"href":"/ko/docs/architecture/cnn/","title":"CNN","section":"아키텍처","content":"CNN (Convolutional Neural Network)# 개요# CNN은 이미지 처리에 특화된 신경망 구조로, 2012년 AlexNet의 등장 이후 컴퓨터 비전의 핵심이 되었습니다.\n핵심 구성 요소# 1. Convolution Layer# 필터(커널)를 이미지에 슬라이딩하며 특징을 추출합니다.\n$$\\text{Output}(i,j) = \\sum_{m}\\sum_{n} \\text{Input}(i+m, j+n) \\cdot \\text{Kernel}(m,n)$$\n특징:\n파라미터 공유로 효율적 지역적 패턴 학습 Translation equivariance 2. Pooling Layer# 공간 해상도를 줄이고 위치 불변성을 제공합니다.\nMax Pooling: 영역 내 최댓값 선택 Average Pooling: 영역 내 평균값 계산 3. Activation Function# 비선형성을 추가합니다.\n$$\\text{ReLU}(x) = \\max(0, x)$$\n4. Fully Connected Layer# 최종 분류를 위한 전결합 층입니다.\n전형적인 CNN 구조# Input → [Conv → ReLU → Pool] × N → Flatten → FC → Output 주요 발전 과정# 연도 모델 핵심 기여 2012 AlexNet GPU 학습, ReLU, Dropout 2014 VGG 깊은 네트워크, 3x3 필터 2015 ResNet Skip Connection, 152층 구현 예시# import torch.nn as nn class SimpleCNN(nn.Module): def __init__(self, num_classes=10): super().__init__() self.features = nn.Sequential( nn.Conv2d(3, 64, kernel_size=3, padding=1), nn.ReLU(), nn.MaxPool2d(2), nn.Conv2d(64, 128, kernel_size=3, padding=1), nn.ReLU(), nn.MaxPool2d(2), ) self.classifier = nn.Sequential( nn.Flatten(), nn.Linear(128 * 8 * 8, 256), nn.ReLU(), nn.Linear(256, num_classes), ) def forward(self, x): x = self.features(x) x = self.classifier(x) return x 관련 콘텐츠# Convolution - Convolution 연산의 수학적 이해 Backpropagation - CNN 학습 원리 Classification - CNN의 대표적 응용 "},{"id":5,"href":"/ko/docs/topdown/","title":"Top-Down","section":"Docs","content":"Top-Down 학습# 문제를 정하고, 필요한 지식을 찾아갑니다.\nImage Classification# Cross-entropy Loss CNN 기초 ResNet Classification Object Detection# IoU \u0026amp; NMS Anchor Box Faster R-CNN YOLO Detection Segmentation# Transposed Convolution U-Net Mask R-CNN Segmentation Image Generation# 확률분포 VAE GAN Diffusion Stable Diffusion ControlNet DiT Generation Vision-Language (VLM)# Contrastive Learning CLIP VLM Vision-Language 3D Vision# 카메라 모델 NeRF 3D Vision 모델 배포# Quantization Deployment "},{"id":6,"href":"/ko/docs/bottomup/","title":"Bottom-Up","section":"Docs","content":"Bottom-Up 학습# 기초 개념부터 차근차근 쌓아올립니다.\nLevel 1: 수학 기초# 선형대수 미적분 \u0026amp; Chain Rule 확률/통계 Level 2: 딥러닝 기초# Convolution Backpropagation Loss Functions Optimization Level 3: 기본 아키텍처# CNN 기초 AlexNet VGG ResNet Level 4: 기본 태스크# Classification Detection Segmentation Level 5: 고급 개념# Attention Transformer ViT Level 6: 생성 모델# Diffusion Process Stable Diffusion ControlNet DiT Generation Level 7: Multimodal \u0026amp; 3D# Contrastive Learning CLIP VLM Vision-Language NeRF 3D Vision "},{"id":7,"href":"/ko/docs/math/","title":"수학","section":"Docs","content":"수학 기초# Vision 엔지니어에게 필요한 수학 지식입니다.\n"},{"id":8,"href":"/ko/docs/architecture/","title":"아키텍처","section":"Docs","content":"아키텍처# Computer Vision 모델 및 네트워크 구조입니다.\n카테고리# Classical CV - SIFT, HOG 등 전통적 특징 추출 CNN - Convolutional Neural Network 계열 Detection - 객체 탐지 모델 Segmentation - 세그멘테이션 모델 Transformer - Transformer 기반 모델 Generative - 생성 모델 Multimodal - 멀티모달 모델 3D - 3D 비전 모델 "},{"id":9,"href":"/ko/docs/task/","title":"태스크","section":"Docs","content":"태스크# 문제 정의, 평가지표, 데이터셋입니다.\n"},{"id":10,"href":"/ko/docs/etc/","title":"기타 자료","section":"Docs","content":"논문 \u0026amp; 자료# 필수 논문과 학습 자료 모음입니다.\n"}]