<!DOCTYPE html>
<html lang="ko-KR" dir="ltr">
<head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script>
  <!--
Made with Book Theme
https://github.com/alex-shpak/hugo-book
-->

<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="description" content="ONNX (Open Neural Network Exchange)# 개요# ONNX는 딥러닝 모델의 표준 교환 포맷입니다.
PyTorch ─┐ TensorFlow ─┼──→ ONNX ──→ TensorRT / OpenVINO / CoreML / ... Keras ─┘ PyTorch → ONNX 변환# 기본 변환# import torch import torch.onnx model = MyModel() model.load_state_dict(torch.load(&#39;model.pt&#39;)) model.eval() # 더미 입력 (모델 구조 추론용) dummy_input = torch.randn(1, 3, 224, 224) # ONNX 변환 torch.onnx.export( model, dummy_input, &#34;model.onnx&#34;, input_names=[&#39;input&#39;], output_names=[&#39;output&#39;], dynamic_axes={ &#39;input&#39;: {0: &#39;batch_size&#39;}, &#39;output&#39;: {0: &#39;batch_size&#39;} }, opset_version=17, )주요 파라미터# 파라미터 설명 input_names 입력 텐서 이름 output_names 출력 텐서 이름 dynamic_axes 동적 차원 (배치 크기 등) opset_version ONNX 연산자 버전 ONNX 검증# 구조 확인# import onnx # 모델 로드 및 검증 model = onnx.load(&#34;model.onnx&#34;) onnx.checker.check_model(model) # 그래프 정보 print(onnx.helper.printable_graph(model.graph))Netron으로 시각화# pip install netron netron model.onnx ONNX Runtime 추론# 기본 추론# import onnxruntime as ort import numpy as np # 세션 생성 session = ort.InferenceSession( &#34;model.onnx&#34;, providers=[&#39;CUDAExecutionProvider&#39;, &#39;CPUExecutionProvider&#39;] ) # 입력 정보 input_name = session.get_inputs()[0].name output_name = session.get_outputs()[0].name # 추론 input_data = np.random.randn(1, 3, 224, 224).astype(np.float32) result = session.run([output_name], {input_name: input_data})성능 최적화# # 세션 옵션 sess_options = ort.SessionOptions() sess_options.graph_optimization_level = ort.GraphOptimizationLevel.ORT_ENABLE_ALL sess_options.intra_op_num_threads = 4 # GPU 옵션 providers = [ (&#39;CUDAExecutionProvider&#39;, { &#39;device_id&#39;: 0, &#39;arena_extend_strategy&#39;: &#39;kNextPowerOfTwo&#39;, }), &#39;CPUExecutionProvider&#39; ] session = ort.InferenceSession(&#34;model.onnx&#34;, sess_options, providers=providers) 동적 입력 처리# 가변 배치 크기# torch.onnx.export( model, dummy_input, &#34;model.onnx&#34;, dynamic_axes={ &#39;input&#39;: {0: &#39;batch&#39;}, &#39;output&#39;: {0: &#39;batch&#39;} } )가변 이미지 크기# torch.onnx.export( model, dummy_input, &#34;model.onnx&#34;, dynamic_axes={ &#39;input&#39;: {0: &#39;batch&#39;, 2: &#39;height&#39;, 3: &#39;width&#39;}, &#39;output&#39;: {0: &#39;batch&#39;} } ) 일반적인 문제 해결# 지원되지 않는 연산자# # 커스텀 연산자 등록 from torch.onnx import register_custom_op_symbolic def my_custom_op(g, input): return g.op(&#34;CustomOp&#34;, input) register_custom_op_symbolic(&#39;my_custom_op&#39;, my_custom_op, opset_version=11)동적 제어 흐름# # torch.jit.script 사용 @torch.jit.script def my_function(x): if x.sum() &gt; 0: return x * 2 return x # 또는 조건부 로직 제거값 불일치# # PyTorch와 ONNX Runtime 출력 비교 import numpy as np torch_output = model(input_tensor).detach().numpy() onnx_output = session.run([output_name], {input_name: input_data})[0] np.testing.assert_allclose(torch_output, onnx_output, rtol=1e-3, atol=1e-5) ONNX 모델 최적화# onnxoptimizer# import onnx from onnxoptimizer import optimize model = onnx.load(&#34;model.onnx&#34;) optimized_model = optimize(model, [ &#39;eliminate_deadend&#39;, &#39;eliminate_identity&#39;, &#39;fuse_consecutive_transposes&#39;, &#39;fuse_bn_into_conv&#39;, ]) onnx.save(optimized_model, &#34;model_optimized.onnx&#34;)onnx-simplifier# pip install onnx-simplifier onnxsim model.onnx model_simplified.onnximport onnx from onnxsim import simplify model = onnx.load(&#34;model.onnx&#34;) simplified_model, check = simplify(model) onnx.save(simplified_model, &#34;model_simplified.onnx&#34;) 벤치마크# import time import numpy as np # 워밍업 for _ in range(10): session.run([output_name], {input_name: input_data}) # 측정 n_runs = 100 start = time.time() for _ in range(n_runs): session.run([output_name], {input_name: input_data}) elapsed = time.time() - start print(f&#34;Average latency: {elapsed / n_runs * 1000:.2f} ms&#34;) print(f&#34;Throughput: {n_runs / elapsed:.2f} FPS&#34;) 관련 콘텐츠# TensorRT - GPU 최적화 모델 서빙 - 추론 서버 최적화 - 양자화 ">
<meta name="theme-color" media="(prefers-color-scheme: light)" content="#ffffff">
<meta name="theme-color" media="(prefers-color-scheme: dark)" content="#343a40">
<meta name="color-scheme" content="light dark"><meta property="og:url" content="http://localhost:1313/ko/docs/engineering/deployment/onnx/">
  <meta property="og:site_name" content="Vision Engineer 지식 가이드">
  <meta property="og:title" content="ONNX">
  <meta property="og:description" content="ONNX (Open Neural Network Exchange)# 개요# ONNX는 딥러닝 모델의 표준 교환 포맷입니다.
PyTorch ─┐ TensorFlow ─┼──→ ONNX ──→ TensorRT / OpenVINO / CoreML / ... Keras ─┘ PyTorch → ONNX 변환# 기본 변환# import torch import torch.onnx model = MyModel() model.load_state_dict(torch.load(&#39;model.pt&#39;)) model.eval() # 더미 입력 (모델 구조 추론용) dummy_input = torch.randn(1, 3, 224, 224) # ONNX 변환 torch.onnx.export( model, dummy_input, &#34;model.onnx&#34;, input_names=[&#39;input&#39;], output_names=[&#39;output&#39;], dynamic_axes={ &#39;input&#39;: {0: &#39;batch_size&#39;}, &#39;output&#39;: {0: &#39;batch_size&#39;} }, opset_version=17, )주요 파라미터# 파라미터 설명 input_names 입력 텐서 이름 output_names 출력 텐서 이름 dynamic_axes 동적 차원 (배치 크기 등) opset_version ONNX 연산자 버전 ONNX 검증# 구조 확인# import onnx # 모델 로드 및 검증 model = onnx.load(&#34;model.onnx&#34;) onnx.checker.check_model(model) # 그래프 정보 print(onnx.helper.printable_graph(model.graph))Netron으로 시각화# pip install netron netron model.onnx ONNX Runtime 추론# 기본 추론# import onnxruntime as ort import numpy as np # 세션 생성 session = ort.InferenceSession( &#34;model.onnx&#34;, providers=[&#39;CUDAExecutionProvider&#39;, &#39;CPUExecutionProvider&#39;] ) # 입력 정보 input_name = session.get_inputs()[0].name output_name = session.get_outputs()[0].name # 추론 input_data = np.random.randn(1, 3, 224, 224).astype(np.float32) result = session.run([output_name], {input_name: input_data})성능 최적화# # 세션 옵션 sess_options = ort.SessionOptions() sess_options.graph_optimization_level = ort.GraphOptimizationLevel.ORT_ENABLE_ALL sess_options.intra_op_num_threads = 4 # GPU 옵션 providers = [ (&#39;CUDAExecutionProvider&#39;, { &#39;device_id&#39;: 0, &#39;arena_extend_strategy&#39;: &#39;kNextPowerOfTwo&#39;, }), &#39;CPUExecutionProvider&#39; ] session = ort.InferenceSession(&#34;model.onnx&#34;, sess_options, providers=providers) 동적 입력 처리# 가변 배치 크기# torch.onnx.export( model, dummy_input, &#34;model.onnx&#34;, dynamic_axes={ &#39;input&#39;: {0: &#39;batch&#39;}, &#39;output&#39;: {0: &#39;batch&#39;} } )가변 이미지 크기# torch.onnx.export( model, dummy_input, &#34;model.onnx&#34;, dynamic_axes={ &#39;input&#39;: {0: &#39;batch&#39;, 2: &#39;height&#39;, 3: &#39;width&#39;}, &#39;output&#39;: {0: &#39;batch&#39;} } ) 일반적인 문제 해결# 지원되지 않는 연산자# # 커스텀 연산자 등록 from torch.onnx import register_custom_op_symbolic def my_custom_op(g, input): return g.op(&#34;CustomOp&#34;, input) register_custom_op_symbolic(&#39;my_custom_op&#39;, my_custom_op, opset_version=11)동적 제어 흐름# # torch.jit.script 사용 @torch.jit.script def my_function(x): if x.sum() &gt; 0: return x * 2 return x # 또는 조건부 로직 제거값 불일치# # PyTorch와 ONNX Runtime 출력 비교 import numpy as np torch_output = model(input_tensor).detach().numpy() onnx_output = session.run([output_name], {input_name: input_data})[0] np.testing.assert_allclose(torch_output, onnx_output, rtol=1e-3, atol=1e-5) ONNX 모델 최적화# onnxoptimizer# import onnx from onnxoptimizer import optimize model = onnx.load(&#34;model.onnx&#34;) optimized_model = optimize(model, [ &#39;eliminate_deadend&#39;, &#39;eliminate_identity&#39;, &#39;fuse_consecutive_transposes&#39;, &#39;fuse_bn_into_conv&#39;, ]) onnx.save(optimized_model, &#34;model_optimized.onnx&#34;)onnx-simplifier# pip install onnx-simplifier onnxsim model.onnx model_simplified.onnximport onnx from onnxsim import simplify model = onnx.load(&#34;model.onnx&#34;) simplified_model, check = simplify(model) onnx.save(simplified_model, &#34;model_simplified.onnx&#34;) 벤치마크# import time import numpy as np # 워밍업 for _ in range(10): session.run([output_name], {input_name: input_data}) # 측정 n_runs = 100 start = time.time() for _ in range(n_runs): session.run([output_name], {input_name: input_data}) elapsed = time.time() - start print(f&#34;Average latency: {elapsed / n_runs * 1000:.2f} ms&#34;) print(f&#34;Throughput: {n_runs / elapsed:.2f} FPS&#34;) 관련 콘텐츠# TensorRT - GPU 최적화 모델 서빙 - 추론 서버 최적화 - 양자화">
  <meta property="og:locale" content="ko_KR">
  <meta property="og:type" content="article">
    <meta property="article:section" content="docs">


  <meta itemprop="name" content="ONNX">
  <meta itemprop="description" content="ONNX (Open Neural Network Exchange)# 개요# ONNX는 딥러닝 모델의 표준 교환 포맷입니다.
PyTorch ─┐ TensorFlow ─┼──→ ONNX ──→ TensorRT / OpenVINO / CoreML / ... Keras ─┘ PyTorch → ONNX 변환# 기본 변환# import torch import torch.onnx model = MyModel() model.load_state_dict(torch.load(&#39;model.pt&#39;)) model.eval() # 더미 입력 (모델 구조 추론용) dummy_input = torch.randn(1, 3, 224, 224) # ONNX 변환 torch.onnx.export( model, dummy_input, &#34;model.onnx&#34;, input_names=[&#39;input&#39;], output_names=[&#39;output&#39;], dynamic_axes={ &#39;input&#39;: {0: &#39;batch_size&#39;}, &#39;output&#39;: {0: &#39;batch_size&#39;} }, opset_version=17, )주요 파라미터# 파라미터 설명 input_names 입력 텐서 이름 output_names 출력 텐서 이름 dynamic_axes 동적 차원 (배치 크기 등) opset_version ONNX 연산자 버전 ONNX 검증# 구조 확인# import onnx # 모델 로드 및 검증 model = onnx.load(&#34;model.onnx&#34;) onnx.checker.check_model(model) # 그래프 정보 print(onnx.helper.printable_graph(model.graph))Netron으로 시각화# pip install netron netron model.onnx ONNX Runtime 추론# 기본 추론# import onnxruntime as ort import numpy as np # 세션 생성 session = ort.InferenceSession( &#34;model.onnx&#34;, providers=[&#39;CUDAExecutionProvider&#39;, &#39;CPUExecutionProvider&#39;] ) # 입력 정보 input_name = session.get_inputs()[0].name output_name = session.get_outputs()[0].name # 추론 input_data = np.random.randn(1, 3, 224, 224).astype(np.float32) result = session.run([output_name], {input_name: input_data})성능 최적화# # 세션 옵션 sess_options = ort.SessionOptions() sess_options.graph_optimization_level = ort.GraphOptimizationLevel.ORT_ENABLE_ALL sess_options.intra_op_num_threads = 4 # GPU 옵션 providers = [ (&#39;CUDAExecutionProvider&#39;, { &#39;device_id&#39;: 0, &#39;arena_extend_strategy&#39;: &#39;kNextPowerOfTwo&#39;, }), &#39;CPUExecutionProvider&#39; ] session = ort.InferenceSession(&#34;model.onnx&#34;, sess_options, providers=providers) 동적 입력 처리# 가변 배치 크기# torch.onnx.export( model, dummy_input, &#34;model.onnx&#34;, dynamic_axes={ &#39;input&#39;: {0: &#39;batch&#39;}, &#39;output&#39;: {0: &#39;batch&#39;} } )가변 이미지 크기# torch.onnx.export( model, dummy_input, &#34;model.onnx&#34;, dynamic_axes={ &#39;input&#39;: {0: &#39;batch&#39;, 2: &#39;height&#39;, 3: &#39;width&#39;}, &#39;output&#39;: {0: &#39;batch&#39;} } ) 일반적인 문제 해결# 지원되지 않는 연산자# # 커스텀 연산자 등록 from torch.onnx import register_custom_op_symbolic def my_custom_op(g, input): return g.op(&#34;CustomOp&#34;, input) register_custom_op_symbolic(&#39;my_custom_op&#39;, my_custom_op, opset_version=11)동적 제어 흐름# # torch.jit.script 사용 @torch.jit.script def my_function(x): if x.sum() &gt; 0: return x * 2 return x # 또는 조건부 로직 제거값 불일치# # PyTorch와 ONNX Runtime 출력 비교 import numpy as np torch_output = model(input_tensor).detach().numpy() onnx_output = session.run([output_name], {input_name: input_data})[0] np.testing.assert_allclose(torch_output, onnx_output, rtol=1e-3, atol=1e-5) ONNX 모델 최적화# onnxoptimizer# import onnx from onnxoptimizer import optimize model = onnx.load(&#34;model.onnx&#34;) optimized_model = optimize(model, [ &#39;eliminate_deadend&#39;, &#39;eliminate_identity&#39;, &#39;fuse_consecutive_transposes&#39;, &#39;fuse_bn_into_conv&#39;, ]) onnx.save(optimized_model, &#34;model_optimized.onnx&#34;)onnx-simplifier# pip install onnx-simplifier onnxsim model.onnx model_simplified.onnximport onnx from onnxsim import simplify model = onnx.load(&#34;model.onnx&#34;) simplified_model, check = simplify(model) onnx.save(simplified_model, &#34;model_simplified.onnx&#34;) 벤치마크# import time import numpy as np # 워밍업 for _ in range(10): session.run([output_name], {input_name: input_data}) # 측정 n_runs = 100 start = time.time() for _ in range(n_runs): session.run([output_name], {input_name: input_data}) elapsed = time.time() - start print(f&#34;Average latency: {elapsed / n_runs * 1000:.2f} ms&#34;) print(f&#34;Throughput: {n_runs / elapsed:.2f} FPS&#34;) 관련 콘텐츠# TensorRT - GPU 최적화 모델 서빙 - 추론 서버 최적화 - 양자화">
  <meta itemprop="wordCount" content="411">

<title>ONNX | Vision Engineer 지식 가이드</title>
<link rel="icon" href="/favicon.png" >
<link rel="manifest" href="/manifest.json">
<link rel="canonical" href="http://localhost:1313/ko/docs/engineering/deployment/onnx/">
<link rel="stylesheet" href="/book.min.6970156cec683193d93c9c4edaf0d56574e4361df2e0c1be4f697ae81c3ba55f.css" integrity="sha256-aXAVbOxoMZPZPJxO2vDVZXTkNh3y4MG&#43;T2l66Bw7pV8=" crossorigin="anonymous">


  <script defer src="/fuse.min.js"></script>
  <script defer src="/ko.search.min.e521ced8a1de353f186f5733d176d23d7236b1309fd3a485d880dd5743b5a505.js" integrity="sha256-5SHO2KHeNT8Yb1cz0XbSPXI2sTCf06SF2IDdV0O1pQU=" crossorigin="anonymous"></script>



  <link rel="stylesheet" href="/katex/katex.min.css" />
<script defer src="/katex/katex.min.js"></script><script defer src="/katex/auto-render.min.js" onload="renderMathInElement(document.body, {&#34;delimiters&#34;:[{&#34;left&#34;:&#34;$$&#34;,&#34;right&#34;:&#34;$$&#34;,&#34;display&#34;:true},{&#34;left&#34;:&#34;\\(&#34;,&#34;right&#34;:&#34;\\)&#34;,&#34;display&#34;:false},{&#34;left&#34;:&#34;\\[&#34;,&#34;right&#34;:&#34;\\]&#34;,&#34;display&#34;:true}]});"></script>
</head>
<body dir="ltr" class="book-kind-page book-type-docs">
  <input type="checkbox" class="hidden toggle" id="menu-control" />
  <input type="checkbox" class="hidden toggle" id="toc-control" />
  <main class="container flex">
    
<aside class="book-menu">
  <div class="book-menu-content">
    
  <nav>
<h2 class="book-brand">
  <a class="flex align-center" href="/ko/"><span>Vision Engineer 지식 가이드</span>
  </a>
</h2>


<div class="book-search hidden">
  <input id="book-search-input" type="text" 
    placeholder="Search"
    aria-label="Search"
    maxlength="64" data-hotkeys="s/" />
  <div class="book-search-spinner hidden"></div>
  <ul id="book-search-results"></ul>
</div>
<script>document.querySelector(".book-search").classList.remove("hidden")</script>



  


  
    
  



<ul class="book-languages">
  <li>
    <input type="checkbox" id="languages" class="toggle" />
    <label for="languages" class="flex">
      <a role="button">
        <img src="/icons/translate.svg" class="book-icon" alt="Languages" />
        한국어
      </a>
      <img src="/icons/chevron-right.svg" class="book-icon" alt="Expand" />
    </label>

    <ul>
      
      <li>
        <a href="/" class="flex flex-auto">
          English
        </a>
      </li>
      
    </ul>
  </li>
</ul>












  
  <ul>
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-14bcba7439f342435c91a57530ca56c8" class="toggle"  />
    <label for="section-14bcba7439f342435c91a57530ca56c8" class="flex">
      <a href="/ko/docs/timeline/" class="">
        타임라인</a>
      <img src="/icons/chevron-right.svg" class="book-icon" alt="Expand" />
    </label>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-cb9657695dbd536c3a44d019c4d6ef98" class="toggle"  />
    <label for="section-cb9657695dbd536c3a44d019c4d6ef98" class="flex">
      <a href="/ko/docs/topdown/" class="">
        Top-Down</a>
      <img src="/icons/chevron-right.svg" class="book-icon" alt="Expand" />
    </label>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-e7f22db027b1c591ed84a4d4d3a6014f" class="toggle"  />
    <label for="section-e7f22db027b1c591ed84a4d4d3a6014f" class="flex">
      <a href="/ko/docs/bottomup/" class="">
        Bottom-Up</a>
      <img src="/icons/chevron-right.svg" class="book-icon" alt="Expand" />
    </label>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-ce31bba1d1f88a1d133a7e7232f1b4ec" class="toggle"  />
    <label for="section-ce31bba1d1f88a1d133a7e7232f1b4ec" class="flex">
      <a href="/ko/docs/math/" class="">
        수학</a>
      <img src="/icons/chevron-right.svg" class="book-icon" alt="Expand" />
    </label>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-b7c22078b221fa1e5fe6dba5f036e317" class="toggle" checked />
    <label for="section-b7c22078b221fa1e5fe6dba5f036e317" class="flex">
      <a href="/ko/docs/engineering/" class="">
        실무 기술</a>
      <img src="/icons/chevron-right.svg" class="book-icon" alt="Expand" />
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-41bc70f3b465f23cc6f68dbb9cf6930e" class="toggle"  />
    <label for="section-41bc70f3b465f23cc6f68dbb9cf6930e" class="flex">
      <a href="/ko/docs/engineering/data/" class="">
        데이터</a>
      <img src="/icons/chevron-right.svg" class="book-icon" alt="Expand" />
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/ko/docs/engineering/data/augmentation/" class="">
      데이터 증강</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/ko/docs/engineering/data/formats/" class="">
      데이터 포맷</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/ko/docs/engineering/data/pipeline/" class="">
      데이터 파이프라인</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/ko/docs/engineering/data/labeling/" class="">
      레이블링</a>
  

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-08b7417cd9477b9be27e6c7b561a01bc" class="toggle" checked />
    <label for="section-08b7417cd9477b9be27e6c7b561a01bc" class="flex">
      <a href="/ko/docs/engineering/deployment/" class="">
        배포</a>
      <img src="/icons/chevron-right.svg" class="book-icon" alt="Expand" />
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/ko/docs/engineering/deployment/onnx/" class="active">
      ONNX</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/ko/docs/engineering/deployment/tensorrt/" class="">
      TensorRT</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/ko/docs/engineering/deployment/serving/" class="">
      모델 서빙</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/ko/docs/engineering/deployment/optimization/" class="">
      모델 최적화</a>
  

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-d367cbc8b1f6018b8f46a12cb86b41d6" class="toggle"  />
    <label for="section-d367cbc8b1f6018b8f46a12cb86b41d6" class="flex">
      <a href="/ko/docs/engineering/hardware/" class="">
        하드웨어</a>
      <img src="/icons/chevron-right.svg" class="book-icon" alt="Expand" />
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/ko/docs/engineering/hardware/camera/" class="">
      카메라</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/ko/docs/engineering/hardware/lighting/" class="">
      조명</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/ko/docs/engineering/hardware/edge/" class="">
      엣지 디바이스</a>
  

        </li>
      
    
  </ul>

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-32f2aee524dad19f5100855d6e2014e6" class="toggle"  />
    <label for="section-32f2aee524dad19f5100855d6e2014e6" class="flex">
      <a href="/ko/docs/architecture/" class="">
        아키텍처</a>
      <img src="/icons/chevron-right.svg" class="book-icon" alt="Expand" />
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-47444199c3019e8b479623bc90a9bd74" class="toggle"  />
    <label for="section-47444199c3019e8b479623bc90a9bd74" class="flex">
      <a href="/ko/docs/architecture/classical/" class="">
        Classical CV</a>
      <img src="/icons/chevron-right.svg" class="book-icon" alt="Expand" />
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/ko/docs/architecture/classical/sift-hog/" class="">
      SIFT &amp; HOG</a>
  

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-7bf44239f7ce2c72600738f8c315efe4" class="toggle"  />
    <label for="section-7bf44239f7ce2c72600738f8c315efe4" class="flex">
      <a href="/ko/docs/architecture/cnn/" class="">
        CNN</a>
      <img src="/icons/chevron-right.svg" class="book-icon" alt="Expand" />
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/ko/docs/architecture/cnn/alexnet/" class="">
      AlexNet</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/ko/docs/architecture/cnn/vgg/" class="">
      VGG</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/ko/docs/architecture/cnn/resnet/" class="">
      ResNet</a>
  

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-274b800b12326ef4e06255cf5f15c308" class="toggle"  />
    <label for="section-274b800b12326ef4e06255cf5f15c308" class="flex">
      <a href="/ko/docs/architecture/detection/" class="">
        Detection</a>
      <img src="/icons/chevron-right.svg" class="book-icon" alt="Expand" />
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/ko/docs/architecture/detection/faster-rcnn/" class="">
      Faster R-CNN</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/ko/docs/architecture/detection/yolo/" class="">
      YOLO</a>
  

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-7246e67fd6c549f3bd6240d998b23a6f" class="toggle"  />
    <label for="section-7246e67fd6c549f3bd6240d998b23a6f" class="flex">
      <a href="/ko/docs/architecture/segmentation/" class="">
        Segmentation</a>
      <img src="/icons/chevron-right.svg" class="book-icon" alt="Expand" />
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/ko/docs/architecture/segmentation/unet/" class="">
      U-Net</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/ko/docs/architecture/segmentation/mask-rcnn/" class="">
      Mask R-CNN</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/ko/docs/architecture/segmentation/sam/" class="">
      SAM</a>
  

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-3a9f4e0826e1b9e72550db30b2adcad7" class="toggle"  />
    <label for="section-3a9f4e0826e1b9e72550db30b2adcad7" class="flex">
      <a href="/ko/docs/architecture/transformer/" class="">
        Transformer</a>
      <img src="/icons/chevron-right.svg" class="book-icon" alt="Expand" />
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/ko/docs/architecture/transformer/vit/" class="">
      ViT</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/ko/docs/architecture/transformer/dit/" class="">
      DiT</a>
  

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-2902afa0a62febfd7a5eb243df871e8c" class="toggle"  />
    <label for="section-2902afa0a62febfd7a5eb243df871e8c" class="flex">
      <a href="/ko/docs/architecture/generative/" class="">
        Generative</a>
      <img src="/icons/chevron-right.svg" class="book-icon" alt="Expand" />
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/ko/docs/architecture/generative/vae/" class="">
      VAE</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/ko/docs/architecture/generative/gan/" class="">
      GAN</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/ko/docs/architecture/generative/stable-diffusion/" class="">
      Stable Diffusion</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/ko/docs/architecture/generative/controlnet/" class="">
      ControlNet</a>
  

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-1670f136e85bf39bce97c9ee224d29d9" class="toggle"  />
    <label for="section-1670f136e85bf39bce97c9ee224d29d9" class="flex">
      <a href="/ko/docs/architecture/multimodal/" class="">
        Multimodal</a>
      <img src="/icons/chevron-right.svg" class="book-icon" alt="Expand" />
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/ko/docs/architecture/multimodal/clip/" class="">
      CLIP</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/ko/docs/architecture/multimodal/vlm/" class="">
      VLM</a>
  

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-fc1b0b4545ce791b47ab3fe55b854e56" class="toggle"  />
    <label for="section-fc1b0b4545ce791b47ab3fe55b854e56" class="flex">
      <a href="/ko/docs/architecture/3d/" class="">
        3D Vision</a>
      <img src="/icons/chevron-right.svg" class="book-icon" alt="Expand" />
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/ko/docs/architecture/3d/nerf/" class="">
      NeRF</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/ko/docs/architecture/3d/3dgs/" class="">
      3D Gaussian Splatting</a>
  

        </li>
      
    
  </ul>

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-cd575cc6fd4e25b684b552791b7a009a" class="toggle"  />
    <label for="section-cd575cc6fd4e25b684b552791b7a009a" class="flex">
      <a href="/ko/docs/task/" class="">
        태스크</a>
      <img src="/icons/chevron-right.svg" class="book-icon" alt="Expand" />
    </label>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-fb690f19903e1435676f710c928c9ad4" class="toggle"  />
    <label for="section-fb690f19903e1435676f710c928c9ad4" class="flex">
      <a href="/ko/docs/etc/" class="">
        기타 자료</a>
      <img src="/icons/chevron-right.svg" class="book-icon" alt="Expand" />
    </label>
  

          
  <ul>
    
  </ul>

        </li>
      
    
  </ul>













</nav>




  <script>(function(){var e=document.querySelector("aside .book-menu-content");addEventListener("beforeunload",function(){localStorage.setItem("menu.scrollTop",e.scrollTop)}),e.scrollTop=localStorage.getItem("menu.scrollTop")})()</script>



  </div>
</aside>
 

    <div class="book-page">
      <header class="book-header hidden">
        
  <div class="flex align-center justify-between">
  <label for="menu-control">
    <img src="/icons/menu.svg" class="book-icon" alt="Menu" />
  </label>

  <h3>ONNX</h3>

  <label for="toc-control">
    
    <img src="/icons/toc.svg" class="book-icon" alt="Table of Contents" />
    
  </label>
</div>


  
  <aside class="hidden">
    
  
<nav id="TableOfContents">
  <ul>
    <li><a href="#개요">개요</a></li>
    <li><a href="#pytorch--onnx-변환">PyTorch → ONNX 변환</a>
      <ul>
        <li><a href="#기본-변환">기본 변환</a></li>
        <li><a href="#주요-파라미터">주요 파라미터</a></li>
      </ul>
    </li>
    <li><a href="#onnx-검증">ONNX 검증</a>
      <ul>
        <li><a href="#구조-확인">구조 확인</a></li>
        <li><a href="#netron으로-시각화">Netron으로 시각화</a></li>
      </ul>
    </li>
    <li><a href="#onnx-runtime-추론">ONNX Runtime 추론</a>
      <ul>
        <li><a href="#기본-추론">기본 추론</a></li>
        <li><a href="#성능-최적화">성능 최적화</a></li>
      </ul>
    </li>
    <li><a href="#동적-입력-처리">동적 입력 처리</a>
      <ul>
        <li><a href="#가변-배치-크기">가변 배치 크기</a></li>
        <li><a href="#가변-이미지-크기">가변 이미지 크기</a></li>
      </ul>
    </li>
    <li><a href="#일반적인-문제-해결">일반적인 문제 해결</a>
      <ul>
        <li><a href="#지원되지-않는-연산자">지원되지 않는 연산자</a></li>
        <li><a href="#동적-제어-흐름">동적 제어 흐름</a></li>
        <li><a href="#값-불일치">값 불일치</a></li>
      </ul>
    </li>
    <li><a href="#onnx-모델-최적화">ONNX 모델 최적화</a>
      <ul>
        <li><a href="#onnxoptimizer">onnxoptimizer</a></li>
        <li><a href="#onnx-simplifier">onnx-simplifier</a></li>
      </ul>
    </li>
    <li><a href="#벤치마크">벤치마크</a></li>
    <li><a href="#관련-콘텐츠">관련 콘텐츠</a></li>
  </ul>
</nav>



  </aside>
  
 
      </header>

      
      
  <article class="markdown book-article"><h1 id="onnx-open-neural-network-exchange">ONNX (Open Neural Network Exchange)<a class="anchor" href="#onnx-open-neural-network-exchange">#</a></h1>
<h2 id="개요">개요<a class="anchor" href="#%ea%b0%9c%ec%9a%94">#</a></h2>
<p>ONNX는 딥러닝 모델의 표준 교환 포맷입니다.</p>
<pre tabindex="0"><code>PyTorch    ─┐
TensorFlow ─┼──→ ONNX ──→ TensorRT / OpenVINO / CoreML / ...
Keras      ─┘</code></pre><hr>
<h2 id="pytorch--onnx-변환">PyTorch → ONNX 변환<a class="anchor" href="#pytorch--onnx-%eb%b3%80%ed%99%98">#</a></h2>
<h3 id="기본-변환">기본 변환<a class="anchor" href="#%ea%b8%b0%eb%b3%b8-%eb%b3%80%ed%99%98">#</a></h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">import</span> torch
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> torch.onnx
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>model <span style="color:#f92672">=</span> MyModel()
</span></span><span style="display:flex;"><span>model<span style="color:#f92672">.</span>load_state_dict(torch<span style="color:#f92672">.</span>load(<span style="color:#e6db74">&#39;model.pt&#39;</span>))
</span></span><span style="display:flex;"><span>model<span style="color:#f92672">.</span>eval()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 더미 입력 (모델 구조 추론용)</span>
</span></span><span style="display:flex;"><span>dummy_input <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>randn(<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">3</span>, <span style="color:#ae81ff">224</span>, <span style="color:#ae81ff">224</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># ONNX 변환</span>
</span></span><span style="display:flex;"><span>torch<span style="color:#f92672">.</span>onnx<span style="color:#f92672">.</span>export(
</span></span><span style="display:flex;"><span>    model,
</span></span><span style="display:flex;"><span>    dummy_input,
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;model.onnx&#34;</span>,
</span></span><span style="display:flex;"><span>    input_names<span style="color:#f92672">=</span>[<span style="color:#e6db74">&#39;input&#39;</span>],
</span></span><span style="display:flex;"><span>    output_names<span style="color:#f92672">=</span>[<span style="color:#e6db74">&#39;output&#39;</span>],
</span></span><span style="display:flex;"><span>    dynamic_axes<span style="color:#f92672">=</span>{
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#39;input&#39;</span>: {<span style="color:#ae81ff">0</span>: <span style="color:#e6db74">&#39;batch_size&#39;</span>},
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#39;output&#39;</span>: {<span style="color:#ae81ff">0</span>: <span style="color:#e6db74">&#39;batch_size&#39;</span>}
</span></span><span style="display:flex;"><span>    },
</span></span><span style="display:flex;"><span>    opset_version<span style="color:#f92672">=</span><span style="color:#ae81ff">17</span>,
</span></span><span style="display:flex;"><span>)</span></span></code></pre></div><h3 id="주요-파라미터">주요 파라미터<a class="anchor" href="#%ec%a3%bc%ec%9a%94-%ed%8c%8c%eb%9d%bc%eb%af%b8%ed%84%b0">#</a></h3>
<table>
  <thead>
      <tr>
          <th>파라미터</th>
          <th>설명</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td><code>input_names</code></td>
          <td>입력 텐서 이름</td>
      </tr>
      <tr>
          <td><code>output_names</code></td>
          <td>출력 텐서 이름</td>
      </tr>
      <tr>
          <td><code>dynamic_axes</code></td>
          <td>동적 차원 (배치 크기 등)</td>
      </tr>
      <tr>
          <td><code>opset_version</code></td>
          <td>ONNX 연산자 버전</td>
      </tr>
  </tbody>
</table>
<hr>
<h2 id="onnx-검증">ONNX 검증<a class="anchor" href="#onnx-%ea%b2%80%ec%a6%9d">#</a></h2>
<h3 id="구조-확인">구조 확인<a class="anchor" href="#%ea%b5%ac%ec%a1%b0-%ed%99%95%ec%9d%b8">#</a></h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">import</span> onnx
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 모델 로드 및 검증</span>
</span></span><span style="display:flex;"><span>model <span style="color:#f92672">=</span> onnx<span style="color:#f92672">.</span>load(<span style="color:#e6db74">&#34;model.onnx&#34;</span>)
</span></span><span style="display:flex;"><span>onnx<span style="color:#f92672">.</span>checker<span style="color:#f92672">.</span>check_model(model)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 그래프 정보</span>
</span></span><span style="display:flex;"><span>print(onnx<span style="color:#f92672">.</span>helper<span style="color:#f92672">.</span>printable_graph(model<span style="color:#f92672">.</span>graph))</span></span></code></pre></div><h3 id="netron으로-시각화">Netron으로 시각화<a class="anchor" href="#netron%ec%9c%bc%eb%a1%9c-%ec%8b%9c%ea%b0%81%ed%99%94">#</a></h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>pip install netron
</span></span><span style="display:flex;"><span>netron model.onnx</span></span></code></pre></div><hr>
<h2 id="onnx-runtime-추론">ONNX Runtime 추론<a class="anchor" href="#onnx-runtime-%ec%b6%94%eb%a1%a0">#</a></h2>
<h3 id="기본-추론">기본 추론<a class="anchor" href="#%ea%b8%b0%eb%b3%b8-%ec%b6%94%eb%a1%a0">#</a></h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">import</span> onnxruntime <span style="color:#66d9ef">as</span> ort
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> numpy <span style="color:#66d9ef">as</span> np
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 세션 생성</span>
</span></span><span style="display:flex;"><span>session <span style="color:#f92672">=</span> ort<span style="color:#f92672">.</span>InferenceSession(
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;model.onnx&#34;</span>,
</span></span><span style="display:flex;"><span>    providers<span style="color:#f92672">=</span>[<span style="color:#e6db74">&#39;CUDAExecutionProvider&#39;</span>, <span style="color:#e6db74">&#39;CPUExecutionProvider&#39;</span>]
</span></span><span style="display:flex;"><span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 입력 정보</span>
</span></span><span style="display:flex;"><span>input_name <span style="color:#f92672">=</span> session<span style="color:#f92672">.</span>get_inputs()[<span style="color:#ae81ff">0</span>]<span style="color:#f92672">.</span>name
</span></span><span style="display:flex;"><span>output_name <span style="color:#f92672">=</span> session<span style="color:#f92672">.</span>get_outputs()[<span style="color:#ae81ff">0</span>]<span style="color:#f92672">.</span>name
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 추론</span>
</span></span><span style="display:flex;"><span>input_data <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>random<span style="color:#f92672">.</span>randn(<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">3</span>, <span style="color:#ae81ff">224</span>, <span style="color:#ae81ff">224</span>)<span style="color:#f92672">.</span>astype(np<span style="color:#f92672">.</span>float32)
</span></span><span style="display:flex;"><span>result <span style="color:#f92672">=</span> session<span style="color:#f92672">.</span>run([output_name], {input_name: input_data})</span></span></code></pre></div><h3 id="성능-최적화">성능 최적화<a class="anchor" href="#%ec%84%b1%eb%8a%a5-%ec%b5%9c%ec%a0%81%ed%99%94">#</a></h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># 세션 옵션</span>
</span></span><span style="display:flex;"><span>sess_options <span style="color:#f92672">=</span> ort<span style="color:#f92672">.</span>SessionOptions()
</span></span><span style="display:flex;"><span>sess_options<span style="color:#f92672">.</span>graph_optimization_level <span style="color:#f92672">=</span> ort<span style="color:#f92672">.</span>GraphOptimizationLevel<span style="color:#f92672">.</span>ORT_ENABLE_ALL
</span></span><span style="display:flex;"><span>sess_options<span style="color:#f92672">.</span>intra_op_num_threads <span style="color:#f92672">=</span> <span style="color:#ae81ff">4</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># GPU 옵션</span>
</span></span><span style="display:flex;"><span>providers <span style="color:#f92672">=</span> [
</span></span><span style="display:flex;"><span>    (<span style="color:#e6db74">&#39;CUDAExecutionProvider&#39;</span>, {
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#39;device_id&#39;</span>: <span style="color:#ae81ff">0</span>,
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#39;arena_extend_strategy&#39;</span>: <span style="color:#e6db74">&#39;kNextPowerOfTwo&#39;</span>,
</span></span><span style="display:flex;"><span>    }),
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#39;CPUExecutionProvider&#39;</span>
</span></span><span style="display:flex;"><span>]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>session <span style="color:#f92672">=</span> ort<span style="color:#f92672">.</span>InferenceSession(<span style="color:#e6db74">&#34;model.onnx&#34;</span>, sess_options, providers<span style="color:#f92672">=</span>providers)</span></span></code></pre></div><hr>
<h2 id="동적-입력-처리">동적 입력 처리<a class="anchor" href="#%eb%8f%99%ec%a0%81-%ec%9e%85%eb%a0%a5-%ec%b2%98%eb%a6%ac">#</a></h2>
<h3 id="가변-배치-크기">가변 배치 크기<a class="anchor" href="#%ea%b0%80%eb%b3%80-%eb%b0%b0%ec%b9%98-%ed%81%ac%ea%b8%b0">#</a></h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>torch<span style="color:#f92672">.</span>onnx<span style="color:#f92672">.</span>export(
</span></span><span style="display:flex;"><span>    model,
</span></span><span style="display:flex;"><span>    dummy_input,
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;model.onnx&#34;</span>,
</span></span><span style="display:flex;"><span>    dynamic_axes<span style="color:#f92672">=</span>{
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#39;input&#39;</span>: {<span style="color:#ae81ff">0</span>: <span style="color:#e6db74">&#39;batch&#39;</span>},
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#39;output&#39;</span>: {<span style="color:#ae81ff">0</span>: <span style="color:#e6db74">&#39;batch&#39;</span>}
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>)</span></span></code></pre></div><h3 id="가변-이미지-크기">가변 이미지 크기<a class="anchor" href="#%ea%b0%80%eb%b3%80-%ec%9d%b4%eb%af%b8%ec%a7%80-%ed%81%ac%ea%b8%b0">#</a></h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>torch<span style="color:#f92672">.</span>onnx<span style="color:#f92672">.</span>export(
</span></span><span style="display:flex;"><span>    model,
</span></span><span style="display:flex;"><span>    dummy_input,
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;model.onnx&#34;</span>,
</span></span><span style="display:flex;"><span>    dynamic_axes<span style="color:#f92672">=</span>{
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#39;input&#39;</span>: {<span style="color:#ae81ff">0</span>: <span style="color:#e6db74">&#39;batch&#39;</span>, <span style="color:#ae81ff">2</span>: <span style="color:#e6db74">&#39;height&#39;</span>, <span style="color:#ae81ff">3</span>: <span style="color:#e6db74">&#39;width&#39;</span>},
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#39;output&#39;</span>: {<span style="color:#ae81ff">0</span>: <span style="color:#e6db74">&#39;batch&#39;</span>}
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>)</span></span></code></pre></div><hr>
<h2 id="일반적인-문제-해결">일반적인 문제 해결<a class="anchor" href="#%ec%9d%bc%eb%b0%98%ec%a0%81%ec%9d%b8-%eb%ac%b8%ec%a0%9c-%ed%95%b4%ea%b2%b0">#</a></h2>
<h3 id="지원되지-않는-연산자">지원되지 않는 연산자<a class="anchor" href="#%ec%a7%80%ec%9b%90%eb%90%98%ec%a7%80-%ec%95%8a%eb%8a%94-%ec%97%b0%ec%82%b0%ec%9e%90">#</a></h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># 커스텀 연산자 등록</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> torch.onnx <span style="color:#f92672">import</span> register_custom_op_symbolic
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">my_custom_op</span>(g, input):
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> g<span style="color:#f92672">.</span>op(<span style="color:#e6db74">&#34;CustomOp&#34;</span>, input)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>register_custom_op_symbolic(<span style="color:#e6db74">&#39;my_custom_op&#39;</span>, my_custom_op, opset_version<span style="color:#f92672">=</span><span style="color:#ae81ff">11</span>)</span></span></code></pre></div><h3 id="동적-제어-흐름">동적 제어 흐름<a class="anchor" href="#%eb%8f%99%ec%a0%81-%ec%a0%9c%ec%96%b4-%ed%9d%90%eb%a6%84">#</a></h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># torch.jit.script 사용</span>
</span></span><span style="display:flex;"><span><span style="color:#a6e22e">@torch.jit.script</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">my_function</span>(x):
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">if</span> x<span style="color:#f92672">.</span>sum() <span style="color:#f92672">&gt;</span> <span style="color:#ae81ff">0</span>:
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">return</span> x <span style="color:#f92672">*</span> <span style="color:#ae81ff">2</span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> x
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 또는 조건부 로직 제거</span></span></span></code></pre></div><h3 id="값-불일치">값 불일치<a class="anchor" href="#%ea%b0%92-%eb%b6%88%ec%9d%bc%ec%b9%98">#</a></h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># PyTorch와 ONNX Runtime 출력 비교</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> numpy <span style="color:#66d9ef">as</span> np
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>torch_output <span style="color:#f92672">=</span> model(input_tensor)<span style="color:#f92672">.</span>detach()<span style="color:#f92672">.</span>numpy()
</span></span><span style="display:flex;"><span>onnx_output <span style="color:#f92672">=</span> session<span style="color:#f92672">.</span>run([output_name], {input_name: input_data})[<span style="color:#ae81ff">0</span>]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>np<span style="color:#f92672">.</span>testing<span style="color:#f92672">.</span>assert_allclose(torch_output, onnx_output, rtol<span style="color:#f92672">=</span><span style="color:#ae81ff">1e-3</span>, atol<span style="color:#f92672">=</span><span style="color:#ae81ff">1e-5</span>)</span></span></code></pre></div><hr>
<h2 id="onnx-모델-최적화">ONNX 모델 최적화<a class="anchor" href="#onnx-%eb%aa%a8%eb%8d%b8-%ec%b5%9c%ec%a0%81%ed%99%94">#</a></h2>
<h3 id="onnxoptimizer">onnxoptimizer<a class="anchor" href="#onnxoptimizer">#</a></h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">import</span> onnx
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> onnxoptimizer <span style="color:#f92672">import</span> optimize
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>model <span style="color:#f92672">=</span> onnx<span style="color:#f92672">.</span>load(<span style="color:#e6db74">&#34;model.onnx&#34;</span>)
</span></span><span style="display:flex;"><span>optimized_model <span style="color:#f92672">=</span> optimize(model, [
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#39;eliminate_deadend&#39;</span>,
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#39;eliminate_identity&#39;</span>,
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#39;fuse_consecutive_transposes&#39;</span>,
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#39;fuse_bn_into_conv&#39;</span>,
</span></span><span style="display:flex;"><span>])
</span></span><span style="display:flex;"><span>onnx<span style="color:#f92672">.</span>save(optimized_model, <span style="color:#e6db74">&#34;model_optimized.onnx&#34;</span>)</span></span></code></pre></div><h3 id="onnx-simplifier">onnx-simplifier<a class="anchor" href="#onnx-simplifier">#</a></h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>pip install onnx-simplifier
</span></span><span style="display:flex;"><span>onnxsim model.onnx model_simplified.onnx</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">import</span> onnx
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> onnxsim <span style="color:#f92672">import</span> simplify
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>model <span style="color:#f92672">=</span> onnx<span style="color:#f92672">.</span>load(<span style="color:#e6db74">&#34;model.onnx&#34;</span>)
</span></span><span style="display:flex;"><span>simplified_model, check <span style="color:#f92672">=</span> simplify(model)
</span></span><span style="display:flex;"><span>onnx<span style="color:#f92672">.</span>save(simplified_model, <span style="color:#e6db74">&#34;model_simplified.onnx&#34;</span>)</span></span></code></pre></div><hr>
<h2 id="벤치마크">벤치마크<a class="anchor" href="#%eb%b2%a4%ec%b9%98%eb%a7%88%ed%81%ac">#</a></h2>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">import</span> time
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> numpy <span style="color:#66d9ef">as</span> np
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 워밍업</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">for</span> _ <span style="color:#f92672">in</span> range(<span style="color:#ae81ff">10</span>):
</span></span><span style="display:flex;"><span>    session<span style="color:#f92672">.</span>run([output_name], {input_name: input_data})
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 측정</span>
</span></span><span style="display:flex;"><span>n_runs <span style="color:#f92672">=</span> <span style="color:#ae81ff">100</span>
</span></span><span style="display:flex;"><span>start <span style="color:#f92672">=</span> time<span style="color:#f92672">.</span>time()
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">for</span> _ <span style="color:#f92672">in</span> range(n_runs):
</span></span><span style="display:flex;"><span>    session<span style="color:#f92672">.</span>run([output_name], {input_name: input_data})
</span></span><span style="display:flex;"><span>elapsed <span style="color:#f92672">=</span> time<span style="color:#f92672">.</span>time() <span style="color:#f92672">-</span> start
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;Average latency: </span><span style="color:#e6db74">{</span>elapsed <span style="color:#f92672">/</span> n_runs <span style="color:#f92672">*</span> <span style="color:#ae81ff">1000</span><span style="color:#e6db74">:</span><span style="color:#e6db74">.2f</span><span style="color:#e6db74">}</span><span style="color:#e6db74"> ms&#34;</span>)
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;Throughput: </span><span style="color:#e6db74">{</span>n_runs <span style="color:#f92672">/</span> elapsed<span style="color:#e6db74">:</span><span style="color:#e6db74">.2f</span><span style="color:#e6db74">}</span><span style="color:#e6db74"> FPS&#34;</span>)</span></span></code></pre></div><hr>
<h2 id="관련-콘텐츠">관련 콘텐츠<a class="anchor" href="#%ea%b4%80%eb%a0%a8-%ec%bd%98%ed%85%90%ec%b8%a0">#</a></h2>
<ul>
<li><a href="/ko/docs/engineering/deployment/tensorrt">TensorRT</a> - GPU 최적화</li>
<li><a href="/ko/docs/engineering/deployment/serving">모델 서빙</a> - 추론 서버</li>
<li><a href="/ko/docs/engineering/deployment/optimization">최적화</a> - 양자화</li>
</ul>
</article>
 
      

      <footer class="book-footer">
        
  <div class="flex flex-wrap justify-between">

<div>

</div>

<div>

</div>

</div>





  
  
  
  <div class="flex flex-wrap justify-between">
    <span>
    
      <a href="/ko/docs/engineering/deployment/" class="flex align-center">
        <img src="/icons/backward.svg" class="book-icon" alt="Backward" />
        <span>배포</span>
      </a>
    
    </span>
    <span>
    
      <a href="/ko/docs/engineering/deployment/tensorrt/" class="flex align-center">
        <span>TensorRT</span>
        <img src="/icons/forward.svg" class="book-icon" alt="Forward" />
      </a>
    
    </span>
  </div>
  


 
        
  
  <div class="book-comments">

</div>
  
 
        
        
  
 
        
  
  
    <script>(function(){document.querySelectorAll("pre:has(code)").forEach(e=>{e.addEventListener("click",e.focus),e.addEventListener("copy",function(t){if(t.preventDefault(),navigator.clipboard){const t=window.getSelection().toString()||e.textContent;navigator.clipboard.writeText(t)}})})})()</script>
  

      </footer>

      <label for="menu-control" class="hidden book-menu-overlay"></label>
    </div>

    
  
  <aside class="book-toc">
    <div class="book-toc-content">
      
  
<nav id="TableOfContents">
  <ul>
    <li><a href="#개요">개요</a></li>
    <li><a href="#pytorch--onnx-변환">PyTorch → ONNX 변환</a>
      <ul>
        <li><a href="#기본-변환">기본 변환</a></li>
        <li><a href="#주요-파라미터">주요 파라미터</a></li>
      </ul>
    </li>
    <li><a href="#onnx-검증">ONNX 검증</a>
      <ul>
        <li><a href="#구조-확인">구조 확인</a></li>
        <li><a href="#netron으로-시각화">Netron으로 시각화</a></li>
      </ul>
    </li>
    <li><a href="#onnx-runtime-추론">ONNX Runtime 추론</a>
      <ul>
        <li><a href="#기본-추론">기본 추론</a></li>
        <li><a href="#성능-최적화">성능 최적화</a></li>
      </ul>
    </li>
    <li><a href="#동적-입력-처리">동적 입력 처리</a>
      <ul>
        <li><a href="#가변-배치-크기">가변 배치 크기</a></li>
        <li><a href="#가변-이미지-크기">가변 이미지 크기</a></li>
      </ul>
    </li>
    <li><a href="#일반적인-문제-해결">일반적인 문제 해결</a>
      <ul>
        <li><a href="#지원되지-않는-연산자">지원되지 않는 연산자</a></li>
        <li><a href="#동적-제어-흐름">동적 제어 흐름</a></li>
        <li><a href="#값-불일치">값 불일치</a></li>
      </ul>
    </li>
    <li><a href="#onnx-모델-최적화">ONNX 모델 최적화</a>
      <ul>
        <li><a href="#onnxoptimizer">onnxoptimizer</a></li>
        <li><a href="#onnx-simplifier">onnx-simplifier</a></li>
      </ul>
    </li>
    <li><a href="#벤치마크">벤치마크</a></li>
    <li><a href="#관련-콘텐츠">관련 콘텐츠</a></li>
  </ul>
</nav>



    </div>
  </aside>
  
 
  </main>

  
</body>
</html>




















