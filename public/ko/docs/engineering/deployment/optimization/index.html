<!DOCTYPE html>
<html lang="ko-KR" dir="ltr">
<head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script>
  <!--
Made with Book Theme
https://github.com/alex-shpak/hugo-book
-->

<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="description" content="모델 최적화# 개요# 모델 크기와 추론 속도를 개선하는 기법들입니다.
최적화 기법 분류# 기법 설명 정확도 영향 양자화 비트 수 줄임 (FP32→INT8) 약간 감소 프루닝 불필요한 가중치 제거 약간 감소 Knowledge Distillation 작은 모델에 지식 전달 가능한 한 유지 아키텍처 최적화 효율적 구조 설계 설계에 따라 다름 양자화 (Quantization)# 종류# 방식 설명 특징 PTQ Post-Training Quantization 빠름, 약간의 정확도 손실 QAT Quantization-Aware Training 느림, 정확도 유지 Dynamic 추론 시 동적 양자화 간단, 제한적 성능 향상 PyTorch 동적 양자화# import torch.quantization # 동적 양자화 (주로 Linear, LSTM에 효과적) model_quantized = torch.quantization.quantize_dynamic( model, {torch.nn.Linear}, dtype=torch.qint8 )PyTorch 정적 양자화 (PTQ)# import torch.quantization model.eval() # 양자화 설정 model.qconfig = torch.quantization.get_default_qconfig(&#39;fbgemm&#39;) # 퓨전 (Conv &#43; BN &#43; ReLU) model_fused = torch.quantization.fuse_modules(model, [[&#39;conv&#39;, &#39;bn&#39;, &#39;relu&#39;]]) # 준비 model_prepared = torch.quantization.prepare(model_fused) # 캘리브레이션 (대표 데이터로) with torch.no_grad(): for data in calibration_loader: model_prepared(data) # 변환 model_quantized = torch.quantization.convert(model_prepared)QAT (Quantization-Aware Training)# # 준비 model.train() model.qconfig = torch.quantization.get_default_qat_qconfig(&#39;fbgemm&#39;) model_prepared = torch.quantization.prepare_qat(model) # 학습 (fake quantization 포함) for epoch in range(epochs): for data, target in train_loader: output = model_prepared(data) loss = criterion(output, target) loss.backward() optimizer.step() # 변환 model_prepared.eval() model_quantized = torch.quantization.convert(model_prepared) 프루닝 (Pruning)# 비구조적 프루닝# 개별 가중치 제거:
">
<meta name="theme-color" media="(prefers-color-scheme: light)" content="#ffffff">
<meta name="theme-color" media="(prefers-color-scheme: dark)" content="#343a40">
<meta name="color-scheme" content="light dark"><meta property="og:url" content="http://localhost:1313/ko/docs/engineering/deployment/optimization/">
  <meta property="og:site_name" content="Vision Engineer 지식 가이드">
  <meta property="og:title" content="모델 최적화">
  <meta property="og:description" content="모델 최적화# 개요# 모델 크기와 추론 속도를 개선하는 기법들입니다.
최적화 기법 분류# 기법 설명 정확도 영향 양자화 비트 수 줄임 (FP32→INT8) 약간 감소 프루닝 불필요한 가중치 제거 약간 감소 Knowledge Distillation 작은 모델에 지식 전달 가능한 한 유지 아키텍처 최적화 효율적 구조 설계 설계에 따라 다름 양자화 (Quantization)# 종류# 방식 설명 특징 PTQ Post-Training Quantization 빠름, 약간의 정확도 손실 QAT Quantization-Aware Training 느림, 정확도 유지 Dynamic 추론 시 동적 양자화 간단, 제한적 성능 향상 PyTorch 동적 양자화# import torch.quantization # 동적 양자화 (주로 Linear, LSTM에 효과적) model_quantized = torch.quantization.quantize_dynamic( model, {torch.nn.Linear}, dtype=torch.qint8 )PyTorch 정적 양자화 (PTQ)# import torch.quantization model.eval() # 양자화 설정 model.qconfig = torch.quantization.get_default_qconfig(&#39;fbgemm&#39;) # 퓨전 (Conv &#43; BN &#43; ReLU) model_fused = torch.quantization.fuse_modules(model, [[&#39;conv&#39;, &#39;bn&#39;, &#39;relu&#39;]]) # 준비 model_prepared = torch.quantization.prepare(model_fused) # 캘리브레이션 (대표 데이터로) with torch.no_grad(): for data in calibration_loader: model_prepared(data) # 변환 model_quantized = torch.quantization.convert(model_prepared)QAT (Quantization-Aware Training)# # 준비 model.train() model.qconfig = torch.quantization.get_default_qat_qconfig(&#39;fbgemm&#39;) model_prepared = torch.quantization.prepare_qat(model) # 학습 (fake quantization 포함) for epoch in range(epochs): for data, target in train_loader: output = model_prepared(data) loss = criterion(output, target) loss.backward() optimizer.step() # 변환 model_prepared.eval() model_quantized = torch.quantization.convert(model_prepared) 프루닝 (Pruning)# 비구조적 프루닝# 개별 가중치 제거:">
  <meta property="og:locale" content="ko_KR">
  <meta property="og:type" content="article">
    <meta property="article:section" content="docs">


  <meta itemprop="name" content="모델 최적화">
  <meta itemprop="description" content="모델 최적화# 개요# 모델 크기와 추론 속도를 개선하는 기법들입니다.
최적화 기법 분류# 기법 설명 정확도 영향 양자화 비트 수 줄임 (FP32→INT8) 약간 감소 프루닝 불필요한 가중치 제거 약간 감소 Knowledge Distillation 작은 모델에 지식 전달 가능한 한 유지 아키텍처 최적화 효율적 구조 설계 설계에 따라 다름 양자화 (Quantization)# 종류# 방식 설명 특징 PTQ Post-Training Quantization 빠름, 약간의 정확도 손실 QAT Quantization-Aware Training 느림, 정확도 유지 Dynamic 추론 시 동적 양자화 간단, 제한적 성능 향상 PyTorch 동적 양자화# import torch.quantization # 동적 양자화 (주로 Linear, LSTM에 효과적) model_quantized = torch.quantization.quantize_dynamic( model, {torch.nn.Linear}, dtype=torch.qint8 )PyTorch 정적 양자화 (PTQ)# import torch.quantization model.eval() # 양자화 설정 model.qconfig = torch.quantization.get_default_qconfig(&#39;fbgemm&#39;) # 퓨전 (Conv &#43; BN &#43; ReLU) model_fused = torch.quantization.fuse_modules(model, [[&#39;conv&#39;, &#39;bn&#39;, &#39;relu&#39;]]) # 준비 model_prepared = torch.quantization.prepare(model_fused) # 캘리브레이션 (대표 데이터로) with torch.no_grad(): for data in calibration_loader: model_prepared(data) # 변환 model_quantized = torch.quantization.convert(model_prepared)QAT (Quantization-Aware Training)# # 준비 model.train() model.qconfig = torch.quantization.get_default_qat_qconfig(&#39;fbgemm&#39;) model_prepared = torch.quantization.prepare_qat(model) # 학습 (fake quantization 포함) for epoch in range(epochs): for data, target in train_loader: output = model_prepared(data) loss = criterion(output, target) loss.backward() optimizer.step() # 변환 model_prepared.eval() model_quantized = torch.quantization.convert(model_prepared) 프루닝 (Pruning)# 비구조적 프루닝# 개별 가중치 제거:">
  <meta itemprop="wordCount" content="603">

<title>모델 최적화 | Vision Engineer 지식 가이드</title>
<link rel="icon" href="/favicon.png" >
<link rel="manifest" href="/manifest.json">
<link rel="canonical" href="http://localhost:1313/ko/docs/engineering/deployment/optimization/">
<link rel="stylesheet" href="/book.min.6970156cec683193d93c9c4edaf0d56574e4361df2e0c1be4f697ae81c3ba55f.css" integrity="sha256-aXAVbOxoMZPZPJxO2vDVZXTkNh3y4MG&#43;T2l66Bw7pV8=" crossorigin="anonymous">


  <script defer src="/fuse.min.js"></script>
  <script defer src="/ko.search.min.e521ced8a1de353f186f5733d176d23d7236b1309fd3a485d880dd5743b5a505.js" integrity="sha256-5SHO2KHeNT8Yb1cz0XbSPXI2sTCf06SF2IDdV0O1pQU=" crossorigin="anonymous"></script>



  <link rel="stylesheet" href="/katex/katex.min.css" />
<script defer src="/katex/katex.min.js"></script><script defer src="/katex/auto-render.min.js" onload="renderMathInElement(document.body, {&#34;delimiters&#34;:[{&#34;left&#34;:&#34;$$&#34;,&#34;right&#34;:&#34;$$&#34;,&#34;display&#34;:true},{&#34;left&#34;:&#34;\\(&#34;,&#34;right&#34;:&#34;\\)&#34;,&#34;display&#34;:false},{&#34;left&#34;:&#34;\\[&#34;,&#34;right&#34;:&#34;\\]&#34;,&#34;display&#34;:true}]});"></script>
</head>
<body dir="ltr" class="book-kind-page book-type-docs">
  <input type="checkbox" class="hidden toggle" id="menu-control" />
  <input type="checkbox" class="hidden toggle" id="toc-control" />
  <main class="container flex">
    
<aside class="book-menu">
  <div class="book-menu-content">
    
  <nav>
<h2 class="book-brand">
  <a class="flex align-center" href="/ko/"><span>Vision Engineer 지식 가이드</span>
  </a>
</h2>


<div class="book-search hidden">
  <input id="book-search-input" type="text" 
    placeholder="Search"
    aria-label="Search"
    maxlength="64" data-hotkeys="s/" />
  <div class="book-search-spinner hidden"></div>
  <ul id="book-search-results"></ul>
</div>
<script>document.querySelector(".book-search").classList.remove("hidden")</script>



  


  
    
  



<ul class="book-languages">
  <li>
    <input type="checkbox" id="languages" class="toggle" />
    <label for="languages" class="flex">
      <a role="button">
        <img src="/icons/translate.svg" class="book-icon" alt="Languages" />
        한국어
      </a>
      <img src="/icons/chevron-right.svg" class="book-icon" alt="Expand" />
    </label>

    <ul>
      
      <li>
        <a href="/" class="flex flex-auto">
          English
        </a>
      </li>
      
    </ul>
  </li>
</ul>












  
  <ul>
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-14bcba7439f342435c91a57530ca56c8" class="toggle"  />
    <label for="section-14bcba7439f342435c91a57530ca56c8" class="flex">
      <a href="/ko/docs/timeline/" class="">
        타임라인</a>
      <img src="/icons/chevron-right.svg" class="book-icon" alt="Expand" />
    </label>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-cb9657695dbd536c3a44d019c4d6ef98" class="toggle"  />
    <label for="section-cb9657695dbd536c3a44d019c4d6ef98" class="flex">
      <a href="/ko/docs/topdown/" class="">
        Top-Down</a>
      <img src="/icons/chevron-right.svg" class="book-icon" alt="Expand" />
    </label>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-e7f22db027b1c591ed84a4d4d3a6014f" class="toggle"  />
    <label for="section-e7f22db027b1c591ed84a4d4d3a6014f" class="flex">
      <a href="/ko/docs/bottomup/" class="">
        Bottom-Up</a>
      <img src="/icons/chevron-right.svg" class="book-icon" alt="Expand" />
    </label>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-ce31bba1d1f88a1d133a7e7232f1b4ec" class="toggle"  />
    <label for="section-ce31bba1d1f88a1d133a7e7232f1b4ec" class="flex">
      <a href="/ko/docs/math/" class="">
        수학</a>
      <img src="/icons/chevron-right.svg" class="book-icon" alt="Expand" />
    </label>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-b7c22078b221fa1e5fe6dba5f036e317" class="toggle" checked />
    <label for="section-b7c22078b221fa1e5fe6dba5f036e317" class="flex">
      <a href="/ko/docs/engineering/" class="">
        실무 기술</a>
      <img src="/icons/chevron-right.svg" class="book-icon" alt="Expand" />
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-41bc70f3b465f23cc6f68dbb9cf6930e" class="toggle"  />
    <label for="section-41bc70f3b465f23cc6f68dbb9cf6930e" class="flex">
      <a href="/ko/docs/engineering/data/" class="">
        데이터</a>
      <img src="/icons/chevron-right.svg" class="book-icon" alt="Expand" />
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/ko/docs/engineering/data/augmentation/" class="">
      데이터 증강</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/ko/docs/engineering/data/formats/" class="">
      데이터 포맷</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/ko/docs/engineering/data/pipeline/" class="">
      데이터 파이프라인</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/ko/docs/engineering/data/labeling/" class="">
      레이블링</a>
  

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-08b7417cd9477b9be27e6c7b561a01bc" class="toggle" checked />
    <label for="section-08b7417cd9477b9be27e6c7b561a01bc" class="flex">
      <a href="/ko/docs/engineering/deployment/" class="">
        배포</a>
      <img src="/icons/chevron-right.svg" class="book-icon" alt="Expand" />
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/ko/docs/engineering/deployment/onnx/" class="">
      ONNX</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/ko/docs/engineering/deployment/tensorrt/" class="">
      TensorRT</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/ko/docs/engineering/deployment/serving/" class="">
      모델 서빙</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/ko/docs/engineering/deployment/optimization/" class="active">
      모델 최적화</a>
  

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-d367cbc8b1f6018b8f46a12cb86b41d6" class="toggle"  />
    <label for="section-d367cbc8b1f6018b8f46a12cb86b41d6" class="flex">
      <a href="/ko/docs/engineering/hardware/" class="">
        하드웨어</a>
      <img src="/icons/chevron-right.svg" class="book-icon" alt="Expand" />
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/ko/docs/engineering/hardware/camera/" class="">
      카메라</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/ko/docs/engineering/hardware/lighting/" class="">
      조명</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/ko/docs/engineering/hardware/edge/" class="">
      엣지 디바이스</a>
  

        </li>
      
    
  </ul>

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-32f2aee524dad19f5100855d6e2014e6" class="toggle"  />
    <label for="section-32f2aee524dad19f5100855d6e2014e6" class="flex">
      <a href="/ko/docs/architecture/" class="">
        아키텍처</a>
      <img src="/icons/chevron-right.svg" class="book-icon" alt="Expand" />
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-47444199c3019e8b479623bc90a9bd74" class="toggle"  />
    <label for="section-47444199c3019e8b479623bc90a9bd74" class="flex">
      <a href="/ko/docs/architecture/classical/" class="">
        Classical CV</a>
      <img src="/icons/chevron-right.svg" class="book-icon" alt="Expand" />
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/ko/docs/architecture/classical/sift-hog/" class="">
      SIFT &amp; HOG</a>
  

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-7bf44239f7ce2c72600738f8c315efe4" class="toggle"  />
    <label for="section-7bf44239f7ce2c72600738f8c315efe4" class="flex">
      <a href="/ko/docs/architecture/cnn/" class="">
        CNN</a>
      <img src="/icons/chevron-right.svg" class="book-icon" alt="Expand" />
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/ko/docs/architecture/cnn/alexnet/" class="">
      AlexNet</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/ko/docs/architecture/cnn/vgg/" class="">
      VGG</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/ko/docs/architecture/cnn/resnet/" class="">
      ResNet</a>
  

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-274b800b12326ef4e06255cf5f15c308" class="toggle"  />
    <label for="section-274b800b12326ef4e06255cf5f15c308" class="flex">
      <a href="/ko/docs/architecture/detection/" class="">
        Detection</a>
      <img src="/icons/chevron-right.svg" class="book-icon" alt="Expand" />
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/ko/docs/architecture/detection/faster-rcnn/" class="">
      Faster R-CNN</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/ko/docs/architecture/detection/yolo/" class="">
      YOLO</a>
  

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-7246e67fd6c549f3bd6240d998b23a6f" class="toggle"  />
    <label for="section-7246e67fd6c549f3bd6240d998b23a6f" class="flex">
      <a href="/ko/docs/architecture/segmentation/" class="">
        Segmentation</a>
      <img src="/icons/chevron-right.svg" class="book-icon" alt="Expand" />
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/ko/docs/architecture/segmentation/unet/" class="">
      U-Net</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/ko/docs/architecture/segmentation/mask-rcnn/" class="">
      Mask R-CNN</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/ko/docs/architecture/segmentation/sam/" class="">
      SAM</a>
  

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-3a9f4e0826e1b9e72550db30b2adcad7" class="toggle"  />
    <label for="section-3a9f4e0826e1b9e72550db30b2adcad7" class="flex">
      <a href="/ko/docs/architecture/transformer/" class="">
        Transformer</a>
      <img src="/icons/chevron-right.svg" class="book-icon" alt="Expand" />
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/ko/docs/architecture/transformer/vit/" class="">
      ViT</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/ko/docs/architecture/transformer/dit/" class="">
      DiT</a>
  

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-2902afa0a62febfd7a5eb243df871e8c" class="toggle"  />
    <label for="section-2902afa0a62febfd7a5eb243df871e8c" class="flex">
      <a href="/ko/docs/architecture/generative/" class="">
        Generative</a>
      <img src="/icons/chevron-right.svg" class="book-icon" alt="Expand" />
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/ko/docs/architecture/generative/vae/" class="">
      VAE</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/ko/docs/architecture/generative/gan/" class="">
      GAN</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/ko/docs/architecture/generative/stable-diffusion/" class="">
      Stable Diffusion</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/ko/docs/architecture/generative/controlnet/" class="">
      ControlNet</a>
  

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-1670f136e85bf39bce97c9ee224d29d9" class="toggle"  />
    <label for="section-1670f136e85bf39bce97c9ee224d29d9" class="flex">
      <a href="/ko/docs/architecture/multimodal/" class="">
        Multimodal</a>
      <img src="/icons/chevron-right.svg" class="book-icon" alt="Expand" />
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/ko/docs/architecture/multimodal/clip/" class="">
      CLIP</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/ko/docs/architecture/multimodal/vlm/" class="">
      VLM</a>
  

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-fc1b0b4545ce791b47ab3fe55b854e56" class="toggle"  />
    <label for="section-fc1b0b4545ce791b47ab3fe55b854e56" class="flex">
      <a href="/ko/docs/architecture/3d/" class="">
        3D Vision</a>
      <img src="/icons/chevron-right.svg" class="book-icon" alt="Expand" />
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/ko/docs/architecture/3d/nerf/" class="">
      NeRF</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/ko/docs/architecture/3d/3dgs/" class="">
      3D Gaussian Splatting</a>
  

        </li>
      
    
  </ul>

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-cd575cc6fd4e25b684b552791b7a009a" class="toggle"  />
    <label for="section-cd575cc6fd4e25b684b552791b7a009a" class="flex">
      <a href="/ko/docs/task/" class="">
        태스크</a>
      <img src="/icons/chevron-right.svg" class="book-icon" alt="Expand" />
    </label>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-fb690f19903e1435676f710c928c9ad4" class="toggle"  />
    <label for="section-fb690f19903e1435676f710c928c9ad4" class="flex">
      <a href="/ko/docs/etc/" class="">
        기타 자료</a>
      <img src="/icons/chevron-right.svg" class="book-icon" alt="Expand" />
    </label>
  

          
  <ul>
    
  </ul>

        </li>
      
    
  </ul>













</nav>




  <script>(function(){var e=document.querySelector("aside .book-menu-content");addEventListener("beforeunload",function(){localStorage.setItem("menu.scrollTop",e.scrollTop)}),e.scrollTop=localStorage.getItem("menu.scrollTop")})()</script>



  </div>
</aside>
 

    <div class="book-page">
      <header class="book-header hidden">
        
  <div class="flex align-center justify-between">
  <label for="menu-control">
    <img src="/icons/menu.svg" class="book-icon" alt="Menu" />
  </label>

  <h3>모델 최적화</h3>

  <label for="toc-control">
    
    <img src="/icons/toc.svg" class="book-icon" alt="Table of Contents" />
    
  </label>
</div>


  
  <aside class="hidden">
    
  
<nav id="TableOfContents">
  <ul>
    <li><a href="#개요">개요</a></li>
    <li><a href="#최적화-기법-분류">최적화 기법 분류</a></li>
    <li><a href="#양자화-quantization">양자화 (Quantization)</a>
      <ul>
        <li><a href="#종류">종류</a></li>
        <li><a href="#pytorch-동적-양자화">PyTorch 동적 양자화</a></li>
        <li><a href="#pytorch-정적-양자화-ptq">PyTorch 정적 양자화 (PTQ)</a></li>
        <li><a href="#qat-quantization-aware-training">QAT (Quantization-Aware Training)</a></li>
      </ul>
    </li>
    <li><a href="#프루닝-pruning">프루닝 (Pruning)</a>
      <ul>
        <li><a href="#비구조적-프루닝">비구조적 프루닝</a></li>
        <li><a href="#구조적-프루닝">구조적 프루닝</a></li>
        <li><a href="#글로벌-프루닝">글로벌 프루닝</a></li>
      </ul>
    </li>
    <li><a href="#knowledge-distillation">Knowledge Distillation</a>
      <ul>
        <li><a href="#기본-구조">기본 구조</a></li>
        <li><a href="#구현">구현</a></li>
      </ul>
    </li>
    <li><a href="#효율적인-아키텍처">효율적인 아키텍처</a>
      <ul>
        <li><a href="#mobilenet">MobileNet</a></li>
        <li><a href="#efficientnet">EfficientNet</a></li>
      </ul>
    </li>
    <li><a href="#혼합-정밀도-학습">혼합 정밀도 학습</a></li>
    <li><a href="#최적화-파이프라인">최적화 파이프라인</a></li>
    <li><a href="#성능-측정">성능 측정</a>
      <ul>
        <li><a href="#모델-크기-측정">모델 크기 측정</a></li>
      </ul>
    </li>
    <li><a href="#관련-콘텐츠">관련 콘텐츠</a></li>
  </ul>
</nav>



  </aside>
  
 
      </header>

      
      
  <article class="markdown book-article"><h1 id="모델-최적화">모델 최적화<a class="anchor" href="#%eb%aa%a8%eb%8d%b8-%ec%b5%9c%ec%a0%81%ed%99%94">#</a></h1>
<h2 id="개요">개요<a class="anchor" href="#%ea%b0%9c%ec%9a%94">#</a></h2>
<p>모델 크기와 추론 속도를 개선하는 기법들입니다.</p>
<hr>
<h2 id="최적화-기법-분류">최적화 기법 분류<a class="anchor" href="#%ec%b5%9c%ec%a0%81%ed%99%94-%ea%b8%b0%eb%b2%95-%eb%b6%84%eb%a5%98">#</a></h2>
<table>
  <thead>
      <tr>
          <th>기법</th>
          <th>설명</th>
          <th>정확도 영향</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td><strong>양자화</strong></td>
          <td>비트 수 줄임 (FP32→INT8)</td>
          <td>약간 감소</td>
      </tr>
      <tr>
          <td><strong>프루닝</strong></td>
          <td>불필요한 가중치 제거</td>
          <td>약간 감소</td>
      </tr>
      <tr>
          <td><strong>Knowledge Distillation</strong></td>
          <td>작은 모델에 지식 전달</td>
          <td>가능한 한 유지</td>
      </tr>
      <tr>
          <td><strong>아키텍처 최적화</strong></td>
          <td>효율적 구조 설계</td>
          <td>설계에 따라 다름</td>
      </tr>
  </tbody>
</table>
<hr>
<h2 id="양자화-quantization">양자화 (Quantization)<a class="anchor" href="#%ec%96%91%ec%9e%90%ed%99%94-quantization">#</a></h2>
<h3 id="종류">종류<a class="anchor" href="#%ec%a2%85%eb%a5%98">#</a></h3>
<table>
  <thead>
      <tr>
          <th>방식</th>
          <th>설명</th>
          <th>특징</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td><strong>PTQ</strong></td>
          <td>Post-Training Quantization</td>
          <td>빠름, 약간의 정확도 손실</td>
      </tr>
      <tr>
          <td><strong>QAT</strong></td>
          <td>Quantization-Aware Training</td>
          <td>느림, 정확도 유지</td>
      </tr>
      <tr>
          <td><strong>Dynamic</strong></td>
          <td>추론 시 동적 양자화</td>
          <td>간단, 제한적 성능 향상</td>
      </tr>
  </tbody>
</table>
<h3 id="pytorch-동적-양자화">PyTorch 동적 양자화<a class="anchor" href="#pytorch-%eb%8f%99%ec%a0%81-%ec%96%91%ec%9e%90%ed%99%94">#</a></h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">import</span> torch.quantization
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 동적 양자화 (주로 Linear, LSTM에 효과적)</span>
</span></span><span style="display:flex;"><span>model_quantized <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>quantization<span style="color:#f92672">.</span>quantize_dynamic(
</span></span><span style="display:flex;"><span>    model,
</span></span><span style="display:flex;"><span>    {torch<span style="color:#f92672">.</span>nn<span style="color:#f92672">.</span>Linear},
</span></span><span style="display:flex;"><span>    dtype<span style="color:#f92672">=</span>torch<span style="color:#f92672">.</span>qint8
</span></span><span style="display:flex;"><span>)</span></span></code></pre></div><h3 id="pytorch-정적-양자화-ptq">PyTorch 정적 양자화 (PTQ)<a class="anchor" href="#pytorch-%ec%a0%95%ec%a0%81-%ec%96%91%ec%9e%90%ed%99%94-ptq">#</a></h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">import</span> torch.quantization
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>model<span style="color:#f92672">.</span>eval()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 양자화 설정</span>
</span></span><span style="display:flex;"><span>model<span style="color:#f92672">.</span>qconfig <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>quantization<span style="color:#f92672">.</span>get_default_qconfig(<span style="color:#e6db74">&#39;fbgemm&#39;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 퓨전 (Conv + BN + ReLU)</span>
</span></span><span style="display:flex;"><span>model_fused <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>quantization<span style="color:#f92672">.</span>fuse_modules(model, [[<span style="color:#e6db74">&#39;conv&#39;</span>, <span style="color:#e6db74">&#39;bn&#39;</span>, <span style="color:#e6db74">&#39;relu&#39;</span>]])
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 준비</span>
</span></span><span style="display:flex;"><span>model_prepared <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>quantization<span style="color:#f92672">.</span>prepare(model_fused)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 캘리브레이션 (대표 데이터로)</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">with</span> torch<span style="color:#f92672">.</span>no_grad():
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">for</span> data <span style="color:#f92672">in</span> calibration_loader:
</span></span><span style="display:flex;"><span>        model_prepared(data)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 변환</span>
</span></span><span style="display:flex;"><span>model_quantized <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>quantization<span style="color:#f92672">.</span>convert(model_prepared)</span></span></code></pre></div><h3 id="qat-quantization-aware-training">QAT (Quantization-Aware Training)<a class="anchor" href="#qat-quantization-aware-training">#</a></h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># 준비</span>
</span></span><span style="display:flex;"><span>model<span style="color:#f92672">.</span>train()
</span></span><span style="display:flex;"><span>model<span style="color:#f92672">.</span>qconfig <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>quantization<span style="color:#f92672">.</span>get_default_qat_qconfig(<span style="color:#e6db74">&#39;fbgemm&#39;</span>)
</span></span><span style="display:flex;"><span>model_prepared <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>quantization<span style="color:#f92672">.</span>prepare_qat(model)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 학습 (fake quantization 포함)</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">for</span> epoch <span style="color:#f92672">in</span> range(epochs):
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">for</span> data, target <span style="color:#f92672">in</span> train_loader:
</span></span><span style="display:flex;"><span>        output <span style="color:#f92672">=</span> model_prepared(data)
</span></span><span style="display:flex;"><span>        loss <span style="color:#f92672">=</span> criterion(output, target)
</span></span><span style="display:flex;"><span>        loss<span style="color:#f92672">.</span>backward()
</span></span><span style="display:flex;"><span>        optimizer<span style="color:#f92672">.</span>step()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 변환</span>
</span></span><span style="display:flex;"><span>model_prepared<span style="color:#f92672">.</span>eval()
</span></span><span style="display:flex;"><span>model_quantized <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>quantization<span style="color:#f92672">.</span>convert(model_prepared)</span></span></code></pre></div><hr>
<h2 id="프루닝-pruning">프루닝 (Pruning)<a class="anchor" href="#%ed%94%84%eb%a3%a8%eb%8b%9d-pruning">#</a></h2>
<h3 id="비구조적-프루닝">비구조적 프루닝<a class="anchor" href="#%eb%b9%84%ea%b5%ac%ec%a1%b0%ec%a0%81-%ed%94%84%eb%a3%a8%eb%8b%9d">#</a></h3>
<p>개별 가중치 제거:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">import</span> torch.nn.utils.prune <span style="color:#66d9ef">as</span> prune
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># L1 프루닝 (30% 제거)</span>
</span></span><span style="display:flex;"><span>prune<span style="color:#f92672">.</span>l1_unstructured(model<span style="color:#f92672">.</span>conv1, name<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;weight&#39;</span>, amount<span style="color:#f92672">=</span><span style="color:#ae81ff">0.3</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 영구 적용</span>
</span></span><span style="display:flex;"><span>prune<span style="color:#f92672">.</span>remove(model<span style="color:#f92672">.</span>conv1, <span style="color:#e6db74">&#39;weight&#39;</span>)</span></span></code></pre></div><h3 id="구조적-프루닝">구조적 프루닝<a class="anchor" href="#%ea%b5%ac%ec%a1%b0%ec%a0%81-%ed%94%84%eb%a3%a8%eb%8b%9d">#</a></h3>
<p>전체 채널/필터 제거:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># 채널 프루닝</span>
</span></span><span style="display:flex;"><span>prune<span style="color:#f92672">.</span>ln_structured(model<span style="color:#f92672">.</span>conv1, name<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;weight&#39;</span>, amount<span style="color:#f92672">=</span><span style="color:#ae81ff">0.3</span>, n<span style="color:#f92672">=</span><span style="color:#ae81ff">2</span>, dim<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>)</span></span></code></pre></div><h3 id="글로벌-프루닝">글로벌 프루닝<a class="anchor" href="#%ea%b8%80%eb%a1%9c%eb%b2%8c-%ed%94%84%eb%a3%a8%eb%8b%9d">#</a></h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>parameters_to_prune <span style="color:#f92672">=</span> [
</span></span><span style="display:flex;"><span>    (model<span style="color:#f92672">.</span>conv1, <span style="color:#e6db74">&#39;weight&#39;</span>),
</span></span><span style="display:flex;"><span>    (model<span style="color:#f92672">.</span>conv2, <span style="color:#e6db74">&#39;weight&#39;</span>),
</span></span><span style="display:flex;"><span>    (model<span style="color:#f92672">.</span>fc, <span style="color:#e6db74">&#39;weight&#39;</span>),
</span></span><span style="display:flex;"><span>]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>prune<span style="color:#f92672">.</span>global_unstructured(
</span></span><span style="display:flex;"><span>    parameters_to_prune,
</span></span><span style="display:flex;"><span>    pruning_method<span style="color:#f92672">=</span>prune<span style="color:#f92672">.</span>L1Unstructured,
</span></span><span style="display:flex;"><span>    amount<span style="color:#f92672">=</span><span style="color:#ae81ff">0.3</span>,
</span></span><span style="display:flex;"><span>)</span></span></code></pre></div><hr>
<h2 id="knowledge-distillation">Knowledge Distillation<a class="anchor" href="#knowledge-distillation">#</a></h2>
<h3 id="기본-구조">기본 구조<a class="anchor" href="#%ea%b8%b0%eb%b3%b8-%ea%b5%ac%ec%a1%b0">#</a></h3>
<pre tabindex="0"><code>Teacher (큰 모델) ──→ Soft Labels
                          ↓
                    Student (작은 모델)
                          ↑
Ground Truth ────────→ Hard Labels</code></pre><h3 id="구현">구현<a class="anchor" href="#%ea%b5%ac%ed%98%84">#</a></h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">import</span> torch.nn.functional <span style="color:#66d9ef">as</span> F
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">distillation_loss</span>(student_logits, teacher_logits, labels, T<span style="color:#f92672">=</span><span style="color:#ae81ff">4.0</span>, alpha<span style="color:#f92672">=</span><span style="color:#ae81ff">0.7</span>):
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;&#34;&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    T: temperature (높을수록 soft한 분포)
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    alpha: soft loss 비중
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    &#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># Soft loss (teacher의 지식)</span>
</span></span><span style="display:flex;"><span>    soft_loss <span style="color:#f92672">=</span> F<span style="color:#f92672">.</span>kl_div(
</span></span><span style="display:flex;"><span>        F<span style="color:#f92672">.</span>log_softmax(student_logits <span style="color:#f92672">/</span> T, dim<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>),
</span></span><span style="display:flex;"><span>        F<span style="color:#f92672">.</span>softmax(teacher_logits <span style="color:#f92672">/</span> T, dim<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>),
</span></span><span style="display:flex;"><span>        reduction<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;batchmean&#39;</span>
</span></span><span style="display:flex;"><span>    ) <span style="color:#f92672">*</span> (T <span style="color:#f92672">*</span> T)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># Hard loss (실제 레이블)</span>
</span></span><span style="display:flex;"><span>    hard_loss <span style="color:#f92672">=</span> F<span style="color:#f92672">.</span>cross_entropy(student_logits, labels)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> alpha <span style="color:#f92672">*</span> soft_loss <span style="color:#f92672">+</span> (<span style="color:#ae81ff">1</span> <span style="color:#f92672">-</span> alpha) <span style="color:#f92672">*</span> hard_loss
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 학습</span>
</span></span><span style="display:flex;"><span>teacher<span style="color:#f92672">.</span>eval()
</span></span><span style="display:flex;"><span>student<span style="color:#f92672">.</span>train()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">for</span> data, labels <span style="color:#f92672">in</span> train_loader:
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">with</span> torch<span style="color:#f92672">.</span>no_grad():
</span></span><span style="display:flex;"><span>        teacher_logits <span style="color:#f92672">=</span> teacher(data)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    student_logits <span style="color:#f92672">=</span> student(data)
</span></span><span style="display:flex;"><span>    loss <span style="color:#f92672">=</span> distillation_loss(student_logits, teacher_logits, labels)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    optimizer<span style="color:#f92672">.</span>zero_grad()
</span></span><span style="display:flex;"><span>    loss<span style="color:#f92672">.</span>backward()
</span></span><span style="display:flex;"><span>    optimizer<span style="color:#f92672">.</span>step()</span></span></code></pre></div><hr>
<h2 id="효율적인-아키텍처">효율적인 아키텍처<a class="anchor" href="#%ed%9a%a8%ec%9c%a8%ec%a0%81%ec%9d%b8-%ec%95%84%ed%82%a4%ed%85%8d%ec%b2%98">#</a></h2>
<h3 id="mobilenet">MobileNet<a class="anchor" href="#mobilenet">#</a></h3>
<p>Depthwise Separable Convolution:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#66d9ef">class</span> <span style="color:#a6e22e">DepthwiseSeparable</span>(nn<span style="color:#f92672">.</span>Module):
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">__init__</span>(self, in_ch, out_ch, stride<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>):
</span></span><span style="display:flex;"><span>        super()<span style="color:#f92672">.</span><span style="color:#a6e22e">__init__</span>()
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># Depthwise: 채널별 독립 연산</span>
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>depthwise <span style="color:#f92672">=</span> nn<span style="color:#f92672">.</span>Conv2d(in_ch, in_ch, <span style="color:#ae81ff">3</span>, stride, <span style="color:#ae81ff">1</span>, groups<span style="color:#f92672">=</span>in_ch)
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># Pointwise: 1x1 conv</span>
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>pointwise <span style="color:#f92672">=</span> nn<span style="color:#f92672">.</span>Conv2d(in_ch, out_ch, <span style="color:#ae81ff">1</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">forward</span>(self, x):
</span></span><span style="display:flex;"><span>        x <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>depthwise(x)
</span></span><span style="display:flex;"><span>        x <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>pointwise(x)
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">return</span> x</span></span></code></pre></div><h3 id="efficientnet">EfficientNet<a class="anchor" href="#efficientnet">#</a></h3>
<p>Compound Scaling:</p>
<pre tabindex="0"><code>depth = α^φ
width = β^φ
resolution = γ^φ

여기서 α · β² · γ² ≈ 2</code></pre><hr>
<h2 id="혼합-정밀도-학습">혼합 정밀도 학습<a class="anchor" href="#%ed%98%bc%ed%95%a9-%ec%a0%95%eb%b0%80%eb%8f%84-%ed%95%99%ec%8a%b5">#</a></h2>
<p>학습 시 FP16 사용으로 메모리와 속도 개선:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">from</span> torch.cuda.amp <span style="color:#f92672">import</span> autocast, GradScaler
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>scaler <span style="color:#f92672">=</span> GradScaler()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">for</span> data, target <span style="color:#f92672">in</span> train_loader:
</span></span><span style="display:flex;"><span>    optimizer<span style="color:#f92672">.</span>zero_grad()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">with</span> autocast():  <span style="color:#75715e"># FP16 연산</span>
</span></span><span style="display:flex;"><span>        output <span style="color:#f92672">=</span> model(data)
</span></span><span style="display:flex;"><span>        loss <span style="color:#f92672">=</span> criterion(output, target)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    scaler<span style="color:#f92672">.</span>scale(loss)<span style="color:#f92672">.</span>backward()
</span></span><span style="display:flex;"><span>    scaler<span style="color:#f92672">.</span>step(optimizer)
</span></span><span style="display:flex;"><span>    scaler<span style="color:#f92672">.</span>update()</span></span></code></pre></div><hr>
<h2 id="최적화-파이프라인">최적화 파이프라인<a class="anchor" href="#%ec%b5%9c%ec%a0%81%ed%99%94-%ed%8c%8c%ec%9d%b4%ed%94%84%eb%9d%bc%ec%9d%b8">#</a></h2>
<pre tabindex="0"><code>1. 베이스라인 측정
   ↓
2. 프루닝 (30-50%)
   ↓
3. 재학습 (정확도 복구)
   ↓
4. 양자화 (INT8)
   ↓
5. ONNX 변환
   ↓
6. TensorRT 최적화
   ↓
7. 최종 벤치마크</code></pre><hr>
<h2 id="성능-측정">성능 측정<a class="anchor" href="#%ec%84%b1%eb%8a%a5-%ec%b8%a1%ec%a0%95">#</a></h2>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">import</span> torch
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> time
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">benchmark</span>(model, input_shape, n_runs<span style="color:#f92672">=</span><span style="color:#ae81ff">100</span>, warmup<span style="color:#f92672">=</span><span style="color:#ae81ff">10</span>):
</span></span><span style="display:flex;"><span>    device <span style="color:#f92672">=</span> next(model<span style="color:#f92672">.</span>parameters())<span style="color:#f92672">.</span>device
</span></span><span style="display:flex;"><span>    x <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>randn(input_shape)<span style="color:#f92672">.</span>to(device)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># 워밍업</span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">for</span> _ <span style="color:#f92672">in</span> range(warmup):
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">with</span> torch<span style="color:#f92672">.</span>no_grad():
</span></span><span style="display:flex;"><span>            model(x)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># 동기화 (GPU)</span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">if</span> device<span style="color:#f92672">.</span>type <span style="color:#f92672">==</span> <span style="color:#e6db74">&#39;cuda&#39;</span>:
</span></span><span style="display:flex;"><span>        torch<span style="color:#f92672">.</span>cuda<span style="color:#f92672">.</span>synchronize()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># 측정</span>
</span></span><span style="display:flex;"><span>    start <span style="color:#f92672">=</span> time<span style="color:#f92672">.</span>time()
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">for</span> _ <span style="color:#f92672">in</span> range(n_runs):
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">with</span> torch<span style="color:#f92672">.</span>no_grad():
</span></span><span style="display:flex;"><span>            model(x)
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">if</span> device<span style="color:#f92672">.</span>type <span style="color:#f92672">==</span> <span style="color:#e6db74">&#39;cuda&#39;</span>:
</span></span><span style="display:flex;"><span>            torch<span style="color:#f92672">.</span>cuda<span style="color:#f92672">.</span>synchronize()
</span></span><span style="display:flex;"><span>    elapsed <span style="color:#f92672">=</span> time<span style="color:#f92672">.</span>time() <span style="color:#f92672">-</span> start
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    latency <span style="color:#f92672">=</span> elapsed <span style="color:#f92672">/</span> n_runs <span style="color:#f92672">*</span> <span style="color:#ae81ff">1000</span>
</span></span><span style="display:flex;"><span>    throughput <span style="color:#f92672">=</span> n_runs <span style="color:#f92672">/</span> elapsed
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;Latency: </span><span style="color:#e6db74">{</span>latency<span style="color:#e6db74">:</span><span style="color:#e6db74">.2f</span><span style="color:#e6db74">}</span><span style="color:#e6db74"> ms&#34;</span>)
</span></span><span style="display:flex;"><span>    print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;Throughput: </span><span style="color:#e6db74">{</span>throughput<span style="color:#e6db74">:</span><span style="color:#e6db74">.2f</span><span style="color:#e6db74">}</span><span style="color:#e6db74"> FPS&#34;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> latency, throughput</span></span></code></pre></div><h3 id="모델-크기-측정">모델 크기 측정<a class="anchor" href="#%eb%aa%a8%eb%8d%b8-%ed%81%ac%ea%b8%b0-%ec%b8%a1%ec%a0%95">#</a></h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">get_model_size</span>(model):
</span></span><span style="display:flex;"><span>    param_size <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">for</span> param <span style="color:#f92672">in</span> model<span style="color:#f92672">.</span>parameters():
</span></span><span style="display:flex;"><span>        param_size <span style="color:#f92672">+=</span> param<span style="color:#f92672">.</span>nelement() <span style="color:#f92672">*</span> param<span style="color:#f92672">.</span>element_size()
</span></span><span style="display:flex;"><span>    buffer_size <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">for</span> buffer <span style="color:#f92672">in</span> model<span style="color:#f92672">.</span>buffers():
</span></span><span style="display:flex;"><span>        buffer_size <span style="color:#f92672">+=</span> buffer<span style="color:#f92672">.</span>nelement() <span style="color:#f92672">*</span> buffer<span style="color:#f92672">.</span>element_size()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    size_mb <span style="color:#f92672">=</span> (param_size <span style="color:#f92672">+</span> buffer_size) <span style="color:#f92672">/</span> <span style="color:#ae81ff">1024</span> <span style="color:#f92672">/</span> <span style="color:#ae81ff">1024</span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> size_mb</span></span></code></pre></div><hr>
<h2 id="관련-콘텐츠">관련 콘텐츠<a class="anchor" href="#%ea%b4%80%eb%a0%a8-%ec%bd%98%ed%85%90%ec%b8%a0">#</a></h2>
<ul>
<li><a href="/ko/docs/engineering/deployment/tensorrt">TensorRT</a> - GPU 최적화</li>
<li><a href="/ko/docs/engineering/deployment/onnx">ONNX</a> - 모델 변환</li>
<li><a href="/ko/docs/engineering/deployment/serving">모델 서빙</a> - 배포</li>
</ul>
</article>
 
      

      <footer class="book-footer">
        
  <div class="flex flex-wrap justify-between">

<div>

</div>

<div>

</div>

</div>





  
  
  
  <div class="flex flex-wrap justify-between">
    <span>
    
      <a href="/ko/docs/engineering/deployment/serving/" class="flex align-center">
        <img src="/icons/backward.svg" class="book-icon" alt="Backward" />
        <span>모델 서빙</span>
      </a>
    
    </span>
    <span>
    
      <a href="/ko/docs/engineering/hardware/" class="flex align-center">
        <span>하드웨어</span>
        <img src="/icons/forward.svg" class="book-icon" alt="Forward" />
      </a>
    
    </span>
  </div>
  


 
        
  
  <div class="book-comments">

</div>
  
 
        
        
  
 
        
  
  
    <script>(function(){document.querySelectorAll("pre:has(code)").forEach(e=>{e.addEventListener("click",e.focus),e.addEventListener("copy",function(t){if(t.preventDefault(),navigator.clipboard){const t=window.getSelection().toString()||e.textContent;navigator.clipboard.writeText(t)}})})})()</script>
  

      </footer>

      <label for="menu-control" class="hidden book-menu-overlay"></label>
    </div>

    
  
  <aside class="book-toc">
    <div class="book-toc-content">
      
  
<nav id="TableOfContents">
  <ul>
    <li><a href="#개요">개요</a></li>
    <li><a href="#최적화-기법-분류">최적화 기법 분류</a></li>
    <li><a href="#양자화-quantization">양자화 (Quantization)</a>
      <ul>
        <li><a href="#종류">종류</a></li>
        <li><a href="#pytorch-동적-양자화">PyTorch 동적 양자화</a></li>
        <li><a href="#pytorch-정적-양자화-ptq">PyTorch 정적 양자화 (PTQ)</a></li>
        <li><a href="#qat-quantization-aware-training">QAT (Quantization-Aware Training)</a></li>
      </ul>
    </li>
    <li><a href="#프루닝-pruning">프루닝 (Pruning)</a>
      <ul>
        <li><a href="#비구조적-프루닝">비구조적 프루닝</a></li>
        <li><a href="#구조적-프루닝">구조적 프루닝</a></li>
        <li><a href="#글로벌-프루닝">글로벌 프루닝</a></li>
      </ul>
    </li>
    <li><a href="#knowledge-distillation">Knowledge Distillation</a>
      <ul>
        <li><a href="#기본-구조">기본 구조</a></li>
        <li><a href="#구현">구현</a></li>
      </ul>
    </li>
    <li><a href="#효율적인-아키텍처">효율적인 아키텍처</a>
      <ul>
        <li><a href="#mobilenet">MobileNet</a></li>
        <li><a href="#efficientnet">EfficientNet</a></li>
      </ul>
    </li>
    <li><a href="#혼합-정밀도-학습">혼합 정밀도 학습</a></li>
    <li><a href="#최적화-파이프라인">최적화 파이프라인</a></li>
    <li><a href="#성능-측정">성능 측정</a>
      <ul>
        <li><a href="#모델-크기-측정">모델 크기 측정</a></li>
      </ul>
    </li>
    <li><a href="#관련-콘텐츠">관련 콘텐츠</a></li>
  </ul>
</nav>



    </div>
  </aside>
  
 
  </main>

  
</body>
</html>




















