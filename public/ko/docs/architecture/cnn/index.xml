<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>CNN on Vision Engineer 지식 가이드</title>
    <link>http://localhost:1313/ko/docs/architecture/cnn/</link>
    <description>Recent content in CNN on Vision Engineer 지식 가이드</description>
    <generator>Hugo</generator>
    <language>ko-KR</language>
    <atom:link href="http://localhost:1313/ko/docs/architecture/cnn/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>AlexNet</title>
      <link>http://localhost:1313/ko/docs/architecture/cnn/alexnet/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/ko/docs/architecture/cnn/alexnet/</guid>
      <description>&lt;h1 id=&#34;alexnet&#34;&gt;AlexNet&lt;a class=&#34;anchor&#34; href=&#34;#alexnet&#34;&gt;#&lt;/a&gt;&lt;/h1&gt;&#xA;&lt;h2 id=&#34;개요&#34;&gt;개요&lt;a class=&#34;anchor&#34; href=&#34;#%ea%b0%9c%ec%9a%94&#34;&gt;#&lt;/a&gt;&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;논문&lt;/strong&gt;: ImageNet Classification with Deep Convolutional Neural Networks (2012)&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;저자&lt;/strong&gt;: Alex Krizhevsky, Ilya Sutskever, Geoffrey Hinton&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;핵심 기여&lt;/strong&gt;: 딥러닝 시대의 시작을 알린 모델. ImageNet 2012에서 압도적 성능으로 우승&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;왜-중요한가&#34;&gt;왜 중요한가?&lt;a class=&#34;anchor&#34; href=&#34;#%ec%99%9c-%ec%a4%91%ec%9a%94%ed%95%9c%ea%b0%80&#34;&gt;#&lt;/a&gt;&lt;/h2&gt;&#xA;&lt;p&gt;AlexNet은 ImageNet에서 top-5 error를 **26% → 16%**로 크게 낮추며 딥러닝의 가능성을 증명했습니다. 이후 모든 컴퓨터 비전 연구가 CNN 기반으로 전환되는 계기가 되었습니다.&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;구조&#34;&gt;구조&lt;a class=&#34;anchor&#34; href=&#34;#%ea%b5%ac%ec%a1%b0&#34;&gt;#&lt;/a&gt;&lt;/h2&gt;&#xA;&lt;h3 id=&#34;전체-아키텍처&#34;&gt;전체 아키텍처&lt;a class=&#34;anchor&#34; href=&#34;#%ec%a0%84%ec%b2%b4-%ec%95%84%ed%82%a4%ed%85%8d%ec%b2%98&#34;&gt;#&lt;/a&gt;&lt;/h3&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;Input (224×224×3)&#xA;    ↓&#xA;Conv1: 96 filters, 11×11, stride 4 → ReLU → LRN → MaxPool&#xA;    ↓&#xA;Conv2: 256 filters, 5×5 → ReLU → LRN → MaxPool&#xA;    ↓&#xA;Conv3: 384 filters, 3×3 → ReLU&#xA;    ↓&#xA;Conv4: 384 filters, 3×3 → ReLU&#xA;    ↓&#xA;Conv5: 256 filters, 3×3 → ReLU → MaxPool&#xA;    ↓&#xA;FC6: 4096 → ReLU → Dropout&#xA;    ↓&#xA;FC7: 4096 → ReLU → Dropout&#xA;    ↓&#xA;FC8: 1000 (softmax)&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&#34;주요-특징&#34;&gt;주요 특징&lt;a class=&#34;anchor&#34; href=&#34;#%ec%a3%bc%ec%9a%94-%ed%8a%b9%ec%a7%95&#34;&gt;#&lt;/a&gt;&lt;/h3&gt;&#xA;&lt;table&gt;&#xA;  &lt;thead&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;th&gt;요소&lt;/th&gt;&#xA;          &lt;th&gt;설명&lt;/th&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/thead&gt;&#xA;  &lt;tbody&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;&lt;strong&gt;ReLU&lt;/strong&gt;&lt;/td&gt;&#xA;          &lt;td&gt;Sigmoid 대신 사용하여 학습 속도 6배 향상&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;&lt;strong&gt;GPU 학습&lt;/strong&gt;&lt;/td&gt;&#xA;          &lt;td&gt;2개의 GTX 580 GPU로 병렬 학습&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;&lt;strong&gt;Dropout&lt;/strong&gt;&lt;/td&gt;&#xA;          &lt;td&gt;FC 레이어에 0.5 비율로 적용하여 과적합 방지&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;&lt;strong&gt;LRN&lt;/strong&gt;&lt;/td&gt;&#xA;          &lt;td&gt;Local Response Normalization (현재는 사용 안 함)&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;&lt;strong&gt;Data Augmentation&lt;/strong&gt;&lt;/td&gt;&#xA;          &lt;td&gt;랜덤 크롭, 수평 뒤집기, 색상 변환&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/tbody&gt;&#xA;&lt;/table&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;핵심-기술-상세&#34;&gt;핵심 기술 상세&lt;a class=&#34;anchor&#34; href=&#34;#%ed%95%b5%ec%8b%ac-%ea%b8%b0%ec%88%a0-%ec%83%81%ec%84%b8&#34;&gt;#&lt;/a&gt;&lt;/h2&gt;&#xA;&lt;h3 id=&#34;1-relu-rectified-linear-unit&#34;&gt;1. ReLU (Rectified Linear Unit)&lt;a class=&#34;anchor&#34; href=&#34;#1-relu-rectified-linear-unit&#34;&gt;#&lt;/a&gt;&lt;/h3&gt;&#xA;&lt;p&gt;$$f(x) = \max(0, x)$$&lt;/p&gt;</description>
    </item>
    <item>
      <title>VGG</title>
      <link>http://localhost:1313/ko/docs/architecture/cnn/vgg/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/ko/docs/architecture/cnn/vgg/</guid>
      <description>&lt;h1 id=&#34;vgg&#34;&gt;VGG&lt;a class=&#34;anchor&#34; href=&#34;#vgg&#34;&gt;#&lt;/a&gt;&lt;/h1&gt;&#xA;&lt;h2 id=&#34;개요&#34;&gt;개요&lt;a class=&#34;anchor&#34; href=&#34;#%ea%b0%9c%ec%9a%94&#34;&gt;#&lt;/a&gt;&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;논문&lt;/strong&gt;: Very Deep Convolutional Networks for Large-Scale Image Recognition (2014)&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;저자&lt;/strong&gt;: Karen Simonyan, Andrew Zisserman (Oxford)&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;핵심 기여&lt;/strong&gt;: 작은 필터(3×3)를 깊게 쌓는 것이 효과적임을 증명&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;핵심-아이디어&#34;&gt;핵심 아이디어&lt;a class=&#34;anchor&#34; href=&#34;#%ed%95%b5%ec%8b%ac-%ec%95%84%ec%9d%b4%eb%94%94%ec%96%b4&#34;&gt;#&lt;/a&gt;&lt;/h2&gt;&#xA;&lt;blockquote class=&#39;book-hint &#39;&gt;&#xA;&lt;p&gt;&amp;ldquo;3×3 필터를 여러 번 쌓으면 큰 필터와 같은 receptive field를 가지면서 파라미터는 더 적다&amp;rdquo;&lt;/p&gt;&#xA;&lt;/blockquote&gt;&lt;p&gt;&lt;strong&gt;예시&lt;/strong&gt;: 3×3 두 번 = 5×5 한 번의 receptive field&lt;/p&gt;&#xA;&lt;table&gt;&#xA;  &lt;thead&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;th&gt;방식&lt;/th&gt;&#xA;          &lt;th&gt;Receptive Field&lt;/th&gt;&#xA;          &lt;th&gt;파라미터&lt;/th&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/thead&gt;&#xA;  &lt;tbody&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;5×5 한 번&lt;/td&gt;&#xA;          &lt;td&gt;5×5&lt;/td&gt;&#xA;          &lt;td&gt;25C²&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;3×3 두 번&lt;/td&gt;&#xA;          &lt;td&gt;5×5&lt;/td&gt;&#xA;          &lt;td&gt;18C²&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/tbody&gt;&#xA;&lt;/table&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;구조&#34;&gt;구조&lt;a class=&#34;anchor&#34; href=&#34;#%ea%b5%ac%ec%a1%b0&#34;&gt;#&lt;/a&gt;&lt;/h2&gt;&#xA;&lt;h3 id=&#34;vgg-16-아키텍처&#34;&gt;VGG-16 아키텍처&lt;a class=&#34;anchor&#34; href=&#34;#vgg-16-%ec%95%84%ed%82%a4%ed%85%8d%ec%b2%98&#34;&gt;#&lt;/a&gt;&lt;/h3&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;Input (224×224×3)&#xA;    ↓&#xA;Block 1: [Conv3-64] × 2 → MaxPool&#xA;    ↓&#xA;Block 2: [Conv3-128] × 2 → MaxPool&#xA;    ↓&#xA;Block 3: [Conv3-256] × 3 → MaxPool&#xA;    ↓&#xA;Block 4: [Conv3-512] × 3 → MaxPool&#xA;    ↓&#xA;Block 5: [Conv3-512] × 3 → MaxPool&#xA;    ↓&#xA;FC: 4096 → 4096 → 1000&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&#34;vgg-변형&#34;&gt;VGG 변형&lt;a class=&#34;anchor&#34; href=&#34;#vgg-%eb%b3%80%ed%98%95&#34;&gt;#&lt;/a&gt;&lt;/h3&gt;&#xA;&lt;table&gt;&#xA;  &lt;thead&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;th&gt;모델&lt;/th&gt;&#xA;          &lt;th&gt;레이어 수&lt;/th&gt;&#xA;          &lt;th&gt;파라미터&lt;/th&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/thead&gt;&#xA;  &lt;tbody&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;VGG-11&lt;/td&gt;&#xA;          &lt;td&gt;11&lt;/td&gt;&#xA;          &lt;td&gt;133M&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;VGG-13&lt;/td&gt;&#xA;          &lt;td&gt;13&lt;/td&gt;&#xA;          &lt;td&gt;133M&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;VGG-16&lt;/td&gt;&#xA;          &lt;td&gt;16&lt;/td&gt;&#xA;          &lt;td&gt;138M&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;VGG-19&lt;/td&gt;&#xA;          &lt;td&gt;19&lt;/td&gt;&#xA;          &lt;td&gt;144M&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/tbody&gt;&#xA;&lt;/table&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;설계-원칙&#34;&gt;설계 원칙&lt;a class=&#34;anchor&#34; href=&#34;#%ec%84%a4%ea%b3%84-%ec%9b%90%ec%b9%99&#34;&gt;#&lt;/a&gt;&lt;/h2&gt;&#xA;&lt;h3 id=&#34;1-작은-필터-33&#34;&gt;1. 작은 필터 (3×3)&lt;a class=&#34;anchor&#34; href=&#34;#1-%ec%9e%91%ec%9d%80-%ed%95%84%ed%84%b0-33&#34;&gt;#&lt;/a&gt;&lt;/h3&gt;&#xA;&lt;p&gt;모든 Conv 레이어에서 3×3 필터 사용:&lt;/p&gt;</description>
    </item>
    <item>
      <title>ResNet</title>
      <link>http://localhost:1313/ko/docs/architecture/cnn/resnet/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/ko/docs/architecture/cnn/resnet/</guid>
      <description>&lt;h1 id=&#34;resnet-residual-network&#34;&gt;ResNet (Residual Network)&lt;a class=&#34;anchor&#34; href=&#34;#resnet-residual-network&#34;&gt;#&lt;/a&gt;&lt;/h1&gt;&#xA;&lt;h2 id=&#34;개요&#34;&gt;개요&lt;a class=&#34;anchor&#34; href=&#34;#%ea%b0%9c%ec%9a%94&#34;&gt;#&lt;/a&gt;&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;논문&lt;/strong&gt;: Deep Residual Learning for Image Recognition (2015)&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;저자&lt;/strong&gt;: Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun (Microsoft Research)&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;핵심 기여&lt;/strong&gt;: Skip Connection으로 100+ 레이어 학습 가능하게 함&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;해결한-문제-degradation-problem&#34;&gt;해결한 문제: Degradation Problem&lt;a class=&#34;anchor&#34; href=&#34;#%ed%95%b4%ea%b2%b0%ed%95%9c-%eb%ac%b8%ec%a0%9c-degradation-problem&#34;&gt;#&lt;/a&gt;&lt;/h2&gt;&#xA;&lt;p&gt;네트워크가 깊어지면 성능이 오히려 떨어지는 현상:&lt;/p&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;20-layer: 7.4% error&#xA;56-layer: 8.5% error  ← 더 깊은데 성능이 나빠짐&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;이는 과적합이 아니라 &lt;strong&gt;최적화의 어려움&lt;/strong&gt; 때문입니다.&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;핵심-아이디어-residual-learning&#34;&gt;핵심 아이디어: Residual Learning&lt;a class=&#34;anchor&#34; href=&#34;#%ed%95%b5%ec%8b%ac-%ec%95%84%ec%9d%b4%eb%94%94%ec%96%b4-residual-learning&#34;&gt;#&lt;/a&gt;&lt;/h2&gt;&#xA;&lt;h3 id=&#34;skip-connection-shortcut&#34;&gt;Skip Connection (Shortcut)&lt;a class=&#34;anchor&#34; href=&#34;#skip-connection-shortcut&#34;&gt;#&lt;/a&gt;&lt;/h3&gt;&#xA;&lt;p&gt;기존 학습:&#xA;$$H(x) = F(x)$$&lt;/p&gt;&#xA;&lt;p&gt;Residual 학습:&#xA;$$H(x) = F(x) + x$$&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
