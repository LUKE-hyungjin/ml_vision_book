<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Generative on Vision Engineer 지식 가이드</title>
    <link>http://localhost:1313/ko/docs/architecture/generative/</link>
    <description>Recent content in Generative on Vision Engineer 지식 가이드</description>
    <generator>Hugo</generator>
    <language>ko-KR</language>
    <atom:link href="http://localhost:1313/ko/docs/architecture/generative/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>VAE</title>
      <link>http://localhost:1313/ko/docs/architecture/generative/vae/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/ko/docs/architecture/generative/vae/</guid>
      <description>&lt;h1 id=&#34;vae-variational-autoencoder&#34;&gt;VAE (Variational Autoencoder)&lt;a class=&#34;anchor&#34; href=&#34;#vae-variational-autoencoder&#34;&gt;#&lt;/a&gt;&lt;/h1&gt;&#xA;&lt;h2 id=&#34;개요&#34;&gt;개요&lt;a class=&#34;anchor&#34; href=&#34;#%ea%b0%9c%ec%9a%94&#34;&gt;#&lt;/a&gt;&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;논문&lt;/strong&gt;: Auto-Encoding Variational Bayes (2013)&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;저자&lt;/strong&gt;: Diederik P. Kingma, Max Welling&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;핵심 기여&lt;/strong&gt;: 확률적 잠재 공간에서 생성 가능한 오토인코더&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;핵심-아이디어&#34;&gt;핵심 아이디어&lt;a class=&#34;anchor&#34; href=&#34;#%ed%95%b5%ec%8b%ac-%ec%95%84%ec%9d%b4%eb%94%94%ec%96%b4&#34;&gt;#&lt;/a&gt;&lt;/h2&gt;&#xA;&lt;blockquote class=&#39;book-hint &#39;&gt;&#xA;&lt;p&gt;&amp;ldquo;데이터를 압축하는 동시에 잠재 공간을 정규화하여 생성 가능하게&amp;rdquo;&lt;/p&gt;&#xA;&lt;/blockquote&gt;&lt;p&gt;일반 Autoencoder는 데이터 압축만 하지만, VAE는 잠재 공간이 연속적이고 의미있는 구조를 갖도록 학습합니다.&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;autoencoder-vs-vae&#34;&gt;Autoencoder vs VAE&lt;a class=&#34;anchor&#34; href=&#34;#autoencoder-vs-vae&#34;&gt;#&lt;/a&gt;&lt;/h2&gt;&#xA;&lt;h3 id=&#34;일반-autoencoder&#34;&gt;일반 Autoencoder&lt;a class=&#34;anchor&#34; href=&#34;#%ec%9d%bc%eb%b0%98-autoencoder&#34;&gt;#&lt;/a&gt;&lt;/h3&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;x → Encoder → z (deterministic) → Decoder → x̂&lt;/code&gt;&lt;/pre&gt;&lt;ul&gt;&#xA;&lt;li&gt;z가 불연속적&lt;/li&gt;&#xA;&lt;li&gt;학습 데이터 외의 z에서 생성 불가&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;vae&#34;&gt;VAE&lt;a class=&#34;anchor&#34; href=&#34;#vae&#34;&gt;#&lt;/a&gt;&lt;/h3&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;x → Encoder → (μ, σ) → z ~ N(μ, σ²) → Decoder → x̂&lt;/code&gt;&lt;/pre&gt;&lt;ul&gt;&#xA;&lt;li&gt;z가 확률 분포&lt;/li&gt;&#xA;&lt;li&gt;잠재 공간이 연속적 → 생성 가능&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;구조&#34;&gt;구조&lt;a class=&#34;anchor&#34; href=&#34;#%ea%b5%ac%ec%a1%b0&#34;&gt;#&lt;/a&gt;&lt;/h2&gt;&#xA;&lt;h3 id=&#34;전체-아키텍처&#34;&gt;전체 아키텍처&lt;a class=&#34;anchor&#34; href=&#34;#%ec%a0%84%ec%b2%b4-%ec%95%84%ed%82%a4%ed%85%8d%ec%b2%98&#34;&gt;#&lt;/a&gt;&lt;/h3&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;Input x&#xA;    ↓&#xA;┌─────────────────────────┐&#xA;│       Encoder           │&#xA;│  x → hidden → (μ, σ)   │&#xA;└─────────────────────────┘&#xA;    ↓&#xA;┌─────────────────────────┐&#xA;│   Reparameterization    │&#xA;│   z = μ + σ * ε         │&#xA;│   where ε ~ N(0, 1)     │&#xA;└─────────────────────────┘&#xA;    ↓&#xA;┌─────────────────────────┐&#xA;│       Decoder           │&#xA;│   z → hidden → x̂       │&#xA;└─────────────────────────┘&#xA;    ↓&#xA;Output x̂&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&#34;reparameterization-trick&#34;&gt;Reparameterization Trick&lt;a class=&#34;anchor&#34; href=&#34;#reparameterization-trick&#34;&gt;#&lt;/a&gt;&lt;/h3&gt;&#xA;&lt;p&gt;Gradient가 샘플링을 통과하도록:&lt;/p&gt;</description>
    </item>
    <item>
      <title>GAN</title>
      <link>http://localhost:1313/ko/docs/architecture/generative/gan/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/ko/docs/architecture/generative/gan/</guid>
      <description>&lt;h1 id=&#34;gan-generative-adversarial-network&#34;&gt;GAN (Generative Adversarial Network)&lt;a class=&#34;anchor&#34; href=&#34;#gan-generative-adversarial-network&#34;&gt;#&lt;/a&gt;&lt;/h1&gt;&#xA;&lt;h2 id=&#34;개요&#34;&gt;개요&lt;a class=&#34;anchor&#34; href=&#34;#%ea%b0%9c%ec%9a%94&#34;&gt;#&lt;/a&gt;&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;논문&lt;/strong&gt;: Generative Adversarial Networks (2014)&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;저자&lt;/strong&gt;: Ian Goodfellow et al.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;핵심 기여&lt;/strong&gt;: 적대적 학습으로 선명한 이미지 생성&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;핵심-아이디어&#34;&gt;핵심 아이디어&lt;a class=&#34;anchor&#34; href=&#34;#%ed%95%b5%ec%8b%ac-%ec%95%84%ec%9d%b4%eb%94%94%ec%96%b4&#34;&gt;#&lt;/a&gt;&lt;/h2&gt;&#xA;&lt;blockquote class=&#39;book-hint &#39;&gt;&#xA;&lt;p&gt;&amp;ldquo;Generator와 Discriminator가 경쟁하며 학습&amp;rdquo;&lt;/p&gt;&#xA;&lt;/blockquote&gt;&lt;p&gt;위조지폐범(Generator)과 경찰(Discriminator)의 게임:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Generator: 진짜처럼 보이는 가짜 생성&lt;/li&gt;&#xA;&lt;li&gt;Discriminator: 진짜와 가짜 구분&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;구조&#34;&gt;구조&lt;a class=&#34;anchor&#34; href=&#34;#%ea%b5%ac%ec%a1%b0&#34;&gt;#&lt;/a&gt;&lt;/h2&gt;&#xA;&lt;h3 id=&#34;전체-아키텍처&#34;&gt;전체 아키텍처&lt;a class=&#34;anchor&#34; href=&#34;#%ec%a0%84%ec%b2%b4-%ec%95%84%ed%82%a4%ed%85%8d%ec%b2%98&#34;&gt;#&lt;/a&gt;&lt;/h3&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;Random Noise z&#xA;      ↓&#xA;┌─────────────────┐&#xA;│    Generator    │&#xA;│  z → fake image │&#xA;└─────────────────┘&#xA;      ↓&#xA;┌─────────────────┐      ┌─────────────────┐&#xA;│  Fake Image     │      │  Real Image     │&#xA;└────────┬────────┘      └────────┬────────┘&#xA;         │                        │&#xA;         └──────────┬─────────────┘&#xA;                    ↓&#xA;         ┌─────────────────────┐&#xA;         │    Discriminator    │&#xA;         │  image → real/fake  │&#xA;         └─────────────────────┘&#xA;                    ↓&#xA;              0 (fake) or 1 (real)&lt;/code&gt;&lt;/pre&gt;&lt;hr&gt;&#xA;&lt;h2 id=&#34;목적-함수&#34;&gt;목적 함수&lt;a class=&#34;anchor&#34; href=&#34;#%eb%aa%a9%ec%a0%81-%ed%95%a8%ec%88%98&#34;&gt;#&lt;/a&gt;&lt;/h2&gt;&#xA;&lt;h3 id=&#34;minimax-game&#34;&gt;Minimax Game&lt;a class=&#34;anchor&#34; href=&#34;#minimax-game&#34;&gt;#&lt;/a&gt;&lt;/h3&gt;&#xA;&lt;p&gt;$$\min_G \max_D V(D, G) = \mathbb{E}&lt;em&gt;{x \sim p&lt;/em&gt;{data}}[\log D(x)] + \mathbb{E}_{z \sim p_z}[\log(1 - D(G(z)))]$$&lt;/p&gt;</description>
    </item>
    <item>
      <title>Stable Diffusion</title>
      <link>http://localhost:1313/ko/docs/architecture/generative/stable-diffusion/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/ko/docs/architecture/generative/stable-diffusion/</guid>
      <description>&lt;h1 id=&#34;stable-diffusion&#34;&gt;Stable Diffusion&lt;a class=&#34;anchor&#34; href=&#34;#stable-diffusion&#34;&gt;#&lt;/a&gt;&lt;/h1&gt;&#xA;&lt;h2 id=&#34;개요&#34;&gt;개요&lt;a class=&#34;anchor&#34; href=&#34;#%ea%b0%9c%ec%9a%94&#34;&gt;#&lt;/a&gt;&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;논문&lt;/strong&gt;: High-Resolution Image Synthesis with Latent Diffusion Models (2022)&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;저자&lt;/strong&gt;: Robin Rombach et al. (CompVis, Stability AI)&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;핵심 기여&lt;/strong&gt;: Latent space에서 Diffusion을 수행하여 효율적인 고해상도 생성&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;핵심-아이디어&#34;&gt;핵심 아이디어&lt;a class=&#34;anchor&#34; href=&#34;#%ed%95%b5%ec%8b%ac-%ec%95%84%ec%9d%b4%eb%94%94%ec%96%b4&#34;&gt;#&lt;/a&gt;&lt;/h2&gt;&#xA;&lt;blockquote class=&#39;book-hint &#39;&gt;&#xA;&lt;p&gt;&amp;ldquo;픽셀 공간이 아닌 압축된 잠재 공간에서 Diffusion&amp;rdquo;&lt;/p&gt;&#xA;&lt;/blockquote&gt;&lt;p&gt;기존 DDPM은 픽셀 공간에서 직접 작동해 계산량이 많았습니다. Stable Diffusion은 VAE로 이미지를 압축한 후 latent space에서 diffusion을 수행합니다.&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;diffusion-기본-개념&#34;&gt;Diffusion 기본 개념&lt;a class=&#34;anchor&#34; href=&#34;#diffusion-%ea%b8%b0%eb%b3%b8-%ea%b0%9c%eb%85%90&#34;&gt;#&lt;/a&gt;&lt;/h2&gt;&#xA;&lt;h3 id=&#34;forward-process-노이즈-추가&#34;&gt;Forward Process (노이즈 추가)&lt;a class=&#34;anchor&#34; href=&#34;#forward-process-%eb%85%b8%ec%9d%b4%ec%a6%88-%ec%b6%94%ea%b0%80&#34;&gt;#&lt;/a&gt;&lt;/h3&gt;&#xA;&lt;p&gt;$$q(x_t | x_{t-1}) = \mathcal{N}(x_t; \sqrt{1-\beta_t}x_{t-1}, \beta_t I)$$&lt;/p&gt;</description>
    </item>
    <item>
      <title>ControlNet</title>
      <link>http://localhost:1313/ko/docs/architecture/generative/controlnet/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/ko/docs/architecture/generative/controlnet/</guid>
      <description>&lt;h1 id=&#34;controlnet&#34;&gt;ControlNet&lt;a class=&#34;anchor&#34; href=&#34;#controlnet&#34;&gt;#&lt;/a&gt;&lt;/h1&gt;&#xA;&lt;h2 id=&#34;개요&#34;&gt;개요&lt;a class=&#34;anchor&#34; href=&#34;#%ea%b0%9c%ec%9a%94&#34;&gt;#&lt;/a&gt;&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;논문&lt;/strong&gt;: Adding Conditional Control to Text-to-Image Diffusion Models (2023)&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;저자&lt;/strong&gt;: Lvmin Zhang, Maneesh Agrawala (Stanford)&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;핵심 기여&lt;/strong&gt;: 사전학습된 Diffusion 모델에 공간적 조건 추가&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;핵심-아이디어&#34;&gt;핵심 아이디어&lt;a class=&#34;anchor&#34; href=&#34;#%ed%95%b5%ec%8b%ac-%ec%95%84%ec%9d%b4%eb%94%94%ec%96%b4&#34;&gt;#&lt;/a&gt;&lt;/h2&gt;&#xA;&lt;blockquote class=&#39;book-hint &#39;&gt;&#xA;&lt;p&gt;&amp;ldquo;원본 모델을 고정하고, 복사본에서 조건을 학습&amp;rdquo;&lt;/p&gt;&#xA;&lt;/blockquote&gt;&lt;p&gt;Stable Diffusion의 가중치를 건드리지 않고, 에지/포즈/깊이 등의 조건을 추가할 수 있습니다.&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;왜-필요한가&#34;&gt;왜 필요한가?&lt;a class=&#34;anchor&#34; href=&#34;#%ec%99%9c-%ed%95%84%ec%9a%94%ed%95%9c%ea%b0%80&#34;&gt;#&lt;/a&gt;&lt;/h2&gt;&#xA;&lt;h3 id=&#34;텍스트만으로는-부족한-제어&#34;&gt;텍스트만으로는 부족한 제어&lt;a class=&#34;anchor&#34; href=&#34;#%ed%85%8d%ec%8a%a4%ed%8a%b8%eb%a7%8c%ec%9c%bc%eb%a1%9c%eb%8a%94-%eb%b6%80%ec%a1%b1%ed%95%9c-%ec%a0%9c%ec%96%b4&#34;&gt;#&lt;/a&gt;&lt;/h3&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;Prompt: &amp;#34;a person raising their hand&amp;#34;&#xA;→ 손 위치, 포즈를 정확히 지정 불가&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&#34;controlnet의-해결&#34;&gt;ControlNet의 해결&lt;a class=&#34;anchor&#34; href=&#34;#controlnet%ec%9d%98-%ed%95%b4%ea%b2%b0&#34;&gt;#&lt;/a&gt;&lt;/h3&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;Prompt: &amp;#34;a person&amp;#34; + Pose Image (조건)&#xA;→ 원하는 포즈 그대로 생성&lt;/code&gt;&lt;/pre&gt;&lt;hr&gt;&#xA;&lt;h2 id=&#34;구조&#34;&gt;구조&lt;a class=&#34;anchor&#34; href=&#34;#%ea%b5%ac%ec%a1%b0&#34;&gt;#&lt;/a&gt;&lt;/h2&gt;&#xA;&lt;h3 id=&#34;전체-아키텍처&#34;&gt;전체 아키텍처&lt;a class=&#34;anchor&#34; href=&#34;#%ec%a0%84%ec%b2%b4-%ec%95%84%ed%82%a4%ed%85%8d%ec%b2%98&#34;&gt;#&lt;/a&gt;&lt;/h3&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;Input Image&#xA;      ↓&#xA;┌──────────────────┐&#xA;│ Condition Extractor │ (Canny, Pose, Depth 등)&#xA;└──────────────────┘&#xA;      ↓&#xA;Condition (edge/pose/depth map)&#xA;      ↓&#xA;┌───────────────────────────────────────────────┐&#xA;│                ControlNet                      │&#xA;│                                                │&#xA;│  ┌─────────────────┐    ┌─────────────────┐  │&#xA;│  │ Trainable Copy  │───→│   Zero Conv    │  │&#xA;│  │  of SD Encoder  │    │  (initialized 0)│  │&#xA;│  └─────────────────┘    └────────┬────────┘  │&#xA;│                                   ↓           │&#xA;│  ┌─────────────────────────────────────────┐ │&#xA;│  │        Locked Stable Diffusion          │ │&#xA;│  │     (original weights frozen)           │ │&#xA;│  └─────────────────────────────────────────┘ │&#xA;└───────────────────────────────────────────────┘&#xA;      ↓&#xA;Generated Image (following the condition)&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&#34;핵심-컴포넌트&#34;&gt;핵심 컴포넌트&lt;a class=&#34;anchor&#34; href=&#34;#%ed%95%b5%ec%8b%ac-%ec%bb%b4%ed%8f%ac%eb%84%8c%ed%8a%b8&#34;&gt;#&lt;/a&gt;&lt;/h3&gt;&#xA;&lt;table&gt;&#xA;  &lt;thead&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;th&gt;컴포넌트&lt;/th&gt;&#xA;          &lt;th&gt;설명&lt;/th&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/thead&gt;&#xA;  &lt;tbody&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;&lt;strong&gt;Locked Copy&lt;/strong&gt;&lt;/td&gt;&#xA;          &lt;td&gt;원본 SD 가중치 고정&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;&lt;strong&gt;Trainable Copy&lt;/strong&gt;&lt;/td&gt;&#xA;          &lt;td&gt;SD encoder의 학습 가능한 복사본&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;&lt;strong&gt;Zero Convolution&lt;/strong&gt;&lt;/td&gt;&#xA;          &lt;td&gt;0으로 초기화된 1×1 Conv&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/tbody&gt;&#xA;&lt;/table&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;zero-convolution&#34;&gt;Zero Convolution&lt;a class=&#34;anchor&#34; href=&#34;#zero-convolution&#34;&gt;#&lt;/a&gt;&lt;/h2&gt;&#xA;&lt;p&gt;학습 시작 시 ControlNet의 영향이 0:&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
