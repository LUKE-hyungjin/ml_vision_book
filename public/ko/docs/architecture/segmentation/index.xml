<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Segmentation on Vision Engineer 지식 가이드</title>
    <link>http://localhost:1313/ko/docs/architecture/segmentation/</link>
    <description>Recent content in Segmentation on Vision Engineer 지식 가이드</description>
    <generator>Hugo</generator>
    <language>ko-KR</language>
    <atom:link href="http://localhost:1313/ko/docs/architecture/segmentation/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>U-Net</title>
      <link>http://localhost:1313/ko/docs/architecture/segmentation/unet/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/ko/docs/architecture/segmentation/unet/</guid>
      <description>&lt;h1 id=&#34;u-net&#34;&gt;U-Net&lt;a class=&#34;anchor&#34; href=&#34;#u-net&#34;&gt;#&lt;/a&gt;&lt;/h1&gt;&#xA;&lt;h2 id=&#34;개요&#34;&gt;개요&lt;a class=&#34;anchor&#34; href=&#34;#%ea%b0%9c%ec%9a%94&#34;&gt;#&lt;/a&gt;&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;논문&lt;/strong&gt;: U-Net: Convolutional Networks for Biomedical Image Segmentation (2015)&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;저자&lt;/strong&gt;: Olaf Ronneberger, Philipp Fischer, Thomas Brox&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;핵심 기여&lt;/strong&gt;: Encoder-Decoder + Skip Connection으로 정밀한 segmentation&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;핵심-아이디어&#34;&gt;핵심 아이디어&lt;a class=&#34;anchor&#34; href=&#34;#%ed%95%b5%ec%8b%ac-%ec%95%84%ec%9d%b4%eb%94%94%ec%96%b4&#34;&gt;#&lt;/a&gt;&lt;/h2&gt;&#xA;&lt;blockquote class=&#39;book-hint &#39;&gt;&#xA;&lt;p&gt;&amp;ldquo;수축 경로(encoder)로 context를 잡고, 확장 경로(decoder)로 정밀한 localization&amp;rdquo;&lt;/p&gt;&#xA;&lt;/blockquote&gt;&lt;p&gt;의료 영상처럼 데이터가 적은 상황에서도 효과적으로 동작합니다.&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;구조&#34;&gt;구조&lt;a class=&#34;anchor&#34; href=&#34;#%ea%b5%ac%ec%a1%b0&#34;&gt;#&lt;/a&gt;&lt;/h2&gt;&#xA;&lt;h3 id=&#34;전체-아키텍처&#34;&gt;전체 아키텍처&lt;a class=&#34;anchor&#34; href=&#34;#%ec%a0%84%ec%b2%b4-%ec%95%84%ed%82%a4%ed%85%8d%ec%b2%98&#34;&gt;#&lt;/a&gt;&lt;/h3&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;Input (572×572)&#xA;    ↓&#xA;┌───────────────────────────────────────────────────────────┐&#xA;│                    Contracting Path                        │&#xA;│  [Conv3×3 → ReLU → Conv3×3 → ReLU → MaxPool] × 4          │&#xA;│   64 → 128 → 256 → 512 → 1024                              │&#xA;└───────────────────────────────────────────────────────────┘&#xA;    ↓&#xA;┌───────────────────────────────────────────────────────────┐&#xA;│                    Expanding Path                          │&#xA;│  [UpConv2×2 → Concat(skip) → Conv3×3 → ReLU × 2] × 4     │&#xA;│   1024 → 512 → 256 → 128 → 64                              │&#xA;└───────────────────────────────────────────────────────────┘&#xA;    ↓&#xA;Conv 1×1 → Output (388×388×num_classes)&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&#34;u자-형태&#34;&gt;U자 형태&lt;a class=&#34;anchor&#34; href=&#34;#u%ec%9e%90-%ed%98%95%ed%83%9c&#34;&gt;#&lt;/a&gt;&lt;/h3&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;Input                                           Output&#xA;  ↓                                               ↑&#xA;[Conv]─────────────────────────────────────→[UpConv+Concat]&#xA;  ↓                                               ↑&#xA;[Conv]───────────────────────────────→[UpConv+Concat]&#xA;  ↓                                         ↑&#xA;[Conv]─────────────────────────→[UpConv+Concat]&#xA;  ↓                               ↑&#xA;[Conv]──────────────────→[UpConv+Concat]&#xA;  ↓                    ↑&#xA;     [Bottleneck]&lt;/code&gt;&lt;/pre&gt;&lt;hr&gt;&#xA;&lt;h2 id=&#34;핵심-컴포넌트&#34;&gt;핵심 컴포넌트&lt;a class=&#34;anchor&#34; href=&#34;#%ed%95%b5%ec%8b%ac-%ec%bb%b4%ed%8f%ac%eb%84%8c%ed%8a%b8&#34;&gt;#&lt;/a&gt;&lt;/h2&gt;&#xA;&lt;h3 id=&#34;1-contracting-path-encoder&#34;&gt;1. Contracting Path (Encoder)&lt;a class=&#34;anchor&#34; href=&#34;#1-contracting-path-encoder&#34;&gt;#&lt;/a&gt;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;3×3 Conv (unpadded) + ReLU × 2&lt;/li&gt;&#xA;&lt;li&gt;2×2 Max Pooling (stride 2)&lt;/li&gt;&#xA;&lt;li&gt;채널 수 2배씩 증가&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;2-expanding-path-decoder&#34;&gt;2. Expanding Path (Decoder)&lt;a class=&#34;anchor&#34; href=&#34;#2-expanding-path-decoder&#34;&gt;#&lt;/a&gt;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;2×2 Up-convolution (채널 절반)&lt;/li&gt;&#xA;&lt;li&gt;Skip connection으로 encoder 특징 concat&lt;/li&gt;&#xA;&lt;li&gt;3×3 Conv + ReLU × 2&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;3-skip-connection&#34;&gt;3. Skip Connection&lt;a class=&#34;anchor&#34; href=&#34;#3-skip-connection&#34;&gt;#&lt;/a&gt;&lt;/h3&gt;&#xA;&lt;p&gt;Encoder의 고해상도 특징을 decoder로 전달:&lt;/p&gt;</description>
    </item>
    <item>
      <title>Mask R-CNN</title>
      <link>http://localhost:1313/ko/docs/architecture/segmentation/mask-rcnn/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/ko/docs/architecture/segmentation/mask-rcnn/</guid>
      <description>&lt;h1 id=&#34;mask-r-cnn&#34;&gt;Mask R-CNN&lt;a class=&#34;anchor&#34; href=&#34;#mask-r-cnn&#34;&gt;#&lt;/a&gt;&lt;/h1&gt;&#xA;&lt;h2 id=&#34;개요&#34;&gt;개요&lt;a class=&#34;anchor&#34; href=&#34;#%ea%b0%9c%ec%9a%94&#34;&gt;#&lt;/a&gt;&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;논문&lt;/strong&gt;: Mask R-CNN (2017)&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;저자&lt;/strong&gt;: Kaiming He, Georgia Gkioxari, Piotr Dollár, Ross Girshick (FAIR)&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;핵심 기여&lt;/strong&gt;: Faster R-CNN에 mask branch를 추가하여 instance segmentation&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;핵심-아이디어&#34;&gt;핵심 아이디어&lt;a class=&#34;anchor&#34; href=&#34;#%ed%95%b5%ec%8b%ac-%ec%95%84%ec%9d%b4%eb%94%94%ec%96%b4&#34;&gt;#&lt;/a&gt;&lt;/h2&gt;&#xA;&lt;blockquote class=&#39;book-hint &#39;&gt;&#xA;&lt;p&gt;&amp;ldquo;Faster R-CNN + Mask Branch = Instance Segmentation&amp;rdquo;&lt;/p&gt;&#xA;&lt;/blockquote&gt;&lt;p&gt;Detection과 segmentation을 동시에 수행하는 multi-task 모델입니다.&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;구조&#34;&gt;구조&lt;a class=&#34;anchor&#34; href=&#34;#%ea%b5%ac%ec%a1%b0&#34;&gt;#&lt;/a&gt;&lt;/h2&gt;&#xA;&lt;h3 id=&#34;전체-아키텍처&#34;&gt;전체 아키텍처&lt;a class=&#34;anchor&#34; href=&#34;#%ec%a0%84%ec%b2%b4-%ec%95%84%ed%82%a4%ed%85%8d%ec%b2%98&#34;&gt;#&lt;/a&gt;&lt;/h3&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;Input Image&#xA;    ↓&#xA;Backbone (ResNet + FPN)&#xA;    ↓&#xA;Region Proposal Network (RPN)&#xA;    ↓&#xA;RoI Align (not RoI Pooling!)&#xA;    ↓&#xA;┌─────────────────────────────────────────┐&#xA;│           Three Branches                 │&#xA;├─────────────┬─────────────┬─────────────┤&#xA;│ Classification │ Box Regression │ Mask Prediction │&#xA;│   (class)   │   (x,y,w,h)  │  (28×28 binary) │&#xA;└─────────────┴─────────────┴─────────────┘&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&#34;faster-r-cnn과의-차이&#34;&gt;Faster R-CNN과의 차이&lt;a class=&#34;anchor&#34; href=&#34;#faster-r-cnn%ea%b3%bc%ec%9d%98-%ec%b0%a8%ec%9d%b4&#34;&gt;#&lt;/a&gt;&lt;/h3&gt;&#xA;&lt;table&gt;&#xA;  &lt;thead&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;th&gt;구성 요소&lt;/th&gt;&#xA;          &lt;th&gt;Faster R-CNN&lt;/th&gt;&#xA;          &lt;th&gt;Mask R-CNN&lt;/th&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/thead&gt;&#xA;  &lt;tbody&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;RoI 처리&lt;/td&gt;&#xA;          &lt;td&gt;RoI Pooling&lt;/td&gt;&#xA;          &lt;td&gt;&lt;strong&gt;RoI Align&lt;/strong&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;출력&lt;/td&gt;&#xA;          &lt;td&gt;class, box&lt;/td&gt;&#xA;          &lt;td&gt;class, box, &lt;strong&gt;mask&lt;/strong&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;Backbone&lt;/td&gt;&#xA;          &lt;td&gt;ResNet&lt;/td&gt;&#xA;          &lt;td&gt;ResNet + &lt;strong&gt;FPN&lt;/strong&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/tbody&gt;&#xA;&lt;/table&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;핵심-컴포넌트&#34;&gt;핵심 컴포넌트&lt;a class=&#34;anchor&#34; href=&#34;#%ed%95%b5%ec%8b%ac-%ec%bb%b4%ed%8f%ac%eb%84%8c%ed%8a%b8&#34;&gt;#&lt;/a&gt;&lt;/h2&gt;&#xA;&lt;h3 id=&#34;1-roi-align&#34;&gt;1. RoI Align&lt;a class=&#34;anchor&#34; href=&#34;#1-roi-align&#34;&gt;#&lt;/a&gt;&lt;/h3&gt;&#xA;&lt;p&gt;RoI Pooling의 양자화 문제를 해결:&lt;/p&gt;</description>
    </item>
    <item>
      <title>SAM</title>
      <link>http://localhost:1313/ko/docs/architecture/segmentation/sam/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/ko/docs/architecture/segmentation/sam/</guid>
      <description>&lt;h1 id=&#34;sam-segment-anything-model&#34;&gt;SAM (Segment Anything Model)&lt;a class=&#34;anchor&#34; href=&#34;#sam-segment-anything-model&#34;&gt;#&lt;/a&gt;&lt;/h1&gt;&#xA;&lt;h2 id=&#34;개요&#34;&gt;개요&lt;a class=&#34;anchor&#34; href=&#34;#%ea%b0%9c%ec%9a%94&#34;&gt;#&lt;/a&gt;&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;논문&lt;/strong&gt;: Segment Anything (2023)&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;저자&lt;/strong&gt;: Alexander Kirillov et al. (Meta AI)&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;핵심 기여&lt;/strong&gt;: 프롬프트 기반의 범용 segmentation foundation model&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;핵심-아이디어&#34;&gt;핵심 아이디어&lt;a class=&#34;anchor&#34; href=&#34;#%ed%95%b5%ec%8b%ac-%ec%95%84%ec%9d%b4%eb%94%94%ec%96%b4&#34;&gt;#&lt;/a&gt;&lt;/h2&gt;&#xA;&lt;blockquote class=&#39;book-hint &#39;&gt;&#xA;&lt;p&gt;&amp;ldquo;한 번 학습으로 모든 객체를 segmentation&amp;rdquo;&lt;/p&gt;&#xA;&lt;/blockquote&gt;&lt;p&gt;Point, box, text 등 다양한 프롬프트로 원하는 객체를 분할합니다.&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;프로젝트-구성&#34;&gt;프로젝트 구성&lt;a class=&#34;anchor&#34; href=&#34;#%ed%94%84%eb%a1%9c%ec%a0%9d%ed%8a%b8-%ea%b5%ac%ec%84%b1&#34;&gt;#&lt;/a&gt;&lt;/h2&gt;&#xA;&lt;h3 id=&#34;세-가지-요소&#34;&gt;세 가지 요소&lt;a class=&#34;anchor&#34; href=&#34;#%ec%84%b8-%ea%b0%80%ec%a7%80-%ec%9a%94%ec%86%8c&#34;&gt;#&lt;/a&gt;&lt;/h3&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;strong&gt;Task&lt;/strong&gt;: Promptable segmentation&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Model&lt;/strong&gt;: SAM 아키텍처&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Data&lt;/strong&gt;: SA-1B 데이터셋 (11M 이미지, 1.1B 마스크)&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;구조&#34;&gt;구조&lt;a class=&#34;anchor&#34; href=&#34;#%ea%b5%ac%ec%a1%b0&#34;&gt;#&lt;/a&gt;&lt;/h2&gt;&#xA;&lt;h3 id=&#34;전체-아키텍처&#34;&gt;전체 아키텍처&lt;a class=&#34;anchor&#34; href=&#34;#%ec%a0%84%ec%b2%b4-%ec%95%84%ed%82%a4%ed%85%8d%ec%b2%98&#34;&gt;#&lt;/a&gt;&lt;/h3&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;┌─────────────────────────────────────────┐&#xA;│            Image Encoder                 │&#xA;│         (ViT-H, 실행 1회)                │&#xA;│    Image → Image Embeddings             │&#xA;└─────────────────────────────────────────┘&#xA;                    ↓&#xA;┌─────────────────────────────────────────┐&#xA;│           Prompt Encoder                 │&#xA;│   Points/Boxes/Text → Prompt Tokens     │&#xA;└─────────────────────────────────────────┘&#xA;                    ↓&#xA;┌─────────────────────────────────────────┐&#xA;│           Mask Decoder                   │&#xA;│   Image Emb + Prompt → Masks            │&#xA;└─────────────────────────────────────────┘&#xA;                    ↓&#xA;            Output Masks&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&#34;1-image-encoder&#34;&gt;1. Image Encoder&lt;a class=&#34;anchor&#34; href=&#34;#1-image-encoder&#34;&gt;#&lt;/a&gt;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;모델&lt;/strong&gt;: ViT-H (Vision Transformer Huge)&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;입력&lt;/strong&gt;: 1024×1024 이미지&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;출력&lt;/strong&gt;: 64×64 feature embedding&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;특징&lt;/strong&gt;: 이미지당 한 번만 실행 (0.15초)&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;2-prompt-encoder&#34;&gt;2. Prompt Encoder&lt;a class=&#34;anchor&#34; href=&#34;#2-prompt-encoder&#34;&gt;#&lt;/a&gt;&lt;/h3&gt;&#xA;&lt;p&gt;다양한 프롬프트 처리:&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
