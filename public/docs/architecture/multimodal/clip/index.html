<!DOCTYPE html>
<html lang="ko-KR" dir="ltr">
<head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script>
  <!--
Made with Book Theme
https://github.com/alex-shpak/hugo-book
-->

<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="description" content="CLIP (Contrastive Language-Image Pre-training)# 개요# 논문: Learning Transferable Visual Models From Natural Language Supervision (2021) 저자: Alec Radford et al. (OpenAI) 핵심 기여: 이미지와 텍스트를 같은 공간에 임베딩하여 zero-shot 분류 핵심 아이디어# “이미지와 텍스트 쌍을 대조 학습하여 공유 임베딩 공간 구축”
4억 개의 이미지-텍스트 쌍으로 학습하여, 한 번도 본 적 없는 클래스도 분류할 수 있습니다.
구조# 전체 아키텍처# ┌─────────────────┐ Image ────→ │ Image Encoder │ ────→ Image Embedding (512-d) │ (ViT or ResNet)│ ↓ └─────────────────┘ ↓ (cosine similarity) ↓ ┌─────────────────┐ ↓ Text ────→ │ Text Encoder │ ────→ Text Embedding (512-d) │ (Transformer) │ └─────────────────┘인코더 옵션# Image Encoder Text Encoder ViT-B/32, ViT-B/16, ViT-L/14 Transformer (12-layer) ResNet-50, ResNet-101 Contrastive Learning# 학습 방식# 배치 내 N개의 이미지-텍스트 쌍:
">
<meta name="theme-color" media="(prefers-color-scheme: light)" content="#ffffff">
<meta name="theme-color" media="(prefers-color-scheme: dark)" content="#343a40">
<meta name="color-scheme" content="light dark"><meta property="og:url" content="http://localhost:1313/docs/architecture/multimodal/clip/">
  <meta property="og:site_name" content="Vision Engineer 지식 가이드">
  <meta property="og:title" content="CLIP">
  <meta property="og:description" content="CLIP (Contrastive Language-Image Pre-training)# 개요# 논문: Learning Transferable Visual Models From Natural Language Supervision (2021) 저자: Alec Radford et al. (OpenAI) 핵심 기여: 이미지와 텍스트를 같은 공간에 임베딩하여 zero-shot 분류 핵심 아이디어# “이미지와 텍스트 쌍을 대조 학습하여 공유 임베딩 공간 구축”
4억 개의 이미지-텍스트 쌍으로 학습하여, 한 번도 본 적 없는 클래스도 분류할 수 있습니다.
구조# 전체 아키텍처# ┌─────────────────┐ Image ────→ │ Image Encoder │ ────→ Image Embedding (512-d) │ (ViT or ResNet)│ ↓ └─────────────────┘ ↓ (cosine similarity) ↓ ┌─────────────────┐ ↓ Text ────→ │ Text Encoder │ ────→ Text Embedding (512-d) │ (Transformer) │ └─────────────────┘인코더 옵션# Image Encoder Text Encoder ViT-B/32, ViT-B/16, ViT-L/14 Transformer (12-layer) ResNet-50, ResNet-101 Contrastive Learning# 학습 방식# 배치 내 N개의 이미지-텍스트 쌍:">
  <meta property="og:locale" content="ko_KR">
  <meta property="og:type" content="article">
    <meta property="article:section" content="docs">


  <meta itemprop="name" content="CLIP">
  <meta itemprop="description" content="CLIP (Contrastive Language-Image Pre-training)# 개요# 논문: Learning Transferable Visual Models From Natural Language Supervision (2021) 저자: Alec Radford et al. (OpenAI) 핵심 기여: 이미지와 텍스트를 같은 공간에 임베딩하여 zero-shot 분류 핵심 아이디어# “이미지와 텍스트 쌍을 대조 학습하여 공유 임베딩 공간 구축”
4억 개의 이미지-텍스트 쌍으로 학습하여, 한 번도 본 적 없는 클래스도 분류할 수 있습니다.
구조# 전체 아키텍처# ┌─────────────────┐ Image ────→ │ Image Encoder │ ────→ Image Embedding (512-d) │ (ViT or ResNet)│ ↓ └─────────────────┘ ↓ (cosine similarity) ↓ ┌─────────────────┐ ↓ Text ────→ │ Text Encoder │ ────→ Text Embedding (512-d) │ (Transformer) │ └─────────────────┘인코더 옵션# Image Encoder Text Encoder ViT-B/32, ViT-B/16, ViT-L/14 Transformer (12-layer) ResNet-50, ResNet-101 Contrastive Learning# 학습 방식# 배치 내 N개의 이미지-텍스트 쌍:">
  <meta itemprop="wordCount" content="506">

<title>CLIP | Vision Engineer 지식 가이드</title>
<link rel="icon" href="/favicon.png" >
<link rel="manifest" href="/manifest.json">
<link rel="canonical" href="http://localhost:1313/docs/architecture/multimodal/clip/">
<link rel="stylesheet" href="/book.min.6970156cec683193d93c9c4edaf0d56574e4361df2e0c1be4f697ae81c3ba55f.css" integrity="sha256-aXAVbOxoMZPZPJxO2vDVZXTkNh3y4MG&#43;T2l66Bw7pV8=" crossorigin="anonymous">


  <script defer src="/fuse.min.js"></script>
  <script defer src="/ko.search.min.26f28136458cea7ff1c69490935901eb5c29bceec55294f9efe562732e8a3b1a.js" integrity="sha256-JvKBNkWM6n/xxpSQk1kB61wpvO7FUpT57&#43;Vicy6KOxo=" crossorigin="anonymous"></script>



  
</head>
<body dir="ltr" class="book-kind-page book-type-docs">
  <input type="checkbox" class="hidden toggle" id="menu-control" />
  <input type="checkbox" class="hidden toggle" id="toc-control" />
  <main class="container flex">
    
<aside class="book-menu">
  <div class="book-menu-content">
    
  <nav>
<h2 class="book-brand">
  <a class="flex align-center" href="/"><span>Vision Engineer 지식 가이드</span>
  </a>
</h2>


<div class="book-search hidden">
  <input id="book-search-input" type="text" 
    placeholder="Search"
    aria-label="Search"
    maxlength="64" data-hotkeys="s/" />
  <div class="book-search-spinner hidden"></div>
  <ul id="book-search-results"></ul>
</div>
<script>document.querySelector(".book-search").classList.remove("hidden")</script>



  


  
    
  



<ul class="book-languages">
  <li>
    <input type="checkbox" id="languages" class="toggle" />
    <label for="languages" class="flex">
      <a role="button">
        <img src="/icons/translate.svg" class="book-icon" alt="Languages" />
        한국어
      </a>
      <img src="/icons/chevron-right.svg" class="book-icon" alt="Expand" />
    </label>

    <ul>
      
      <li>
        <a href="/en/" class="flex flex-auto">
          English
        </a>
      </li>
      
    </ul>
  </li>
</ul>












  
  <ul>
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-14bcba7439f342435c91a57530ca56c8" class="toggle"  />
    <label for="section-14bcba7439f342435c91a57530ca56c8" class="flex">
      <a href="/docs/timeline/" class="">
        타임라인</a>
      <img src="/icons/chevron-right.svg" class="book-icon" alt="Expand" />
    </label>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-cb9657695dbd536c3a44d019c4d6ef98" class="toggle"  />
    <label for="section-cb9657695dbd536c3a44d019c4d6ef98" class="flex">
      <a href="/docs/topdown/" class="">
        Top-Down</a>
      <img src="/icons/chevron-right.svg" class="book-icon" alt="Expand" />
    </label>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-e7f22db027b1c591ed84a4d4d3a6014f" class="toggle"  />
    <label for="section-e7f22db027b1c591ed84a4d4d3a6014f" class="flex">
      <a href="/docs/bottomup/" class="">
        Bottom-Up</a>
      <img src="/icons/chevron-right.svg" class="book-icon" alt="Expand" />
    </label>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-ce31bba1d1f88a1d133a7e7232f1b4ec" class="toggle"  />
    <label for="section-ce31bba1d1f88a1d133a7e7232f1b4ec" class="flex">
      <a href="/docs/math/" class="">
        수학</a>
      <img src="/icons/chevron-right.svg" class="book-icon" alt="Expand" />
    </label>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-32f2aee524dad19f5100855d6e2014e6" class="toggle" checked />
    <label for="section-32f2aee524dad19f5100855d6e2014e6" class="flex">
      <a href="/docs/architecture/" class="">
        아키텍처</a>
      <img src="/icons/chevron-right.svg" class="book-icon" alt="Expand" />
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-47444199c3019e8b479623bc90a9bd74" class="toggle"  />
    <label for="section-47444199c3019e8b479623bc90a9bd74" class="flex">
      <a href="/docs/architecture/classical/" class="">
        Classical CV</a>
      <img src="/icons/chevron-right.svg" class="book-icon" alt="Expand" />
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/docs/architecture/classical/sift-hog/" class="">
      SIFT &amp; HOG</a>
  

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-7bf44239f7ce2c72600738f8c315efe4" class="toggle"  />
    <label for="section-7bf44239f7ce2c72600738f8c315efe4" class="flex">
      <a href="/docs/architecture/cnn/" class="">
        CNN</a>
      <img src="/icons/chevron-right.svg" class="book-icon" alt="Expand" />
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/docs/architecture/cnn/alexnet/" class="">
      AlexNet</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/architecture/cnn/vgg/" class="">
      VGG</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/architecture/cnn/resnet/" class="">
      ResNet</a>
  

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-274b800b12326ef4e06255cf5f15c308" class="toggle"  />
    <label for="section-274b800b12326ef4e06255cf5f15c308" class="flex">
      <a href="/docs/architecture/detection/" class="">
        Detection</a>
      <img src="/icons/chevron-right.svg" class="book-icon" alt="Expand" />
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/docs/architecture/detection/faster-rcnn/" class="">
      Faster R-CNN</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/architecture/detection/yolo/" class="">
      YOLO</a>
  

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-7246e67fd6c549f3bd6240d998b23a6f" class="toggle"  />
    <label for="section-7246e67fd6c549f3bd6240d998b23a6f" class="flex">
      <a href="/docs/architecture/segmentation/" class="">
        Segmentation</a>
      <img src="/icons/chevron-right.svg" class="book-icon" alt="Expand" />
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/docs/architecture/segmentation/unet/" class="">
      U-Net</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/architecture/segmentation/mask-rcnn/" class="">
      Mask R-CNN</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/architecture/segmentation/sam/" class="">
      SAM</a>
  

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-3a9f4e0826e1b9e72550db30b2adcad7" class="toggle"  />
    <label for="section-3a9f4e0826e1b9e72550db30b2adcad7" class="flex">
      <a href="/docs/architecture/transformer/" class="">
        Transformer</a>
      <img src="/icons/chevron-right.svg" class="book-icon" alt="Expand" />
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/docs/architecture/transformer/vit/" class="">
      ViT</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/architecture/transformer/dit/" class="">
      DiT</a>
  

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-2902afa0a62febfd7a5eb243df871e8c" class="toggle"  />
    <label for="section-2902afa0a62febfd7a5eb243df871e8c" class="flex">
      <a href="/docs/architecture/generative/" class="">
        Generative</a>
      <img src="/icons/chevron-right.svg" class="book-icon" alt="Expand" />
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/docs/architecture/generative/vae/" class="">
      VAE</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/architecture/generative/gan/" class="">
      GAN</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/architecture/generative/stable-diffusion/" class="">
      Stable Diffusion</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/architecture/generative/controlnet/" class="">
      ControlNet</a>
  

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-1670f136e85bf39bce97c9ee224d29d9" class="toggle" checked />
    <label for="section-1670f136e85bf39bce97c9ee224d29d9" class="flex">
      <a href="/docs/architecture/multimodal/" class="">
        Multimodal</a>
      <img src="/icons/chevron-right.svg" class="book-icon" alt="Expand" />
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/docs/architecture/multimodal/clip/" class="active">
      CLIP</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/architecture/multimodal/vlm/" class="">
      VLM</a>
  

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-fc1b0b4545ce791b47ab3fe55b854e56" class="toggle"  />
    <label for="section-fc1b0b4545ce791b47ab3fe55b854e56" class="flex">
      <a href="/docs/architecture/3d/" class="">
        3D Vision</a>
      <img src="/icons/chevron-right.svg" class="book-icon" alt="Expand" />
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/docs/architecture/3d/nerf/" class="">
      NeRF</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/architecture/3d/3dgs/" class="">
      3D Gaussian Splatting</a>
  

        </li>
      
    
  </ul>

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-cd575cc6fd4e25b684b552791b7a009a" class="toggle"  />
    <label for="section-cd575cc6fd4e25b684b552791b7a009a" class="flex">
      <a href="/docs/task/" class="">
        태스크</a>
      <img src="/icons/chevron-right.svg" class="book-icon" alt="Expand" />
    </label>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-fb690f19903e1435676f710c928c9ad4" class="toggle"  />
    <label for="section-fb690f19903e1435676f710c928c9ad4" class="flex">
      <a href="/docs/etc/" class="">
        기타 자료</a>
      <img src="/icons/chevron-right.svg" class="book-icon" alt="Expand" />
    </label>
  

          
  <ul>
    
  </ul>

        </li>
      
    
  </ul>













</nav>




  <script>(function(){var e=document.querySelector("aside .book-menu-content");addEventListener("beforeunload",function(){localStorage.setItem("menu.scrollTop",e.scrollTop)}),e.scrollTop=localStorage.getItem("menu.scrollTop")})()</script>



  </div>
</aside>
 

    <div class="book-page">
      <header class="book-header hidden">
        
  <div class="flex align-center justify-between">
  <label for="menu-control">
    <img src="/icons/menu.svg" class="book-icon" alt="Menu" />
  </label>

  <h3>CLIP</h3>

  <label for="toc-control">
    
    <img src="/icons/toc.svg" class="book-icon" alt="Table of Contents" />
    
  </label>
</div>


  
  <aside class="hidden">
    
  
<nav id="TableOfContents">
  <ul>
    <li><a href="#개요">개요</a></li>
    <li><a href="#핵심-아이디어">핵심 아이디어</a></li>
    <li><a href="#구조">구조</a>
      <ul>
        <li><a href="#전체-아키텍처">전체 아키텍처</a></li>
        <li><a href="#인코더-옵션">인코더 옵션</a></li>
      </ul>
    </li>
    <li><a href="#contrastive-learning">Contrastive Learning</a>
      <ul>
        <li><a href="#학습-방식">학습 방식</a></li>
        <li><a href="#손실-함수">손실 함수</a></li>
        <li><a href="#대칭적-학습">대칭적 학습</a></li>
      </ul>
    </li>
    <li><a href="#zero-shot-classification">Zero-shot Classification</a>
      <ul>
        <li><a href="#prompt-engineering">Prompt Engineering</a></li>
      </ul>
    </li>
    <li><a href="#구현-예시">구현 예시</a>
      <ul>
        <li><a href="#기본-사용">기본 사용</a></li>
        <li><a href="#openclip-open-source">OpenCLIP (open source)</a></li>
      </ul>
    </li>
    <li><a href="#성능">성능</a>
      <ul>
        <li><a href="#zero-shot-imagenet">Zero-shot ImageNet</a></li>
      </ul>
    </li>
    <li><a href="#clip의-활용">CLIP의 활용</a>
      <ul>
        <li><a href="#1-image-text-retrieval">1. Image-Text Retrieval</a></li>
        <li><a href="#2-stable-diffusion의-text-encoder">2. Stable Diffusion의 Text Encoder</a></li>
        <li><a href="#3-이미지-유사도-검색">3. 이미지 유사도 검색</a></li>
        <li><a href="#4-clip-score-이미지-텍스트-정합성">4. CLIP Score (이미지-텍스트 정합성)</a></li>
      </ul>
    </li>
    <li><a href="#한계점">한계점</a></li>
    <li><a href="#관련-콘텐츠">관련 콘텐츠</a></li>
  </ul>
</nav>



  </aside>
  
 
      </header>

      
      
  <article class="markdown book-article"><h1 id="clip-contrastive-language-image-pre-training">CLIP (Contrastive Language-Image Pre-training)<a class="anchor" href="#clip-contrastive-language-image-pre-training">#</a></h1>
<h2 id="개요">개요<a class="anchor" href="#%ea%b0%9c%ec%9a%94">#</a></h2>
<ul>
<li><strong>논문</strong>: Learning Transferable Visual Models From Natural Language Supervision (2021)</li>
<li><strong>저자</strong>: Alec Radford et al. (OpenAI)</li>
<li><strong>핵심 기여</strong>: 이미지와 텍스트를 같은 공간에 임베딩하여 zero-shot 분류</li>
</ul>
<h2 id="핵심-아이디어">핵심 아이디어<a class="anchor" href="#%ed%95%b5%ec%8b%ac-%ec%95%84%ec%9d%b4%eb%94%94%ec%96%b4">#</a></h2>
<blockquote class='book-hint '>
<p>&ldquo;이미지와 텍스트 쌍을 대조 학습하여 공유 임베딩 공간 구축&rdquo;</p>
</blockquote><p>4억 개의 이미지-텍스트 쌍으로 학습하여, 한 번도 본 적 없는 클래스도 분류할 수 있습니다.</p>
<hr>
<h2 id="구조">구조<a class="anchor" href="#%ea%b5%ac%ec%a1%b0">#</a></h2>
<h3 id="전체-아키텍처">전체 아키텍처<a class="anchor" href="#%ec%a0%84%ec%b2%b4-%ec%95%84%ed%82%a4%ed%85%8d%ec%b2%98">#</a></h3>
<pre tabindex="0"><code>            ┌─────────────────┐
Image ────→ │  Image Encoder  │ ────→ Image Embedding (512-d)
            │  (ViT or ResNet)│                 ↓
            └─────────────────┘                 ↓ (cosine similarity)
                                                ↓
            ┌─────────────────┐                 ↓
Text  ────→ │   Text Encoder  │ ────→ Text Embedding (512-d)
            │  (Transformer)  │
            └─────────────────┘</code></pre><h3 id="인코더-옵션">인코더 옵션<a class="anchor" href="#%ec%9d%b8%ec%bd%94%eb%8d%94-%ec%98%b5%ec%85%98">#</a></h3>
<table>
  <thead>
      <tr>
          <th>Image Encoder</th>
          <th>Text Encoder</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td>ViT-B/32, ViT-B/16, ViT-L/14</td>
          <td>Transformer (12-layer)</td>
      </tr>
      <tr>
          <td>ResNet-50, ResNet-101</td>
          <td></td>
      </tr>
  </tbody>
</table>
<hr>
<h2 id="contrastive-learning">Contrastive Learning<a class="anchor" href="#contrastive-learning">#</a></h2>
<h3 id="학습-방식">학습 방식<a class="anchor" href="#%ed%95%99%ec%8a%b5-%eb%b0%a9%ec%8b%9d">#</a></h3>
<p>배치 내 N개의 이미지-텍스트 쌍:</p>
<pre tabindex="0"><code>       Text1   Text2   Text3   ...   TextN
Image1  [✓]    [✗]     [✗]           [✗]
Image2  [✗]    [✓]     [✗]           [✗]
Image3  [✗]    [✗]     [✓]           [✗]
  ...
ImageN  [✗]    [✗]     [✗]           [✓]</code></pre><ul>
<li>대각선: 매칭 쌍 (positive) → 가깝게</li>
<li>비대각선: 비매칭 쌍 (negative) → 멀게</li>
</ul>
<h3 id="손실-함수">손실 함수<a class="anchor" href="#%ec%86%90%ec%8b%a4-%ed%95%a8%ec%88%98">#</a></h3>
<p>$$L = -\frac{1}{N}\sum_{i=1}^{N} \log \frac{\exp(\text{sim}(I_i, T_i)/\tau)}{\sum_{j=1}^{N}\exp(\text{sim}(I_i, T_j)/\tau)}$$</p>
<ul>
<li>$\text{sim}$: cosine similarity</li>
<li>$\tau$: temperature (학습 가능)</li>
</ul>
<h3 id="대칭적-학습">대칭적 학습<a class="anchor" href="#%eb%8c%80%ec%b9%ad%ec%a0%81-%ed%95%99%ec%8a%b5">#</a></h3>
<p>Image→Text와 Text→Image 양방향으로 학습:</p>
<p>$$L_{total} = \frac{1}{2}(L_{I \to T} + L_{T \to I})$$</p>
<hr>
<h2 id="zero-shot-classification">Zero-shot Classification<a class="anchor" href="#zero-shot-classification">#</a></h2>
<p>학습 없이 새로운 클래스 분류:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># 1. 클래스 이름을 텍스트 임베딩으로</span>
</span></span><span style="display:flex;"><span>classes <span style="color:#f92672">=</span> [<span style="color:#e6db74">&#34;a photo of a dog&#34;</span>, <span style="color:#e6db74">&#34;a photo of a cat&#34;</span>, <span style="color:#f92672">...</span>]
</span></span><span style="display:flex;"><span>text_embeddings <span style="color:#f92672">=</span> model<span style="color:#f92672">.</span>encode_text(classes)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 2. 이미지 임베딩</span>
</span></span><span style="display:flex;"><span>image_embedding <span style="color:#f92672">=</span> model<span style="color:#f92672">.</span>encode_image(image)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 3. 가장 유사한 클래스 선택</span>
</span></span><span style="display:flex;"><span>similarity <span style="color:#f92672">=</span> image_embedding <span style="color:#f92672">@</span> text_embeddings<span style="color:#f92672">.</span>T
</span></span><span style="display:flex;"><span>prediction <span style="color:#f92672">=</span> similarity<span style="color:#f92672">.</span>argmax()</span></span></code></pre></div><h3 id="prompt-engineering">Prompt Engineering<a class="anchor" href="#prompt-engineering">#</a></h3>
<p>분류 성능은 프롬프트에 따라 달라집니다:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># 기본</span>
</span></span><span style="display:flex;"><span><span style="color:#e6db74">&#34;dog&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 개선</span>
</span></span><span style="display:flex;"><span><span style="color:#e6db74">&#34;a photo of a dog&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 더 개선 (앙상블)</span>
</span></span><span style="display:flex;"><span>templates <span style="color:#f92672">=</span> [
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;a photo of a </span><span style="color:#e6db74">{}</span><span style="color:#e6db74">&#34;</span>,
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;a blurry photo of a </span><span style="color:#e6db74">{}</span><span style="color:#e6db74">&#34;</span>,
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;a sculpture of a </span><span style="color:#e6db74">{}</span><span style="color:#e6db74">&#34;</span>,
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">...</span>
</span></span><span style="display:flex;"><span>]</span></span></code></pre></div><hr>
<h2 id="구현-예시">구현 예시<a class="anchor" href="#%ea%b5%ac%ed%98%84-%ec%98%88%ec%8b%9c">#</a></h2>
<h3 id="기본-사용">기본 사용<a class="anchor" href="#%ea%b8%b0%eb%b3%b8-%ec%82%ac%ec%9a%a9">#</a></h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">import</span> torch
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> clip
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> PIL <span style="color:#f92672">import</span> Image
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 모델 로드</span>
</span></span><span style="display:flex;"><span>device <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;cuda&#34;</span> <span style="color:#66d9ef">if</span> torch<span style="color:#f92672">.</span>cuda<span style="color:#f92672">.</span>is_available() <span style="color:#66d9ef">else</span> <span style="color:#e6db74">&#34;cpu&#34;</span>
</span></span><span style="display:flex;"><span>model, preprocess <span style="color:#f92672">=</span> clip<span style="color:#f92672">.</span>load(<span style="color:#e6db74">&#34;ViT-B/32&#34;</span>, device<span style="color:#f92672">=</span>device)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 이미지 전처리</span>
</span></span><span style="display:flex;"><span>image <span style="color:#f92672">=</span> preprocess(Image<span style="color:#f92672">.</span>open(<span style="color:#e6db74">&#34;image.jpg&#34;</span>))<span style="color:#f92672">.</span>unsqueeze(<span style="color:#ae81ff">0</span>)<span style="color:#f92672">.</span>to(device)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 텍스트 토큰화</span>
</span></span><span style="display:flex;"><span>text <span style="color:#f92672">=</span> clip<span style="color:#f92672">.</span>tokenize([<span style="color:#e6db74">&#34;a dog&#34;</span>, <span style="color:#e6db74">&#34;a cat&#34;</span>, <span style="color:#e6db74">&#34;a bird&#34;</span>])<span style="color:#f92672">.</span>to(device)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 유사도 계산</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">with</span> torch<span style="color:#f92672">.</span>no_grad():
</span></span><span style="display:flex;"><span>    image_features <span style="color:#f92672">=</span> model<span style="color:#f92672">.</span>encode_image(image)
</span></span><span style="display:flex;"><span>    text_features <span style="color:#f92672">=</span> model<span style="color:#f92672">.</span>encode_text(text)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># 정규화</span>
</span></span><span style="display:flex;"><span>    image_features <span style="color:#f92672">/=</span> image_features<span style="color:#f92672">.</span>norm(dim<span style="color:#f92672">=-</span><span style="color:#ae81ff">1</span>, keepdim<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>)
</span></span><span style="display:flex;"><span>    text_features <span style="color:#f92672">/=</span> text_features<span style="color:#f92672">.</span>norm(dim<span style="color:#f92672">=-</span><span style="color:#ae81ff">1</span>, keepdim<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># 유사도</span>
</span></span><span style="display:flex;"><span>    similarity <span style="color:#f92672">=</span> (<span style="color:#ae81ff">100.0</span> <span style="color:#f92672">*</span> image_features <span style="color:#f92672">@</span> text_features<span style="color:#f92672">.</span>T)<span style="color:#f92672">.</span>softmax(dim<span style="color:#f92672">=-</span><span style="color:#ae81ff">1</span>)
</span></span><span style="display:flex;"><span>    print(similarity)  <span style="color:#75715e"># [0.95, 0.03, 0.02]</span></span></span></code></pre></div><h3 id="openclip-open-source">OpenCLIP (open source)<a class="anchor" href="#openclip-open-source">#</a></h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">import</span> open_clip
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> torch
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>model, _, preprocess <span style="color:#f92672">=</span> open_clip<span style="color:#f92672">.</span>create_model_and_transforms(
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#39;ViT-B-32&#39;</span>,
</span></span><span style="display:flex;"><span>    pretrained<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;laion2b_s34b_b79k&#39;</span>
</span></span><span style="display:flex;"><span>)
</span></span><span style="display:flex;"><span>tokenizer <span style="color:#f92672">=</span> open_clip<span style="color:#f92672">.</span>get_tokenizer(<span style="color:#e6db74">&#39;ViT-B-32&#39;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 사용법 동일</span></span></span></code></pre></div><hr>
<h2 id="성능">성능<a class="anchor" href="#%ec%84%b1%eb%8a%a5">#</a></h2>
<h3 id="zero-shot-imagenet">Zero-shot ImageNet<a class="anchor" href="#zero-shot-imagenet">#</a></h3>
<table>
  <thead>
      <tr>
          <th>Model</th>
          <th>Top-1 Accuracy</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td>CLIP ViT-B/32</td>
          <td>63.2%</td>
      </tr>
      <tr>
          <td>CLIP ViT-B/16</td>
          <td>68.3%</td>
      </tr>
      <tr>
          <td>CLIP ViT-L/14</td>
          <td>75.5%</td>
      </tr>
      <tr>
          <td>CLIP ViT-L/14@336</td>
          <td>76.2%</td>
      </tr>
  </tbody>
</table>
<p>지도 학습 없이도 상당한 성능을 달성합니다.</p>
<hr>
<h2 id="clip의-활용">CLIP의 활용<a class="anchor" href="#clip%ec%9d%98-%ed%99%9c%ec%9a%a9">#</a></h2>
<h3 id="1-image-text-retrieval">1. Image-Text Retrieval<a class="anchor" href="#1-image-text-retrieval">#</a></h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># 텍스트로 이미지 검색</span>
</span></span><span style="display:flex;"><span>query_embedding <span style="color:#f92672">=</span> model<span style="color:#f92672">.</span>encode_text(<span style="color:#e6db74">&#34;a red car&#34;</span>)
</span></span><span style="display:flex;"><span>similarities <span style="color:#f92672">=</span> query_embedding <span style="color:#f92672">@</span> image_database<span style="color:#f92672">.</span>T
</span></span><span style="display:flex;"><span>top_images <span style="color:#f92672">=</span> similarities<span style="color:#f92672">.</span>argsort(descending<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>)[:<span style="color:#ae81ff">10</span>]</span></span></code></pre></div><h3 id="2-stable-diffusion의-text-encoder">2. Stable Diffusion의 Text Encoder<a class="anchor" href="#2-stable-diffusion%ec%9d%98-text-encoder">#</a></h3>
<pre tabindex="0"><code>Text Prompt → CLIP Text Encoder → Conditioning</code></pre><h3 id="3-이미지-유사도-검색">3. 이미지 유사도 검색<a class="anchor" href="#3-%ec%9d%b4%eb%af%b8%ec%a7%80-%ec%9c%a0%ec%82%ac%eb%8f%84-%ea%b2%80%ec%83%89">#</a></h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>img1_feat <span style="color:#f92672">=</span> model<span style="color:#f92672">.</span>encode_image(img1)
</span></span><span style="display:flex;"><span>img2_feat <span style="color:#f92672">=</span> model<span style="color:#f92672">.</span>encode_image(img2)
</span></span><span style="display:flex;"><span>similarity <span style="color:#f92672">=</span> (img1_feat <span style="color:#f92672">@</span> img2_feat<span style="color:#f92672">.</span>T)<span style="color:#f92672">.</span>item()</span></span></code></pre></div><h3 id="4-clip-score-이미지-텍스트-정합성">4. CLIP Score (이미지-텍스트 정합성)<a class="anchor" href="#4-clip-score-%ec%9d%b4%eb%af%b8%ec%a7%80-%ed%85%8d%ec%8a%a4%ed%8a%b8-%ec%a0%95%ed%95%a9%ec%84%b1">#</a></h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">clip_score</span>(image, text):
</span></span><span style="display:flex;"><span>    img_feat <span style="color:#f92672">=</span> model<span style="color:#f92672">.</span>encode_image(image)
</span></span><span style="display:flex;"><span>    txt_feat <span style="color:#f92672">=</span> model<span style="color:#f92672">.</span>encode_text(text)
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> (img_feat <span style="color:#f92672">@</span> txt_feat<span style="color:#f92672">.</span>T)<span style="color:#f92672">.</span>item()</span></span></code></pre></div><hr>
<h2 id="한계점">한계점<a class="anchor" href="#%ed%95%9c%ea%b3%84%ec%a0%90">#</a></h2>
<ul>
<li><strong>세밀한 이해 부족</strong>: 개수, 공간 관계, 텍스트 인식</li>
<li><strong>편향</strong>: 학습 데이터의 편향 반영</li>
<li><strong>일부 도메인 약함</strong>: 의료, 위성 등 특수 도메인</li>
</ul>
<hr>
<h2 id="관련-콘텐츠">관련 콘텐츠<a class="anchor" href="#%ea%b4%80%eb%a0%a8-%ec%bd%98%ed%85%90%ec%b8%a0">#</a></h2>
<ul>
<li><a href="/docs/math/contrastive">Contrastive Learning</a> - 수학적 기초</li>
<li><a href="/docs/architecture/transformer/vit">ViT</a> - Image encoder</li>
<li><a href="/docs/architecture/multimodal/vlm">VLM</a> - CLIP 발전형</li>
<li><a href="/docs/architecture/generative/stable-diffusion">Stable Diffusion</a> - CLIP 활용</li>
</ul>
</article>
 
      

      <footer class="book-footer">
        
  <div class="flex flex-wrap justify-between">

<div>

</div>

<div>

</div>

</div>





  
  
  
  <div class="flex flex-wrap justify-between">
    <span>
    
      <a href="/docs/architecture/multimodal/" class="flex align-center">
        <img src="/icons/backward.svg" class="book-icon" alt="Backward" />
        <span>Multimodal</span>
      </a>
    
    </span>
    <span>
    
      <a href="/docs/architecture/multimodal/vlm/" class="flex align-center">
        <span>VLM</span>
        <img src="/icons/forward.svg" class="book-icon" alt="Forward" />
      </a>
    
    </span>
  </div>
  


 
        
  
  <div class="book-comments">

</div>
  
 
        
        
  
 
        
  
  
    <script>(function(){document.querySelectorAll("pre:has(code)").forEach(e=>{e.addEventListener("click",e.focus),e.addEventListener("copy",function(t){if(t.preventDefault(),navigator.clipboard){const t=window.getSelection().toString()||e.textContent;navigator.clipboard.writeText(t)}})})})()</script>
  

      </footer>

      <label for="menu-control" class="hidden book-menu-overlay"></label>
    </div>

    
  
  <aside class="book-toc">
    <div class="book-toc-content">
      
  
<nav id="TableOfContents">
  <ul>
    <li><a href="#개요">개요</a></li>
    <li><a href="#핵심-아이디어">핵심 아이디어</a></li>
    <li><a href="#구조">구조</a>
      <ul>
        <li><a href="#전체-아키텍처">전체 아키텍처</a></li>
        <li><a href="#인코더-옵션">인코더 옵션</a></li>
      </ul>
    </li>
    <li><a href="#contrastive-learning">Contrastive Learning</a>
      <ul>
        <li><a href="#학습-방식">학습 방식</a></li>
        <li><a href="#손실-함수">손실 함수</a></li>
        <li><a href="#대칭적-학습">대칭적 학습</a></li>
      </ul>
    </li>
    <li><a href="#zero-shot-classification">Zero-shot Classification</a>
      <ul>
        <li><a href="#prompt-engineering">Prompt Engineering</a></li>
      </ul>
    </li>
    <li><a href="#구현-예시">구현 예시</a>
      <ul>
        <li><a href="#기본-사용">기본 사용</a></li>
        <li><a href="#openclip-open-source">OpenCLIP (open source)</a></li>
      </ul>
    </li>
    <li><a href="#성능">성능</a>
      <ul>
        <li><a href="#zero-shot-imagenet">Zero-shot ImageNet</a></li>
      </ul>
    </li>
    <li><a href="#clip의-활용">CLIP의 활용</a>
      <ul>
        <li><a href="#1-image-text-retrieval">1. Image-Text Retrieval</a></li>
        <li><a href="#2-stable-diffusion의-text-encoder">2. Stable Diffusion의 Text Encoder</a></li>
        <li><a href="#3-이미지-유사도-검색">3. 이미지 유사도 검색</a></li>
        <li><a href="#4-clip-score-이미지-텍스트-정합성">4. CLIP Score (이미지-텍스트 정합성)</a></li>
      </ul>
    </li>
    <li><a href="#한계점">한계점</a></li>
    <li><a href="#관련-콘텐츠">관련 콘텐츠</a></li>
  </ul>
</nav>



    </div>
  </aside>
  
 
  </main>

  
</body>
</html>




















