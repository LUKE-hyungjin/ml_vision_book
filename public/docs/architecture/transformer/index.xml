<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Transformer on Vision Engineer 지식 가이드</title>
    <link>http://localhost:1313/docs/architecture/transformer/</link>
    <description>Recent content in Transformer on Vision Engineer 지식 가이드</description>
    <generator>Hugo</generator>
    <language>ko-KR</language>
    <atom:link href="http://localhost:1313/docs/architecture/transformer/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>ViT</title>
      <link>http://localhost:1313/docs/architecture/transformer/vit/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/architecture/transformer/vit/</guid>
      <description>&lt;h1 id=&#34;vit-vision-transformer&#34;&gt;ViT (Vision Transformer)&lt;a class=&#34;anchor&#34; href=&#34;#vit-vision-transformer&#34;&gt;#&lt;/a&gt;&lt;/h1&gt;&#xA;&lt;h2 id=&#34;개요&#34;&gt;개요&lt;a class=&#34;anchor&#34; href=&#34;#%ea%b0%9c%ec%9a%94&#34;&gt;#&lt;/a&gt;&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;논문&lt;/strong&gt;: An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale (2020)&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;저자&lt;/strong&gt;: Alexey Dosovitskiy et al. (Google)&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;핵심 기여&lt;/strong&gt;: 이미지를 패치로 나누어 순수 Transformer로 처리&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;핵심-아이디어&#34;&gt;핵심 아이디어&lt;a class=&#34;anchor&#34; href=&#34;#%ed%95%b5%ec%8b%ac-%ec%95%84%ec%9d%b4%eb%94%94%ec%96%b4&#34;&gt;#&lt;/a&gt;&lt;/h2&gt;&#xA;&lt;blockquote class=&#39;book-hint &#39;&gt;&#xA;&lt;p&gt;&amp;ldquo;이미지를 단어처럼 취급하자&amp;rdquo;&lt;/p&gt;&#xA;&lt;/blockquote&gt;&lt;p&gt;이미지를 16×16 패치로 나누고, 각 패치를 토큰처럼 Transformer에 입력합니다.&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;구조&#34;&gt;구조&lt;a class=&#34;anchor&#34; href=&#34;#%ea%b5%ac%ec%a1%b0&#34;&gt;#&lt;/a&gt;&lt;/h2&gt;&#xA;&lt;h3 id=&#34;전체-아키텍처&#34;&gt;전체 아키텍처&lt;a class=&#34;anchor&#34; href=&#34;#%ec%a0%84%ec%b2%b4-%ec%95%84%ed%82%a4%ed%85%8d%ec%b2%98&#34;&gt;#&lt;/a&gt;&lt;/h3&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;Input Image (224×224×3)&#xA;        ↓&#xA;Split into patches (14×14 = 196 patches of 16×16)&#xA;        ↓&#xA;Linear projection (flatten + linear → D dim)&#xA;        ↓&#xA;+ Positional Embedding + [CLS] token&#xA;        ↓&#xA;┌─────────────────────────────┐&#xA;│    Transformer Encoder      │&#xA;│  [Multi-Head Attn + FFN]×L │&#xA;└─────────────────────────────┘&#xA;        ↓&#xA;[CLS] token output&#xA;        ↓&#xA;MLP Head → Classification&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&#34;핵심-컴포넌트&#34;&gt;핵심 컴포넌트&lt;a class=&#34;anchor&#34; href=&#34;#%ed%95%b5%ec%8b%ac-%ec%bb%b4%ed%8f%ac%eb%84%8c%ed%8a%b8&#34;&gt;#&lt;/a&gt;&lt;/h3&gt;&#xA;&lt;table&gt;&#xA;  &lt;thead&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;th&gt;컴포넌트&lt;/th&gt;&#xA;          &lt;th&gt;설명&lt;/th&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/thead&gt;&#xA;  &lt;tbody&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;Patch Embedding&lt;/td&gt;&#xA;          &lt;td&gt;16×16×3 → D 차원 벡터&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;[CLS] Token&lt;/td&gt;&#xA;          &lt;td&gt;전체 이미지 표현 학습&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;Position Embedding&lt;/td&gt;&#xA;          &lt;td&gt;학습 가능한 위치 인코딩&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;Transformer Encoder&lt;/td&gt;&#xA;          &lt;td&gt;L개 레이어&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/tbody&gt;&#xA;&lt;/table&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;patch-embedding&#34;&gt;Patch Embedding&lt;a class=&#34;anchor&#34; href=&#34;#patch-embedding&#34;&gt;#&lt;/a&gt;&lt;/h2&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# 이미지를 패치로 분할 후 선형 변환&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# (B, 3, 224, 224) → (B, 196, 768)&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;class&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;PatchEmbedding&lt;/span&gt;(nn&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Module):&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;__init__&lt;/span&gt;(self, img_size&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;224&lt;/span&gt;, patch_size&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;16&lt;/span&gt;, in_channels&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;, embed_dim&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;768&lt;/span&gt;):&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        super()&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;__init__&lt;/span&gt;()&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;num_patches &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; (img_size &lt;span style=&#34;color:#f92672&#34;&gt;//&lt;/span&gt; patch_size) &lt;span style=&#34;color:#f92672&#34;&gt;**&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;proj &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; nn&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Conv2d(in_channels, embed_dim,&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                              kernel_size&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;patch_size, stride&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;patch_size)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;forward&lt;/span&gt;(self, x):&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#75715e&#34;&gt;# (B, C, H, W) → (B, embed_dim, H/P, W/P) → (B, num_patches, embed_dim)&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        x &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;proj(x)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        x &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; x&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;flatten(&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;transpose(&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; x&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;hr&gt;&#xA;&lt;h2 id=&#34;모델-변형&#34;&gt;모델 변형&lt;a class=&#34;anchor&#34; href=&#34;#%eb%aa%a8%eb%8d%b8-%eb%b3%80%ed%98%95&#34;&gt;#&lt;/a&gt;&lt;/h2&gt;&#xA;&lt;table&gt;&#xA;  &lt;thead&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;th&gt;모델&lt;/th&gt;&#xA;          &lt;th&gt;Layers&lt;/th&gt;&#xA;          &lt;th&gt;Hidden&lt;/th&gt;&#xA;          &lt;th&gt;Heads&lt;/th&gt;&#xA;          &lt;th&gt;Params&lt;/th&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/thead&gt;&#xA;  &lt;tbody&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;ViT-Base&lt;/td&gt;&#xA;          &lt;td&gt;12&lt;/td&gt;&#xA;          &lt;td&gt;768&lt;/td&gt;&#xA;          &lt;td&gt;12&lt;/td&gt;&#xA;          &lt;td&gt;86M&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;ViT-Large&lt;/td&gt;&#xA;          &lt;td&gt;24&lt;/td&gt;&#xA;          &lt;td&gt;1024&lt;/td&gt;&#xA;          &lt;td&gt;16&lt;/td&gt;&#xA;          &lt;td&gt;307M&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;ViT-Huge&lt;/td&gt;&#xA;          &lt;td&gt;32&lt;/td&gt;&#xA;          &lt;td&gt;1280&lt;/td&gt;&#xA;          &lt;td&gt;16&lt;/td&gt;&#xA;          &lt;td&gt;632M&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/tbody&gt;&#xA;&lt;/table&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;학습&#34;&gt;학습&lt;a class=&#34;anchor&#34; href=&#34;#%ed%95%99%ec%8a%b5&#34;&gt;#&lt;/a&gt;&lt;/h2&gt;&#xA;&lt;h3 id=&#34;사전학습의-중요성&#34;&gt;사전학습의 중요성&lt;a class=&#34;anchor&#34; href=&#34;#%ec%82%ac%ec%a0%84%ed%95%99%ec%8a%b5%ec%9d%98-%ec%a4%91%ec%9a%94%ec%84%b1&#34;&gt;#&lt;/a&gt;&lt;/h3&gt;&#xA;&lt;p&gt;ViT는 CNN과 달리 inductive bias가 적어서 &lt;strong&gt;대규모 데이터&lt;/strong&gt;가 필수:&lt;/p&gt;</description>
    </item>
    <item>
      <title>DiT</title>
      <link>http://localhost:1313/docs/architecture/transformer/dit/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/architecture/transformer/dit/</guid>
      <description>&lt;h1 id=&#34;dit-diffusion-transformer&#34;&gt;DiT (Diffusion Transformer)&lt;a class=&#34;anchor&#34; href=&#34;#dit-diffusion-transformer&#34;&gt;#&lt;/a&gt;&lt;/h1&gt;&#xA;&lt;h2 id=&#34;개요&#34;&gt;개요&lt;a class=&#34;anchor&#34; href=&#34;#%ea%b0%9c%ec%9a%94&#34;&gt;#&lt;/a&gt;&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;논문&lt;/strong&gt;: Scalable Diffusion Models with Transformers (2023)&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;저자&lt;/strong&gt;: William Peebles, Saining Xie (Meta AI, NYU)&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;핵심 기여&lt;/strong&gt;: Diffusion 모델의 backbone을 U-Net에서 Transformer로 교체&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;핵심-아이디어&#34;&gt;핵심 아이디어&lt;a class=&#34;anchor&#34; href=&#34;#%ed%95%b5%ec%8b%ac-%ec%95%84%ec%9d%b4%eb%94%94%ec%96%b4&#34;&gt;#&lt;/a&gt;&lt;/h2&gt;&#xA;&lt;blockquote class=&#39;book-hint &#39;&gt;&#xA;&lt;p&gt;&amp;ldquo;U-Net 대신 Transformer를 쓰면 scaling이 더 잘 된다&amp;rdquo;&lt;/p&gt;&#xA;&lt;/blockquote&gt;&lt;p&gt;기존 Diffusion 모델(Stable Diffusion 등)은 U-Net을 사용하지만, DiT는 Transformer를 사용하여 더 나은 scaling 특성을 보여줍니다.&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;배경&#34;&gt;배경&lt;a class=&#34;anchor&#34; href=&#34;#%eb%b0%b0%ea%b2%bd&#34;&gt;#&lt;/a&gt;&lt;/h2&gt;&#xA;&lt;h3 id=&#34;기존-diffusion-모델의-backbone&#34;&gt;기존 Diffusion 모델의 backbone&lt;a class=&#34;anchor&#34; href=&#34;#%ea%b8%b0%ec%a1%b4-diffusion-%eb%aa%a8%eb%8d%b8%ec%9d%98-backbone&#34;&gt;#&lt;/a&gt;&lt;/h3&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;Stable Diffusion: Latent → U-Net → Denoised Latent&lt;/code&gt;&lt;/pre&gt;&lt;ul&gt;&#xA;&lt;li&gt;U-Net은 CNN 기반&lt;/li&gt;&#xA;&lt;li&gt;Skip connection으로 세부 정보 보존&lt;/li&gt;&#xA;&lt;li&gt;하지만 모델 크기 증가 시 효율 저하&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;dit의-접근&#34;&gt;DiT의 접근&lt;a class=&#34;anchor&#34; href=&#34;#dit%ec%9d%98-%ec%a0%91%ea%b7%bc&#34;&gt;#&lt;/a&gt;&lt;/h3&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;Latent → Patchify → Transformer → Unpatchify → Denoised Latent&lt;/code&gt;&lt;/pre&gt;&lt;ul&gt;&#xA;&lt;li&gt;ViT 스타일로 latent를 패치화&lt;/li&gt;&#xA;&lt;li&gt;Transformer로 처리&lt;/li&gt;&#xA;&lt;li&gt;모델 크기에 따라 일관된 성능 향상&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;구조&#34;&gt;구조&lt;a class=&#34;anchor&#34; href=&#34;#%ea%b5%ac%ec%a1%b0&#34;&gt;#&lt;/a&gt;&lt;/h2&gt;&#xA;&lt;h3 id=&#34;전체-아키텍처&#34;&gt;전체 아키텍처&lt;a class=&#34;anchor&#34; href=&#34;#%ec%a0%84%ec%b2%b4-%ec%95%84%ed%82%a4%ed%85%8d%ec%b2%98&#34;&gt;#&lt;/a&gt;&lt;/h3&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;Input: Noisy Latent (z_t) + Timestep (t) + Class (c)&#xA;            ↓&#xA;    Patchify (latent → patches)&#xA;            ↓&#xA;    + Position Embedding&#xA;            ↓&#xA;┌─────────────────────────────────────┐&#xA;│         DiT Blocks × N             │&#xA;│  ┌─────────────────────────────┐   │&#xA;│  │     Layer Norm              │   │&#xA;│  │           ↓                 │   │&#xA;│  │    Multi-Head Self-Attn    │   │&#xA;│  │           ↓                 │   │&#xA;│  │     Layer Norm              │   │&#xA;│  │           ↓                 │   │&#xA;│  │    Pointwise FFN           │   │&#xA;│  │           ↓                 │   │&#xA;│  │    + AdaLN (t, c embed)    │   │&#xA;│  └─────────────────────────────┘   │&#xA;└─────────────────────────────────────┘&#xA;            ↓&#xA;    Final Layer Norm&#xA;            ↓&#xA;    Linear (predict noise &amp;amp; variance)&#xA;            ↓&#xA;    Unpatchify&#xA;            ↓&#xA;Output: Predicted Noise (ε) + Variance (Σ)&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&#34;adaln-adaptive-layer-norm&#34;&gt;AdaLN (Adaptive Layer Norm)&lt;a class=&#34;anchor&#34; href=&#34;#adaln-adaptive-layer-norm&#34;&gt;#&lt;/a&gt;&lt;/h3&gt;&#xA;&lt;p&gt;조건 정보(timestep, class)를 Layer Norm에 주입:&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
